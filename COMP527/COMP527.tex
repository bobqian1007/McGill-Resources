\documentclass[12 pt]{article}
\usepackage{hyperref, fancyhdr, setspace, enumerate, amsmath,
  lastpage, amssymb, algpseudocode, bussproofs, tikz, listings,
  marvosym, stmaryrd, collectbox}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{positioning}
\EnableBpAbbreviations
\usepackage[margin=1 in]{geometry}
\allowdisplaybreaks
% \usepackage[dvipsnames]{xcolor}   %May be necessary if you want to color links
\hypersetup{
  % colorlinks=true, %set true if you want colored links
  linktoc=all,     %set to all if you want both sections and subsections linked
  linkcolor=black,  %choose some color if you want links to stand out
}
% New environment to scale prooftrees, from https://tex.stackexchange.com/questions/104554/how-to-scale-prooftree-environment-bussproofs-package
\newenvironment{scprooftree}[1]%
  {\gdef\scalefactor{#1}\begin{center}\proofSkipAmount \leavevmode}%
  {\scalebox{\scalefactor}{\DisplayProof}\proofSkipAmount \end{center}
}
%New command \mybox to box something
\newcommand{\mybox}{%
\collectbox{%
	\setlength{\fboxsep}{3pt}%
	\fbox{\BOXCONTENT}%
	}%
}

\usepackage{graphicx}
\graphicspath{{Images/}}
\author{Julian Lore}
\date{Last updated: \today}
\title{COMP 527: Logic and Computation}
\pagestyle{fancy}
\lhead{COMP 527}
\chead{\leftmark}
\rhead{Julian Lore}
\cfoot{Page \thepage \ of \pageref{LastPage}}
\newcommand{\tab}[1]{\hspace{.2\textwidth}\rlap{#1}}
\newenvironment{rcases}
  {\left.\begin{aligned}}
  {\end{aligned}\right\rbrace}
\begin{document}
\onehalfspacing
\maketitle
\tableofcontents
\section{01/08/19}
\paragraph{Goal:}
\begin{itemize}
	\item Introduction to the proof theoretic foundations
	\item Study the relationship to programming languages and their
	      design
\end{itemize}
\paragraph{Schedule:}
\begin{itemize}
	\item Week 1: Natural Deduction
	\item Week 2: Tutorial (Jacob) on using Tutch (proof assistant,
	      program on writing Natural Deduction proofs)
	\item Week 3: Proofs in the natural deduction system and programs
	      in the $\lambda$-calculus
	\item Week 4: First Order Logic
	\item Week 5: Induction (how we can add induction to logic,
	      corresponds to recursion)
	\item Week 6/7: Programming with dependent types
	\item Week 8: Sequent calculus
	\item Week 9: Consistency
	\item Week 10: Proof search
	\item Week 11/12: Linear logic, modal logic or temporal logic
\end{itemize}
\subsection{Natural Deduction}
\begin{itemize}
	\item G. Gentzen started describing it in the mid 30s
	\item Martin L\"of continued in the mid 80s
\end{itemize}
\paragraph{Motivation} To design a modular system for
reasoning. Want to capture the reasoning of mathematicians (that's
why it's called natural). It is modular because we define the
meaning of each connective by themselves (will not refer to any
other connective in the definition).
\paragraph{Judgment} ``Something we know'' or ``something that is
evident''
\\ Ex. $A$ true, ``The proposition $A$ is true'' (Semantics)
\\ $A$ wf, ``The proposition $A$ is syntactically well-formed''
(Syntax)
\\ $A$ true @ $t$, ``The proposition
$A$ is true at time $t$''
\\ Can describe both aspects (semantics and syntax) as judgment

\paragraph{Example Grammar}
Proposition $A, B:= T \mid \perp \mid A \land B \mid \ldots$
\begin{prooftree}
	\AXC{}
	\UIC{T wf}
\end{prooftree}
\begin{prooftree}
	\AXC{}
	\UIC{$\perp$ wf}
\end{prooftree}
\begin{prooftree}
	\AXC{A wf}
	\AXC{B wf}
	\BIC{A $\land$ B wf}
\end{prooftree}
\begin{prooftree}
	\AXC{$J_1$}
	\AXC{\ldots}
	\AXC{$J_n$}
	\TIC{$J$}
\end{prooftree}
$J_i$ are the premises, $J$ is the conclusion
\\ $A$ true
\begin{itemize}
	\item Introduction rules: How can we conclude $A$
	\item Elimination rules: What information can we extract from A?
	      (i.e. T, $\perp$, $A \land B$, \ldots)
\end{itemize}
\begin{prooftree}
	\AXC{}
	\RL{T I (Introduction)}
	\UIC{T true}
\end{prooftree}
No elim rule for T
\paragraph{Conjunction}
\begin{prooftree}
	\AXC{A true}
	\AXC{B true}
	\RL{$\land$I}
	\BIC{$A \land B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \land B$ true}
	\RL{$\land$E$_l$ (Elimination)}
	\UIC{$A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \land B$ true}
	\RL{$\land$E$_r$}
	\UIC{$B$ true}
\end{prooftree}
What can we now prove?
\begin{prooftree}
	\AXC{}
	\RL{$T$ I}
	\UIC{$T$ true}
	\AXC{}
	\RL{$T$ I}
	\UIC{$T$ true}
	\RL{$\land$ I}
	\BIC{$T \land T$ true}
\end{prooftree}
Is the following a proof?
\begin{prooftree}
	\AXC{$A \land (B \land C)$ true}
	\RL{$\land$E$_r$}
	\UIC{$B \land C$ true}
	\RL{$\land$ E$_l$}
	\UIC{$B$ true}
\end{prooftree}
No, how do we know $A \land (B \land C)$ is true?

Given the assumption (hypothesis) $A \land (B \land C)$ true, we
can construct a proof for $B$ true (reasoning by
assumption/hypothetical reasoning/derivation).
\begin{prooftree}
	\AXC{}
	\RL{$u_1$}
	\UIC{$J_1$}
	\AXC{\ldots}
	\AXC{}
	\RL{$u_n$}
	\UIC{$J_n$}
	\TIC{\vdots}
	\noLine
	\UIC{$J$}
\end{prooftree}
\paragraph{Implication}
\begin{prooftree}
	\AXC{}
	\RL{$u$}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$B$ true}
	\RL{$ \supset$ I$^{u}$}
	\UIC{$A \supset B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \supset B$ true}
	\AXC{$A$ true}
	\RL{$\supset$ E}
	\BIC{$B$ true}
\end{prooftree}
We do not include $A \supset B$ true, $B$ false, implies $A$
false, because we did not add a judgment for false, only talking
about things that are true. If we cannot say something is true, it
is implied that it is false.

Let's prove:
\begin{prooftree}
	\AXC{}
	\RL{$u$}
	\UIC{$A$ true}
	\AXC{}
	\RL{$v$}
	\UIC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$ true}
	\RL{$\supset I^v$}
	\UIC{$B \supset A \land B$ true}
	\RL{$\supset I^u$}
	\UIC{$A \supset (B\supset A \land B)$ true}
\end{prooftree}
\paragraph{Observations}
\begin{enumerate}
	\item \underline{Order} of assumptions does not matter.
	\item Do I have to use an assumption? No. This is called \underline{weakening}.
	      \\ Floating assumption that isn't used:
	      \begin{prooftree}
		      \AXC{}
		      \RL{$v$}
		      \UIC{$B$ true}
	      \end{prooftree}
	      \begin{prooftree}
		      \AXC{}
		      \RL{$u$}
		      \UIC{$A$ true}
		      \RL{$\supset I^v$}
		      \UIC{$B\supset A$ true}
		      \RL{$\supset I^u$}
		      \UIC{$A \supset B \supset A$ true}
	      \end{prooftree}
	\item Can we use assumptions more than once? Yes. This is called
	      \underline{strengthening} (you contract multiple of these
	      assumptions into one).
	      \begin{prooftree}
		      \AXC{}
		      \RL{$u$}
		      \UIC{$A$ true}
		      \AXC{}
		      \RL{$u$}
		      \UIC{$A$ true}
		      \RL{$\land$I}
		      \BIC{$A \land A$ true}
		      \RL{$\supset I^u$}
		      \UIC{$A \supset (A \land A)$ true}
	      \end{prooftree}
	      This is a program that takes in an input and returns it twice.
\end{enumerate}
A simple proof:
\begin{prooftree}
	\AXC{}
	\RL{$u$}
	\UIC{$A \land B$ true}
	\RL{$\land$ E$_l$}
	\UIC{$A$ true}
	\AXC{}
	\RL{$u$}
	\UIC{$A \land B$ true}
	\RL{$\land$ E$_r$}
	\UIC{$B$ true}
	\RL{$\land$I}
	\BIC{$B\land A$ true}
	\RL{$\supset I^u$}
	\UIC{$(A \land B) \supset (B \land A)$ true}
\end{prooftree}
\section{01/10/18}
\subsection{Natural Deduction}
\underline{A true}
\paragraph{Conjunction}
\begin{prooftree}
	\AXC{$A$ true}
	\AXC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \land B$ true}
	\RL{$\land$E$_l$ (Elimination)}
	\UIC{$A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \land B$ true}
	\RL{$\land$E$_r$}
	\UIC{$B$ true}
\end{prooftree}
\paragraph{Implications}
This discharges the assumption $u$ and is the only rule we have
right now that discharges assumptions.
\begin{prooftree}
	\AXC{}
	\RL{$u$}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$B$ true}
	\RL{$ \supset$ I$^{u}$}
	\UIC{$A \supset B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \supset B$ true}
	\AXC{$A$ true}
	\RL{$\supset$ E}
	\BIC{$B$ true}
\end{prooftree}
\paragraph{Truth}
\begin{prooftree}
	\AXC{}
	\RL{T I}
	\UIC{T true}
\end{prooftree}
To get the smallest complete example, we need to introduce
$\perp$.
\paragraph{Falsehood}
No Intro-Rule for $\perp$.
\begin{prooftree}
	\AXC{$\perp$ true}
	\RL{$\perp$ E}
	\UIC{$A$ true}
\end{prooftree}
Define Negation as an abbreviation (notational definition)
$$\neg A \equiv A \supset \perp$$
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A \land \neg A$}
	\RL{$\land$ E$_l$}
	\UIC{$A$}
	\AXC{}
	\RL{u}
	\UIC{$A \land \neg A$}
	\RL{$\land$ E$_r$}
	\UIC{$\neg A \equiv (A \supset \perp)$}
	\RL{$\supset$ E}
	\BIC{$\perp$}
	\RL{$\supset$ I$^u$}
	\UIC{$\neg (A \land \neg A)$ true}
\end{prooftree}
If we could prove $\perp$ from no assumptions, then our system
would be inconsistent.
\paragraph{Examples}
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A\supset (B \land C)$ true}
	\AXC{}
	\RL{v}
	\UIC{$A$ true}
	\RL{$\supset$ E}
	\BIC{$B \land C$ true}
	\RL{$\land$ E$_l$}
	\UIC{$B$ true}
	\RL{$\supset$I$^v$}
	\UIC{$A \supset B$ true}
	\AXC{}
	\RL{u}
	\UIC{$A \supset (B \land C)$ true}
	\AXC{}
	\RL{v}
	\UIC{$A$ true}
	\BIC{$B \land C$}
	\RL{$\land$ E}
	\UIC{$C$ true}
	\RL{$\supset$ I$^v$}
	\UIC{$A \supset C$ true}
	\RL{$\land$ I}
	\BIC{$(A \supset B) \land (A \supset C)$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$(A \supset (B \land C)) \supset ((A \supset B) \land
			(A \supset C)) = (A \land \neg A) \supset \perp$ true}
\end{prooftree}
Note that the assumptions u and v are used twice, but in different
areas.
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A$}
	\AXC{}
	\RL{v}
	\UIC{$\neg A$}
	\RL{$\supset$ E}
	\BIC{$\perp$}
	\RL{$\supset$ I$^v$}
	\UIC{$\neg \neg A = \neg A \supset \perp$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$A \supset \neg \neg A$ true}
\end{prooftree}
Is $A = \neg \neg A$? We cannot prove this in this logic unless we
assume an axiom (although it is true for classical logic).

For a proof, we must discharge all assumptions we make.

\paragraph{Local Soundness}
How do we know the rules we defined for natural deduction make
sense?

Elimination Rules are not too strong (they don't allow us to
conclude more than we should be able to). If the rules are too
strong, we'll be able to prove things that we shouldn't be able
to, more than we had to start with.

Given a proof $\mathcal{D}$ for $A$ true and a proof $\mathcal{E}$ for
$B$ true, we can prove $A$ true.
\begin{center}
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$A$ true}
	\AXC{$\mathcal{E}$}
	\noLine
	\UIC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$ true}
	\RL{$\land$ E}
	\UIC{$A$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$\mathcal{D}$
		\\ $A$ true
	\end{tabular}
\end{center}
\begin{center}
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$A$ true}
	\AXC{$\mathcal{E}$}
	\noLine
	\UIC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$ true}
	\RL{$\land$ E}
	\UIC{$B$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$\mathcal{E}$ \\ $B$ true
	\end{tabular}
\end{center}
\paragraph{Local Completeness}
Elimination Rules are not too weak, i.e. we are expanding proofs.
\begin{center}
	\begin{tabular}{c}
		$\mathcal{D}$ \\ $A \land B$ true
	\end{tabular}
	$\implies$
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$A \land B$ true}
	\RL{$\land$ E$_l$}
	\UIC{$A$ true}
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$A \land B$ true}
	\RL{$\land$ E$_r$}
	\UIC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$ true}
	\DP
\end{center}
\paragraph{Local Soundness (Implication)}
\begin{center}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$\mathcal{D}^u$}
	\noLine
	\UIC{$B$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$A \supset B$ true}
	\AXC{$\mathcal{E}$}
	\noLine
	\UIC{$A$ true}
	\RL{$\supset$ E}
	\BIC{$B$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$\mathcal{E}$
		\\$A$ true
			\\$[\mathcal{E}/u] (\mathcal{D})$
		\\$B$ true
	\end{tabular}
\end{center}
\paragraph{Substitution Principle}
\begin{center}
	If
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{$\vdots$}
	\noLine
	\UIC{$\mathcal{D}$}
	\noLine
	\UIC{$B$ true}
	\DP
	and
	\begin{tabular}{c}
		\begin{tikzpicture} [
				triangle/.style = {fill=blue!20, regular polygon, regular polygon sides=3 },
				node rotated/.style = {rotate=180},
				border rotated/.style = {shape border rotate=180}
			]
			\node[triangle, border rotated] {$\mathcal{E}$};
		\end{tikzpicture} \\
		$A$ true
	\end{tabular},
	then
	\begin{tabular}{c}
		\begin{tikzpicture} [
				triangle/.style = {fill=blue!20, regular polygon, regular polygon sides=3 },
				node rotated/.style = {rotate=180},
				border rotated/.style = {shape border rotate=180}
			]
			\node[triangle, border rotated] {$\mathcal{E}$};
		\end{tikzpicture} \\
		$A$ true                   \\ $\mathcal{D}$ \\ $B$ true
	\end{tabular}
\end{center}

Basically, if we have a proof for $A$ true and from $A$ true we
can show $B$ true, then we have a proof for $B$ true.

\paragraph{Local Completeness}
\begin{center}
	\begin{tabular}{c}
		$\alpha$
		\\$A \supset B$ true
	\end{tabular}
	$\implies$
	\AXC{$\alpha$}
	\noLine
	\UIC{$A \supset B$ true}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\RL{$\supset$ E}
	\BIC{$B$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$A \supset B$ true}
	\DP
\end{center}
So we can prove $A \supset B$ from $A \supset B$.

Another form of $\land$ elimination:
\begin{prooftree}
	\AXC{$A \land B$ true}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\noLine
	\BIC{\vdots}
	\noLine
	\UIC{$C$ true}
	\RL{$\land E^{u,v}$}
	\BIC{$C$ true}
\end{prooftree}
We could use this new rule and check for local soundness and
completeness like above.

Could have unused, floating assumption:
\begin{prooftree}
	\AXC{}
	\RL{a}
	\UIC{$A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A \land B$}
	\RL{b}
	\UIC{$B$ true}
	\AXC{\vdots}
	\noLine
	\UIC{$A$ true}
	\BIC{$B \land A$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$A \land B \supset B \land A$ true}
\end{prooftree}
\subsection{Disjunction}
Intro-Rules:
\begin{prooftree}
	\AXC{$A$ true}
	\RL{$\lor$ I$_l$}
	\UIC{$A \lor B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$B$ true}
	\RL{$\lor$ I$_r$}
	\UIC{$A \lor B$ true}
\end{prooftree}
Might be tempted to make the following rule:
\begin{prooftree}
	\AXC{$B$ true}
	\RL{$\lor$ I$_r$}
	\UIC{$A \lor B$ true}
	\RL{?}
	\UIC{$A$ true}
\end{prooftree}
This is locally unsound! Got information we didn't start with.

We also cannot introduce:
\begin{prooftree}
	\AXC{$A \lor B$}
	\UIC{$\neg A \supset B$ true}
\end{prooftree}
This violates our principle of modularity, as we don't want to
refer to a different kind of connective.

Our elimination rule:
\begin{prooftree}
	\AXC{$A \lor B$ true}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$C$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$C$ true}
	\RL{$\lor$ E$^{u,v}$}
	\TIC{$C$ true}
\end{prooftree}
\paragraph{Example}
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A \lor (B \land C)$ true}
	\AXC{}
	\RL{a}
	\UIC{$A$ true}
	\RL{$\lor$ I$_l$}
	\UIC{$A \lor C$ true}
	\AXC{}
	\RL{b}
	\UIC{$B \land C$ true}
	\RL{$\land$ E$_l$}
	\UIC{$B$ true}
	\RL{$\lor$ I$_r$}
	\UIC{$A \lor B$ true}
	\RL{$\lor$ E}
	\TIC{$A \lor B$ true}
	\AXC{\vdots}
	\noLine
	\UIC{$A \lor C$ true} % Same proof as other thing (almost)
	\RL{$\lor$ I}
	\BIC{$(A \lor B)\land (A \lor C)$}
	\RL{$\supset$ I}
	\UIC{$(A \lor (B \land C))\supset (A \lor B)\land (A \lor C)$}
\end{prooftree}
\section{01/15/19}
Recall: We defined $\neg A$ as $A \supset \perp$. But, there are
other ways you can introduce (define) negation.
\subsection{Negation}
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$p$ true}
	\RL{$\neg$ I$^{u,p}$}
	\UIC{$\neg A$ true}
\end{prooftree}
If we can prove any parameter $p$ from $A$ true, then $\neg A$ is
true. This discharges the assumption $u$ and $p$.
\begin{prooftree}
	\AXC{$\neg A$ true}
	\AXC{$A$ true}
	\RL{$\neg$ E}
	\BIC{$C$ true}
\end{prooftree}
For these new rules, as usual, we want to prove that they are
locally sound and complete. In general, for local soundness, you
want to introduce the rule and then eliminate it and show that
you've learned nothing new.
\paragraph{Local Soundness}
\begin{center}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{$D$}
	\noLine
	\UIC{$p$ true}
	\RL{$\neg$ I$^{p,u}$}
	\UIC{$\neg A$ true}
	\AXC{$\mathcal{E}$}
	\noLine
	\UIC{$A$ true}
	\RL{$\neg$ E}
	\BIC{$C$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$ [\mathcal{E}/u, C/p]D$
		\\ $C$ true
	\end{tabular}
\end{center}
\paragraph{Local Completeness}
\begin{center}
	\begin{tabular}{c}
		$\mathcal{D}$
		\\ $\neg A$ true
	\end{tabular}
	$\implies$
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$\neg A$ true}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\RL{$\neg$ E}
	\BIC{$p$ true}
	\RL{$\neg$ I$^{p,u}$}
	\UIC{$\neg A$ true}
	\DP
\end{center}
\subsection{Classical Reasoning}
Basic idea behind proof by contradiction, you assume $\neg A$,
arrive at a contradiction and then you can prove $A$ true.

\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$\neg A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$p$ true}
	\RL{$C^{u,p}$}
	\UIC{$A$ true}
\end{prooftree}
where $C^{u,p}$ means a proof by contradiction under $u$ and $p$.
\paragraph{Law of Excluded Middle}
Want to show $\neg A \lor A$ is true for all $A$.
\begin{prooftree}

	\AXC{}
	\RL{u}
	\UIC{$\neg (\neg A \lor A)$ true}

	\AXC{}
	\RL{v}
	\UIC{$\neg A$}
	\RL{$\lor$ I$_l$}
	\UIC{$\neg A \lor A$}

	\RL{$\neg$ E}
	\BIC{$p$ true}
	\RL{$C^{v,p}$}
	\UIC{$A$}
	\RL{$\lor$ I$_r$}
	\UIC{$\neg A \lor A$}

	\AXC{}
	\RL{u}
	\UIC{$\neg (\neg A \lor A)$ true}
	\RL{$\neg$ E}

	\BIC{$q$ true}
	\RL{$C^{u,q}$}
	\UIC{$\neg A \lor A$}
\end{prooftree}
\paragraph{Law of Excluded Middle and more examples in tutch}
\lstinputlisting{lem.tut}
\subparagraph{Output}
\lstinputlisting{lem.tut.output}
\subsection{NAND}
$A \overline{\land} B \equiv \neg (A \land B)$

Showing this introduction rule is often a midterm question. Often,
people make the mistake of using $A \land B$, but we cannot
introduce other connectives, make sure $A$ and $B$ are separate.
\begin{prooftree}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\noLine
	\BIC{\vdots}
	\noLine
	\UIC{$p$ true}
	\RL{$\overline{\land}$ I}
	\UIC{$A \overline{\land} B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A$ true}
	\AXC{$B$ true}
	\AXC{$A \overline{\land} B$ true}
	\RL{$\overline{\land}$ E}
	\TIC{$C$ true}
\end{prooftree}
\paragraph{Local Soundness}
Get rid of assumptions by substituting $\mathcal{E}_1,
	\mathcal{E}_2$ and $C$ into $\mathcal{D}$.
\begin{center}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\noLine
	\BIC{$\mathcal{D}$}
	\noLine
	\UIC{$p$ true}
	\RL{$\overline{\land}$ I$^{u,v,p}$}
	\UIC{$A \overline{\land} B$ true}
	\AXC{$\mathcal{E}_1$}
	\noLine
	\UIC{$A$ true}
	\AXC{$\mathcal{E}_2$}
	\noLine
	\UIC{$B$ true}
	\TIC{$C$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$[\mathcal{E}_1/u, \mathcal{E}_2/v, C/p] \mathcal{D}$
		\\ $C$ true
	\end{tabular}
\end{center}
\paragraph{Local Completeness}
\begin{center}
	\begin{tabular}{c}
		$\mathcal{D}$
		\\ $A \overline{\land} B$
	\end{tabular}
	$\implies$
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$A \overline{\land} B$ true}
	\RL{$\overline{\land}$ E}
	\TIC{$p$ true}
	\RL{$\overline{\land}$ I$^{u,v,p}$}
	\UIC{$A \overline{\land} B$}
	\DP
\end{center}
Look for other connectives and do these proofs, as they will
probably be on the midterm.
\section{01/17/19}
\subsection{Context}
So we've seen several rules so far:
\begin{prooftree}
	\AXC{}
	\UIC{$T$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\perp$ true}
	\RL{}
	\UIC{$C$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A$ true}
	\AXC{$B$ true}
	\RL{$\land$ I}
	\BIC{$A \land B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \land B$ true}
	\RL{$\land$ E$_l$}
	\UIC{$A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A \lor B$ true}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine{}
	\UIC{\vdots}
	\noLine
	\UIC{$C$ true}

	\AXC{}
	\RL{v}
	\UIC{$B$}
	\noLine
	\UIC{$\vdots$}
	\noLine
	\UIC{$C$ true}
	\RL{$\lor$ E$^{u,v}$}
	\TIC{$C$ true}
\end{prooftree}
We are now going to extend these rules with contexts, which allows
us to know what we've proved and what assumptions we have at each
step.

Instead of $A$ true, we will write $\Gamma \vdash A$ true. This
means:

``A is true in context $\Gamma$.''

$$\Gamma ::= \cdot \mid \Gamma, u:A \text{ true}$$

So:
\begin{center}
	\AXC{}
	\RL{u}
	\UIC{$A$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\UIC{$B$ true}
	\RL{$\supset$ I$^u$}
	\UIC{$A \supset B$ true}
	\DP
	$\stackrel{+\Gamma}{\longrightarrow}$
	\AXC{$\Gamma,u:A$ true $\vdash B$ true}
	\UIC{$\Gamma \vdash A \supset B$ true}
	\DP
\end{center}
\begin{prooftree}
	\AXC{}
	\UIC{$\Gamma \vdash T$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash \perp$ true}
	\RL{}
	\UIC{$\Gamma \vdash C$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash A$ true}
	\AXC{$\Gamma \vdash B$ true}
	\RL{$\land$ I}
	\BIC{$\Gamma \vdash A \land B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash A \land B$ true}
	\RL{$\land$ E$_l$}
	\UIC{$\Gamma \vdash A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash A \lor B$ true}
	\AXC{$\Gamma,u: A $ true $\vdash C$}
	\AXC{$\Gamma,v: B $ true $\vdash C$}
	\RL{$\lor$ E$^{u,v}$}
	\TIC{$\Gamma\vdash C$ true}
\end{prooftree}
For something to be derived from a context:
\begin{prooftree}
	\AXC{$u: A$ true $\in \Gamma$}
	\RL{H}
	\UIC{$\Gamma \vdash A$ true}
\end{prooftree}
\paragraph{Example}
\begin{prooftree}
	\AXC{$A \in \Gamma, A, B$}
	\RL{H}
	\UIC{$\Gamma, A, B \vdash$ A}
	\AXC{$B \in \Gamma, A, B$}
	\RL{$H$}
	\UIC{$\Gamma, A, B \vdash$ B}

	\RL{$\land$ I}
	\BIC{$\Gamma, u: A$ true, $B$ true $\vdash A \land B$}
	\RL{$\supset$ I}
	\UIC{$\Gamma,u:A$ true $\vdash B \supset A \land B$}
	\RL{$\supset$ I}
	\UIC{$\Gamma \vdash A \supset B \supset A \land B$}
\end{prooftree}
\subsection{The Curry-Howard Correspondence}
We can see that natural deduction is the same as
functional programming:
\\
\begin{tabular}{c c}
	Logic & Types
	\\ \hline $\perp$ & unit
	\\ $A \land B$ & $A \times B$
	\\ $A \lor B$ & $A + B$
	\\ $A \supset B$ & $A \implies B$
	\\ $\perp$ & $\emptyset$
	\\ proofs & programs
	\\ checking a proof & type checker
\end{tabular}
\\

$\emptyset$ is the empty type. There is no proof for $\perp$,
which is why there is no program for $\emptyset$, the two sides
are equivalent.

Proof terms capture the structure of a derivation.

\begin{prooftree}
	\AXC{}
	\RL{H}
	\UIC{$\Gamma,x:A,y:B\vdash x:A$}
	\AXC{}
	\RL{H}
	\UIC{$\Gamma,x:A,y:B\vdash y:B$}
	\RL{$\times$ I}
	\BIC{$\Gamma,x:A,y:B \vdash (x,y): A \times B$}
	\RL{$\implies$ I$^y$}
	\UIC{$\Gamma,x:A \vdash fn\ y \implies (x,y): B \implies A \times
			B$}
	\RL{$\implies$ I$^x$}
	\UIC{$\Gamma \vdash fn\ x \implies fn\ y \implies (x,y) : A \implies B \implies A \times B$}
\end{prooftree}

$\Gamma \vdash M : A$ means:\\
``M is a proof term (program) for proposition (of type) A.''
\subsection{Proof Terms}
Let's upgrade the rules we mentioned earlier to types:
\begin{prooftree}
	\AXC{}
	\UIC{$\Gamma \vdash () : unit$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M: \emptyset$}
	\RL{}
	\UIC{$\Gamma \vdash abort\ M : C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M_1: A$ true}
	\AXC{$\Gamma \vdash M_2: B$ true}
	\RL{$\times$ I}
	\BIC{$\Gamma \vdash (M_1, M_2)\ A\ B$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M: A \times B$}
	\RL{$\times$ E$_l$}
	\UIC{$\Gamma \vdash fst\ M: A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M: A \times B$}
	\RL{$\times$ E$_r$}
	\UIC{$\Gamma \vdash snd\ M: B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M: A + B$ true}
	\AXC{$\Gamma,u: A \vdash N_1:C$}
	\AXC{$\Gamma,v: B \vdash N_2:C$}
	\RL{$+$ E}
	\TIC{$\Gamma\vdash $ case $M$ of}
	\noLine
	\UIC{inl $u \implies N_1$}
	\noLine
	\UIC{inr $v \implies N_2$}
\end{prooftree}
(Where inl is inject left and inr is inject right) Note that this
is pattern matching!
\begin{prooftree}
	\AXC{$\Gamma, x:A \vdash M:B$}
	\UIC{$\Gamma \vdash (fn\ x \implies M):A \implies B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A$}
	\RL{$+$ I$_l$}
	\UIC{$\Gamma \vdash inl \ M: A + B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : B$}
	\RL{$+$ I$_r$}
	\UIC{$\Gamma \vdash inr \ M: A + B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A \implies B$}
	\AXC{$\Gamma \vdash N : A$}
	\BIC{$\Gamma \vdash M\_N: B$}
\end{prooftree}
where $\_$ is a space.
\paragraph{Example}
We did this on Tuesday, now we'll see it with proof terms.
\begin{prooftree}
	\AXC{}
	\RL{H}
	\UIC{$\Gamma, x : A \times B \vdash x : A \times B$}
	\RL{$\times$ E}
	\UIC{$\Gamma, x: A \times B \vdash snd\ x : B$}

	\AXC{}
	\RL{H}
	\UIC{$\Gamma, x : A \times B \vdash x : A \times B$}
	\RL{$\times$ E}
	\UIC{$\Gamma, x: A \times B \vdash fst\ x : A$}
	\RL{$\times$ I}

	\BIC{$\Gamma, x: A \times B \vdash (snd\ x, fst\ x) : B \times
			A$}
	\RL{$\implies$ I}
	\UIC{$\Gamma \vdash fn\ x \implies (snd\ x, fst\ x) : A \times B \implies B \times A$}
\end{prooftree}
\paragraph{Tutch Examples}
\lstinputlisting[breaklines=true]{proofterms.tut}
\section{01/22/19}
\subsection{Metatheory}
Proving things (properties) about a given theory, this will
eventually lead us to completeness.

So far, we've seen:
\paragraph{Propositions/Types} $A,B:=T \mid \perp \mid A \supset B \mid A
	\land B \mid A \lor B$

\paragraph{Proof Terms} $M,N := \langle \rangle \mid abort^{A}\ M
	\mid \underbrace{\lambda x: A.M}_{fn\ x \implies M} \mid M \ N$

\begin{prooftree}
	\AXC{$M : \perp$}
	\UIC{$abort^{A}\ M : A$}
\end{prooftree}

Note that: $M : A$ means: Term $M$ has type $A$ or $M$ is a proof
witness for the proposition $A$

Types that have one type are sometimes just called singleton
types.

Earlier we saw:
\begin{prooftree}
	\AXC{}
	\RL{$u_1$}
	\UIC{$A_1$ true}
	\UIC{$\ddots$}

	\AXC{\ldots}

	\AXC{}
	\RL{$u_n$}
	\UIC{$A_n$ true}
	\UIC{$\ddots$}

	\TIC{$C$ true}
\end{prooftree}
More compactly: Context $\Gamma := \cdot \mid T, A$ true

$$\Gamma \underbrace{\vdash}_{\text{turnstyle}} C \text{ true}$$

\paragraph{Reminder about Contexts}
Context $\Gamma := \cdot \mid \Gamma, x: A$
\begin{prooftree}
	\AXC{$\Gamma \vdash M : \perp$}
	\UIC{$\Gamma \vdash abort^{A}\ M : A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma,x:A \vdash M : B$}
	\UIC{$\Gamma \vdash \lambda x:A.M: A \supset B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A \supset B$}
	\AXC{$\Gamma \vdash N : A$}
	\BIC{$\Gamma \vdash M\ N:B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$x : A \in \Gamma$}
	\UIC{$\Gamma \vdash x : A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A$}
	\AXC{$\Gamma \vdash N : B$}
	\BIC{$\Gamma \vdash \langle M, N \rangle : A \land B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A \land B$}
	\UIC{$\Gamma \vdash fst \ M : A$}
\end{prooftree}
Note that, some may be inclined to make $A \land B$ have a type of
some pair for $\land$ E, i.e. $\langle M,N \rangle$, but we don't want to limit ourselves to a
pair (we also don't yet know it's a pair), so we cannot make it a
pair right off the bat.
\begin{prooftree}
	\AXC{$\Gamma \vdash M : A \land B$}
	\UIC{$\Gamma \vdash snd \ M : B$}
\end{prooftree}
What would we like to compute with these rules?

General form: $M \implies M'$, Term $M$ reduces to $M'$.
\\ $fst\ \langle M, N \rangle \implies M$
\\ $snd\ \langle M, N \rangle \implies N$

So we can now show things like local soundness with terms:
\begin{center}
	\AXC{$\mathcal{D}_1$}
	\noLine
	\UIC{$\Gamma \vdash M : A$}
	\AXC{$\mathcal{D}_2$}
	\noLine
	\UIC{$\Gamma \vdash N : B$}
	\RL{$\land$ I}
	\BIC{$\Gamma \vdash \langle M, N \rangle : A \land B$}
	\RL{$\land$ E$_l$}
	\UIC{$\Gamma \vdash fst \ \langle M, N \rangle : A$}
	\DP
	$\implies$
	\begin{tabular}{c}
		$\mathcal{D}_1$
		\\ $M : A$
	\end{tabular}
\end{center}
Local Soundness here corresponds to Subject Reduction/Type
Preservation.

We've essentially proved that if we start with something well
typed (of type $A$), we end up with something that is still well
typed, we can show that our program is type \textbf{safe}.

Now if we have a function:

$(\lambda x : A . M) N \implies [N/x] M$
\paragraph{Simple Program}
\begin{align*}
	 & fst \ ((\lambda x . \lambda y . \langle x , y \rangle) \langle \rangle \langle \rangle)
	\\ \implies & fst \ \langle \langle \rangle, \langle \rangle \rangle
	\\ \implies & \langle \rangle : T
\end{align*}
The type of this program is unit, because we have stated earlier
that the type we start with is the type we end with. How do we
know the first line is of type unit?
\begin{prooftree}

	\AXC{}
	\RL{var}
	\UIC{$x:T, y:T \vdash x:T$}

	\AXC{}
	\RL{var}
	\UIC{$x:T, y:T \vdash y:T$}

	\RL{$\land$ I}
	\BIC{$x: T, y:T \vdash \langle x,y \rangle : T \land T$}
	\UIC{$x:T \vdash \lambda y:T \langle x,y \rangle : T \supset (T
			\land T)$}
	\RL{$\supset$ I}
	\UIC{$\lambda x: T \lambda . y: T \langle x,y \rangle : T \supset
			T \supset (T \land T)$}

	\AXC{}
	\RL{$T$ I}
	\UIC{$\langle \rangle$ : T}

	\RL{$\supset$ E}
	\BIC{$(\lambda x : T \lambda . y: T \langle x,y \rangle)$ : $\langle \rangle$}

	\AXC{}
	\RL{$T$ I}
	\UIC{$\langle \rangle$ : T}

	\BIC{$((\lambda x:T . \lambda y: T \langle x,y \rangle) \langle
			\rangle) \langle \rangle$ : }
	\RL{$\land$ E$_l$}
	\UIC{$fst\ (\lambda x : T . \lambda y : T \langle x,y \rangle)
			\langle \rangle \langle \rangle$ : }
\end{prooftree}

Note that we have:

If $\Gamma \vdash M : A$ and $M \implies M'$ then $\Gamma \vdash
	M': A$ (subject reduction)

If $\Gamma \vdash M' : A$ and $M \implies M'$ then $\Gamma \vdash
	M: A$ (won't prove this second one, as it's much less obvious)
\subsection{Congruence Rules}
We can go into functions. This strategy is non-deterministic (will
this terminate? Yes, but it is not obvious how to prove it. This
is a metatheoretic property)
\begin{prooftree}
	\AXC{$M \implies M'$}
	\UIC{$fst \ M \implies fst \ M'$}
\end{prooftree}
\begin{prooftree}
	\AXC{$M \implies M'$}
	\UIC{$snd \ M \implies snd \ M'$}
\end{prooftree}
\begin{prooftree}
	\AXC{$M \implies M'$}
	\UIC{$M \ N \implies M' \ N$}
\end{prooftree}
\begin{prooftree}
	\AXC{$N \implies N'$}
	\UIC{$M \ N \implies M \ N'$}
\end{prooftree}
\begin{prooftree}
	\AXC{$M \implies M'$}
	\UIC{$\lambda x:A.M \implies \lambda x : A.M'$}
\end{prooftree}
\paragraph{Syntactic Equality} is important because we want to
introduce substitution.
\\\begin{tabular}{l l}
	$\lambda x.x = \lambda y.y$ & \text{(the name of a bound var
		does not matter)}
	\\ $\lambda x . \lambda y. x \neq \lambda x . \lambda y . y$
	\\ $\lambda x. \lambda y. x = \lambda x' . \lambda y . x'$ & These are the same because $x$ has the same binding site as $x'$
\end{tabular}
\\
Terms that only differ in the names of the bound variables are
considered equal. This is defined as
$\alpha$-renaming. Capture-avoiding substitution.

Note in the following expression, $x$ is new (``fresh''). We
cannot have two variables with the same name, if this was the
case, we'd have to rename $x$.

\begin{prooftree}
	\AXC{$\Gamma, x: A \vdash M : B$}
	\UIC{$\Gamma \vdash \lambda x : A . M : A \supset B$}
\end{prooftree}

Otherwise a rule such as the following would not give you
a unique type.
\begin{prooftree}
	\AXC{$x:A \in \Gamma$}
	\UIC{$\Gamma \vdash x : A$}
\end{prooftree}
\paragraph{Example of substitution} What does this mean?
\\ $[u/w] (\lambda u.w u) \neq \lambda u. u u$
\\ You cannot introduce a new variable with the same name as an
existing one, this will have completely different meaning than you
intended.
\\ Solution: $[u/w](\lambda u. w
	u)\stackrel{\alpha}{=}[u/w](\lambda u'. w u') = \lambda u'. u u'$

Let's assume that $u : T \supset A$.
\\ $[u/w](\underbrace{\lambda u : T. \ w \ u}_{\text{well-typed, $T
			\supset A$}}) = \lambda u : T. \ \underline{u} \ u$? This is
ill-typed!
\subsection{Restatement of Definitions Using Context}
\paragraph{Weakening} If $\Gamma \vdash M:A$ then $\Gamma, \Gamma'
	\vdash M:A$
\paragraph{Substitution} If $\Gamma, x : A , \Gamma' \vdash M : B$
and $\Gamma \vdash N : A$ then $\Gamma, \Gamma' \vdash [N/x] M : B$

How do we prove this? Proof by structural on $\Gamma, x: A,
	\Gamma' \vdash M : B$

First we must consider each rule that could have been used to derive
$M : B$.

Base case would be T, trivially true because there is nothing to
substitute.

\subparagraph{Definition of substitution}
~\\$[N/x]M = M'$, $[N/x] x = N$. Replace the ``free'' occurence of
$x$ in $M$ with $N$

	\subparagraph{Case}
	\AXC{$\mathcal{D}'$}
	\noLine
	\UIC{$\Gamma, x:A, \Gamma' \vdash M : C \land D$}
	\RL{$\land$ E$_l$}
	\UIC{$\Gamma, x:A,\Gamma' \vdash fst\ M : C$}
	\DP
	\\ $\Gamma, \Gamma ' \vdash [N/x] M : C\land D$ by IH
	\\ $\Gamma, \Gamma ' \vdash fst\ ([N/x]M) : C$ by $\land$E$_l$
	\\$\Gamma, \Gamma' \vdash [N/x](fst \ M) : C$ by definition of substitution
\subparagraph{Case}
\AXC{$\mathcal{D}_1$}
\noLine
\UIC{$\Gamma, x:A, \Gamma' \vdash M_1 : D \supset C $}

\AXC{$\mathcal{D}_2$}
\noLine
\UIC{$\Gamma, x:A, \Gamma' \vdash M_2 : D$}
\RL{$\supset$ E}
\BIC{$\Gamma, x:A,\Gamma' \vdash M_1 \ M_2 : C$}
\DP
\\ $\Gamma, \Gamma ' \vdash [N/x] M_1 : D \supset C$ by IH ($\mathcal{D}_1$)
\\ $\Gamma, \Gamma ' \vdash [N/x] M_2 : D$ by IH ($\mathcal{D}_2$)
\\$\Gamma, \Gamma' \vdash [N/x]M_1 \ [N/x]M_2 : C$ by $\supset$ E
	\\ $\Gamma, \Gamma' \vdash [N/x](M_1\ M_2) : C$

	The more interesting case is with variables:
	\subparagraph{Case}
	\AXC{$x: A \in (\Gamma, x : A, \Gamma')$}

	\UIC{$\Gamma, x : A, \Gamma' \vdash x : A$}
	\DP
	\\ $\Gamma \vdash N:A$ by assumption
	\\ $\Gamma, \Gamma' \vdash N : A$ by weakening
	\\ $\Gamma, \Gamma' \vdash [N/x]x : A$ by substitution definition
	\subparagraph{Case}
	\AXC{$y: B \in (\Gamma, x : A, \Gamma')$}
	\AXC{$x \neq y$}

	\BIC{$\Gamma, x : A, \Gamma' \vdash y : B$}
	\DP
	\\ $y:B \in (\Gamma, \Gamma')$
	\\ $\Gamma, \Gamma' \vdash y : B$ by variable
	\subparagraph{Case}
	\AXC{$\Gamma, x : A, \Gamma', y:B \vdash M:C$}

	\UIC{$\Gamma, x : A, \Gamma' \vdash \lambda y : B. M:B\supset C$}
	\DP
	\\ $\Gamma, \Gamma', y:B \vdash [N/x] M:C$ by IH.
	\\ $\Gamma, \Gamma', \lambda y : B . [N/x] M: B \supset C$ by $\supset$ I
	\\ $\Gamma \vdash N : A$ by assumption (i.e any var in $N$ is in
$\Gamma$). $y$ does not occur in $N$
	\\ $\Gamma, \Gamma ' \vdash [N/x] (\lambda y:B.M) : B \supset C$
	by substitution definition
	\section{01/24/19}
	\subsection{More on Proof Terms}
	Last class we saw:
	\\ Prop/Types $A,B:= T \mid \perp \mid A \land B \mid A \supset B
\mid A \lor B$
	\\ Terms $M,N := \langle  \rangle \mid abort^c \ M \mid \langle
M,N \rangle \mid fst\ M \mid snd \ M \mid \lambda x . A . M \mid M
\ N \mid inl^B \ M \mid inr^A \ B \mid (case \ M \ of \ inl \ x
\implies N_1 \mid inr\ y \implies N_2)$

	We can think of $M:A$ iff $A$ true.
	\paragraph{Warm-up}
	\begin{center}
		\begin{tabular}{l l}
			\textbf{Program} & \textbf{Proposition}
			\\ $\lambda x : A . \lambda y: B. \langle x,y \rangle$ & $A \supset B \supset (A \land B)$
			\\ $\lambda x : A \supset B  \land B \supset C.$ & $(A \supset B \land B \supset C) \supset A \supset C$
			\\ ~\hspace{5 pt} $\lambda y: A.(snd\ x)\underbrace{(\underbrace{(fst\ x)}_{A \supset B} y)}_{B}$
			\\ $\lambda x : A \lor B. \lambda y: C.$& $(A \lor B) \supset C \supset (B \lor A) \land C$
			\\ ~\hspace{5 pt} $\langle case \ of \ inl \ a \implies inr\ a \mid inr\ b \implies inl\ b,y  \rangle$
		\end{tabular}
	\end{center}
	\paragraph{Reminder}
	\begin{tabular}{l l}
		Prop & Type
		\\ $T$ & unit
		\\ $A \land B$ & $A * B$
		\\ $A \supset B$ & $A \rightarrow B$
		\\ $ A \lor B$ & $A + B$
	\end{tabular}
	The $+$ is usually hidden in programming languages,
	i.e. \texttt{type int\_or\_string = Int of int | Str of string}
	is actually \texttt{Int + String}.
	\begin{center}
		\begin{tabular}{l l}
			\textbf{Proposition} & \textbf{Program}
			\\ $A \supset A$ (has many programs) & $\lambda x:A.x$ \hspace{10 pt}normal/``canonical form''
			\\ Programs on the right are syntactically different & $\lambda x : A . (\lambda y: A . y) x$
			\\ & $\lambda x : A . fst ((\lambda y:A \land A . y) \langle x,x \rangle)$
		\end{tabular}
	\end{center}
	We hope that all of the functions on the right can reduce to the
	normal form.

	If $\Gamma \vdash M : A$ and $M \implies M'$ then $\Gamma \vdash
M' : A$ \} Subject Reduction/Type Preservation

	By induction (case analysis) on $M \implies M'$
	\subparagraph{Case} $fst \langle M,N \rangle \implies M$
	\\\begin{tabular}{l l}
		$\Gamma \vdash fst\ \langle M,N \rangle : A$ & by assumption
		\\ $\Gamma \vdash \langle M,N \rangle : A \land B$ & by \underline{inversion} on
		$\land$ E$_l$
	\end{tabular}

	Note the inversion rule tells us:
	\begin{prooftree}
		\AXC{$M : A \land B$}
		\RL{$\land$ E$_l$}
		\UIC{$fst\ M : A$}
	\end{prooftree}
	Inversion Lemma: If $fst\ M : A$ then $M:A \land B$. This is
	obvious in this system because there is only one rule. If there
	was another rule that we could use, then we'd have to prove that
	it came from this inversion rule.
	\\\begin{tabular}{l l}
		$\Gamma \vdash M : A$ & by \underline{inversion} of $\land I$
	\end{tabular}

	The concept of \underline{inversion} is very important, we want to
	know where the term comes from.
	\subparagraph{Case} $(\lambda x : A.M) N \implies [N/x] M$
	\\\begin{tabular}{l l}
		$\Gamma \vdash (\lambda x : A . M) N : B$ & by assumption
		\\ $\Gamma \vdash \lambda x: A.M : A \supset B,\ \Gamma \vdash N :
		A$                                        & by inversion on $\supset$ E
		\\ $\Gamma, x : A \vdash M : B$ & by inversion on $\supset$ I
		\\ $\Gamma \vdash [N/x]M:B$ & by substitution lemma (on above line
		and $\Gamma \vdash N:A$)
	\end{tabular}
	\subparagraph{Case} $case\ (inl^B \ M) \ of \ inl\ x \implies N_1
\mid inr\ y \implies N_2 \implies [M/x] N_1$
	\\\begin{tabular}{l l}
		$\Gamma \vdash case\ (inl^B \ M) \ of \ inl\ x \implies N_1
		\mid inr\ y \implies N_2 : C $ & by assumption
		\\ $\Gamma \vdash inl^B \ M : A \lor B$ & by inversion $\lor$ E
		\\ $\Gamma, x:A \vdash N_1 : C$
		\\ $\Gamma, y:B \vdash N_2 : C$
		\\ $\Gamma \vdash M:A$ & by inversion $\lor$ I$_l$
		\\ $\Gamma \vdash [M/x]N_1 : C$ & by substitution
	\end{tabular}
	\subparagraph{Case} \AXC{$M_1 \implies M'$}
	\UIC{$M_1 \ M_2 \implies M_1' M_2$}
	\DP
	\\
	\begin{tabular}{l l}
		$\Gamma \vdash M_1 \ M_2 : B$ & by assumption
		\\ $\Gamma \vdash M_1 : A \supset B$ and $\Gamma \vdash M_2 : A$ & by inversion $\supset$E
		\\ $\Gamma \vdash M_1' : A \supset B$ & by IH
		\\ $\Gamma \vdash M_1'\ M_1 : B$ & by $\supset$ E
	\end{tabular}
	The last step is forward reasoning instead of backward reasoning
	with inversions. Basically show what your case gives you and
	then apply IH to get what you want.
	\subparagraph{Case}
	\AXC{$M \implies M'$}
	\UIC{$\lambda x : A.M \implies \lambda x: A.M'$}
	\DP
	\\\begin{tabular}{l l}
		$\Gamma \vdash \lambda x : A . M : A \supset B$ & by assumption
		\\ $\Gamma, x : A \vdash M:B$ & by inversion on $\supset$ I
		\\ $\Gamma, x:A \vdash M' : B$ & by IH
		\\ $\Gamma \vdash \lambda x : A . M' : A \supset B$ & by $\supset$ I
	\end{tabular}

	Note that in trying to reduce $fst\ ((\lambda y:A \land A. y)
\langle x,x \rangle)$, we will need to step twice:
	\\ $\implies \lambda x : A . fst \langle x,x \rangle$
	\\ $\implies \lambda x : A . x$
	\\ But so far we are only stepping once.
	\paragraph{Can we prove the opposite?}
	If $\Gamma \vdash M' : A$ and $M \implies M'$ then $\Gamma
\vdash M : A$
	\subparagraph{Case} $fst \langle M,N \rangle \implies M$
	\\\begin{tabular}{l l}
		$\Gamma \vdash M :A$ & by assumption
		\\ $\Gamma \vdash N : B$ & How to show this?
		\\ $\Gamma \vdash \langle M,N \rangle : A \land B$
		\\ $\Gamma \vdash fst \ \langle M,N \rangle : A$ & To show
	\end{tabular}
	\\        Cannot prove this syntactically right now.
	\paragraph{Multi Step} Want to step multiple times. $M
\implies^* M'$, meaning $M$ steps in more than one step.
	\begin{prooftree}
		\AXC{}
		\RL{refl(ectivity)}
		\UIC{$M \implies^* M$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$M \implies^* K$}
		\AXC{$K \implies^* N$}
		\RL{Trans(itivity)}
		\BIC{$M \implies^* N$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$M \implies N$}
		\RL{one-step}
		\UIC{$M \implies^* N$}
	\end{prooftree}
	\subsection{Normal Form}
	What is a normal form when no reduction is possible anymore?
	\\ $\lambda :A \supset B.\lambda y : A . x \ y$ is a normal
	form
	\\ So is $\lambda x : (A \supset A)\supset C . x \underbrace{(\lambda y: A
	. y)}_{A \supset A}$
	\\ Basically, you can no longer reduce the expression.
	\paragraph{Normal Form} $m,n : = \lambda x:A.m \mid r$
	\paragraph{Neutral Form} $r : = x \mid r \ m \mid fst\ r \mid
snd\ r$
	\paragraph{Questions}
	\begin{enumerate}
		\item Can we always reach a normal form? (Does reduction
		      terminate?)
		\item Can we change the proof that correspond to the normal
		      forms? ``Normal Proof'' (without any detours)
		\item Is there a unique normal form that can be computed?
		      \\ If $M \implies^* N_1$ and $M \implies^* N_2$ then $N_1 = N_2$
	\end{enumerate}
	Will look at 1 and 2 before the midterm.
	\section{01/29/19}
	\subsection{First-order Logic}
	Reason about domains (nat, list, trees, programs, \ldots)

	How to reason in \underline{general}
	$$\forall x : \underbrace{\tau}_{\text{domain}} : A(x)\ true$$

	\underline{For all} elements in domain $\tau$, $A(x)$ is true.
	\begin{align*}
		 & \forall x : nat\ even(x) \supset \neg odd(x)
		\\ & \forall x : \tau:\forall y:\tau P(x) \supset P(y)
		\\ & (\forall x: \tau . P(x)) \supset \exists x:\tau. P(x)
	\end{align*}
	We define truth of a proposition for all possible domains.
	\paragraph{Well-Formedness:} $A$ wf
	\begin{prooftree}
		\AXC{$\tau$ type ($\tau$ itself is wf)}
		\AXC{}
		\UIC{$x : \tau$}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$A(x)$ wf}
		\BIC{$\forall x : \tau. A(x)$ wf}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$t_1:\tau$}
		\AXC{\ldots}
		\AXC{$t_n:\tau$}
		\TIC{$P(t_1,\ldots,t_n)$ wf}
	\end{prooftree}
$\forall x: nat \ even \ y \supset even (x)$, this is not well
	formed!

	What is a type? What are its elements?

	\begin{tabular}{l l l}
		nat type & \AXC{}\UIC{$z$:nat}\DP & \AXC{$n$:nat}\UIC{$succ\ n$:nat}\DP
		\\ nat\_list type & \AXC{}\UIC{$nil$:nat\_list}\DP & \AXC{$n$:nat}\AXC{$t$:nat\_list}\BIC{$cons(n,t)$:nat\_list}\DP
	\end{tabular}

	Prop. $A,B:= T \mid \perp \mid A \land B \mid \forall
x:\tau. A(x)$
	\\ Terms $t:= x \mid f(t_1,\ldots,t_n)$
	\\ Context $\Gamma := \cdot \mid \Gamma, u : A \mid \Gamma, a
: \tau$
	\paragraph{Introduction} We know what it means for something
	to be well formed, how do we show it? How do we introduce it?
	We could prove the predicate $A(x)$ for all $x$, but what if
	our domain is infinite? Often we may not even know much about
	our domain, so we can't prove it for each element either.
	\begin{prooftree}
		\AXC{}
		\UIC{$a:\tau$}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$A(a)$ true}
		\RL{$\forall $I$^a$ ($a$ is a parameter)}
		\UIC{$\forall x:\tau. A(x)$ true}
	\end{prooftree}
	This satisfies everything in $\tau$ because $a$ is
	generic/new, could not exist before in the proof.

	This rule is true whether you have something in $\tau$ or not,
	if it's impossible to get something from $\tau$, everything in
$\tau$ still satisfies $A(x)$ true.
	\paragraph{Elimination} Now that we have the information, what
	can we do with it?
	\begin{prooftree}
		\AXC{$\forall x:\tau. A(x)$ true}
		\AXC{$t:\tau$}
		\RL{$\forall$ E}
		\BIC{$A(t)$ true}
	\end{prooftree}
	We have to show that there is a $t$ of type $\tau$. This is
	similar to conjunction.
	\paragraph{Example}
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$\forall x : \tau. A(x) \land B(x)$ true}

		\AXC{}
		\RL{}
		\UIC{$a : \tau$}

		\RL{$\forall$ E}
		\BIC{$A(a)\land B(a)$ true}
		\RL{$\land$ E$_l$}
		\UIC{$A(a)$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall x : \tau . A(x)$}


		\AXC{}
		\RL{u}
		\UIC{$\forall x : \tau. A(x) \land B(x)$ true}
		\AXC{}
		\RL{}
		\UIC{$b : \tau$}

		\RL{$\forall$ E}
		\BIC{$A(b)\land B(b)$ true}
		\RL{$\land$ E$_r$}
		\UIC{$A(a)$ true}
		\RL{$\forall$ I$^b$}
		\UIC{$\forall x : \tau . B(x)$}

		\RL{$\land$ I}
		\BIC{($(\forall x : \tau . A(x)) \land (\forall x : \tau
				. B(x))$ true)}
		\RL{$\supset$I$^u$}
		\UIC{$(\forall x : \tau . A(x) \land B(x)) \supset ((\forall
				x : \tau.A(x)) \land (\forall x : \tau. B(x)))$ true}
	\end{prooftree}
	The following proof is \underline{invalid}! $a$ is not fresh
	and we cannot prove $\forall x:\tau .\forall y:\tau
. P(x)\supset P(y)$ true (it doesn't make sense after all).
	\begin{prooftree}
		\AXC{$P(a) \supset P(a)$}
		\RL{$\forall$I$^a \times$}
		\UIC{$\forall y:\tau . P(a) \supset P(y)$}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall x : \tau. \forall y : \tau P(x) \supset P(y)$ true}
	\end{prooftree}
	\paragraph{Overloaded functions}
	\begin{prooftree}
		\AXC{}
		\UIC{$a:\tau$}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$M:A(a)$ true}
		\RL{$\forall $I$^a$ ($a$ is a parameter)}
		\UIC{$\lambda a : \tau . M : \forall x:\tau. A(x)$ true}
	\end{prooftree}
$\lambda a$ is an overloaded function here.
	\begin{prooftree}
		\AXC{$M:\forall x:\tau. A(x)$ true}
		\AXC{$t:\tau$}
		\RL{$\forall$ E}
		\BIC{$M\ t : A(t)$ true}
	\end{prooftree}
	\paragraph{Types and Propositions with Quantifiers}
	\begin{tabular}{c c}
		Prop. & Types
		\\ T & unit
		\\ $A \land B$ & $A * B$
		\\ $A \lor B$ & $A + B$
		\\ $A \supset B$ & $A \to B$
		\\ $\forall x : \tau . A(x)$ & $\underbrace{\Pi x:\tau. A(x)}_{\text{dependent type ``indexed''}}$
	\end{tabular}\\
$\Pi n : nat$ rev:$'\alpha$ list (n) $\to 'a $ list(n)
	\paragraph{Local Soundness}
	\begin{center}
		\AXC{}
		\RL{a}
		\UIC{$a:\tau$}
		\noLine
		\UIC{$\mathcal{D}$}
		\noLine
		\UIC{$A(a)$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall x : \tau . A(x)$ true}

		\AXC{$\mathcal{E}$}
		\noLine
		\UIC{$t:\tau$}
		\RL{$\forall$ E}
		\BIC{$A(t)$ true}
		\DP
		$\implies$
		\begin{tabular}{c}
			$\mathcal{E}$
			\\$[t / a]\mathcal{D}$
				\\ $A(t)$ true
		\end{tabular}
	\end{center}
	Sometimes we omit $\mathcal{E}$ from our proof tree and
	implication (as it is obvious there's a derivation for
$t:\tau$).

	Substitution Lemma (2nd part):
	If $\Gamma, a:\tau, \Gamma'\vdash A(a)$ true and $\Gamma
\vdash t:\tau$ then $\Gamma,[t/a]\Gamma' \vdash A(t)$ true
	\\ $(\lambda x : \tau . M) t \stackrel{\beta}{\implies} [t/x]M$

	\paragraph{Local Completeness}
	\begin{center}
		\begin{tabular}{c}
			$\mathcal{D}$
			\\ $\forall x : \tau . A(x)$ true
		\end{tabular}
		$\implies$
		\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$\forall x : \tau . A(x)$ true}
		\AXC{}
		\RL{}
		\UIC{$a : \tau$}
		\RL{$\forall$ E}
		\BIC{$A(a)$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall x : \tau. A(x)$ true}
		\DP
	\end{center}
	Can also expand local completeness:
	\begin{center}
		\begin{tabular}{c}
			$\mathcal{D}$
			\\ $\forall x : \tau . A(x)$ true
		\end{tabular}
		$\implies$
		\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$M:\forall x : \tau . A(x)$ true}
		\AXC{}
		\RL{}
		\UIC{$a : \tau$}
		\RL{$\forall$ E}
		\BIC{$M\ a: A(a)$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\lambda a : \tau . M\ a:\forall x : \tau. A(x)$ true}
		\DP
	\end{center}
	$$M : \forall x : \tau . A(x) \stackrel{\eta}{\implies} \lambda
		x : \tau . M \ x$$
	Expansion
	$$M : A \supset B \implies \lambda x: A . M \ x$$

	Existential quantifier:

	\paragraph{Well-formedness: } $A$ wf
	\begin{prooftree}
		\AXC{}
		\RL{}
		\UIC{$x:\tau$}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$A(x)$ wf}
		\UIC{$\exists x : \tau . A(x)$ wf}
	\end{prooftree}
	Truth: $A$ true
	\begin{prooftree}
		\AXC{$A(t)$ true}
		\AXC{$t:\tau$}
		\RL{$\exists$ I}
		\BIC{$\exists x : \tau . A(x)$ true}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\exists x : \tau . A(x)$ true}
		\AXC{}
		\RL{u}
		\UIC{$A(a)$ true}

		\AXC{}
		\RL{}
		\UIC{$a:\tau$}

		\noLine
		\BIC{\vdots}
		\noLine
		\UIC{$C$ true}

		\RL{$\exists$ E$^{a,u}$}
		\BIC{$C$ true}
	\end{prooftree}
	Note that the $a$ in $A(a)$ is the same as in $a:\tau$. This
	is similar to disjunction.
	\begin{prooftree}
		\AXC{$A \lor B$}
		\AXC{}
		\RL{}
		\UIC{$A$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$C$ true}
		\AXC{}
		\RL{}
		\UIC{$B$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$C$ true}
		\TIC{$C$ true}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\forall x \in \{r,b,g\}. A(x)$}
		\AXC{}
		\RL{}
		\UIC{$A(r)$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$C$ true}

		\AXC{}
		\RL{}
		\UIC{$A(b)$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$C$ true}

		\AXC{}
		\RL{}
		\UIC{$A(c)$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$C$ true}

		\QIC{$C$ true}
	\end{prooftree}
	\paragraph{Another FOL Example}
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$A(a)$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$A(a) \supset A(a)$ true}

		\AXC{}
		\RL{}
		\UIC{$a:\tau$}

		\BIC{$\exists y : \tau A(a) \supset A(y)$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall x : \tau \exists y : \tau . A(x) \supset A(y)$
			true}
	\end{prooftree}
	The following cannot be proved in constructive logic (in
	classical logic it is not a problem):
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$\forall x : \tau . A(x)$ true}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\exists x : \tau . P(x)$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$(\forall x : \tau . P(x) \supset (\exists x : \tau
				P(x)))$ true}
	\end{prooftree}

	If we add an additional assumption (prove the statement with
$\tau$ not being empty), we can prove it:
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$\forall x : \tau . A(x)$ true}

		\AXC{}
		\RL{}
		\UIC{$a : \tau$}

		\BIC{$P(a)$ true}

		\AXC{}
		\RL{}
		\UIC{$a : \tau$}

		\BIC{$\exists x : \tau . P(x)$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$(\forall x : \tau . P(x) \supset (\exists x : \tau
				P(x)))$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\forall y:\tau ((\forall x : \tau . P(x) \supset
				(\exists x : \tau P(x))))$ true}
	\end{prooftree}
	\section{01/31/19}
	\subsection{More on First-order Logic}
	Reminder:
	\\Prop $A,B := \ldots \mid \forall x : \tau . A(x) \mid \exists x
: \tau . A(x)$
	\\ Terms $t,s := x \mid f(t_1,\ldots,t_n)$
	\begin{center}
		\AXC{}
		\UIC{$a:\tau$}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$A(a)$ true}
		\RL{$\forall $I$^a$}
		\UIC{$\forall x:\tau. A(x)$ true}
		\DP
		~
		\AXC{$\forall x:\tau. A(x)$ true}
		\AXC{$t:\tau$}
		\RL{$\forall$ E}
		\BIC{$A(t)$ true}
		\DP
	\end{center}
	\begin{center}
		\AXC{}
		\UIC{nat type}
		\DP
		~
		\AXC{}
		\RL{z\_n}
		\UIC{$Z$ : nat}
		\DP
		~
		\AXC{$n$ : nat}
		\RL{s\_n}
		\UIC{$s\ n $ : nat}
		\DP
	\end{center}
	\begin{center}
		\AXC{$A(t)$ true}
		\AXC{$t:\tau$}
		\RL{$\exists$ I}
		\BIC{$\exists x : \tau . A(x)$ true}
		\DP
		~
		\AXC{$\exists x : \tau . A(x)$ true}
		%
		\AXC{}
		\RL{w}
		\UIC{$A(a)$ true}
		%
		\AXC{}
		\RL{}
		\UIC{$a:\tau$}
		\noLine
		\BIC{\vdots}
		\noLine
		\UIC{$C$ true}
		%
		\RL{$\exists$ E$^{w,a}$}
		\BIC{$C$ true}
		\DP
	\end{center}
	What can we do with the existential quantifier?
	\begin{flalign*}
		&A(t) \hat{=} [t/x]A(x)&
		\\ &even\ z \supset odd(s\ z)
		\\ &\exists x:nat.even\ x \supset odd (s \ x)
		% \\ \exists x:nat.even\ x \supset odd(s\ z)
	\end{flalign*}
	\paragraph{Examples}
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$\exists x:\tau . \neg A(x)$ true}

		\AXC{}
		\RL{v}
		\UIC{$\neg A(a)$}

		\AXC{}
		\RL{w}
		\UIC{$\forall x : \tau . A(x)$ true}

		\AXC{}
		\RL{}
		\UIC{$a:\tau$}
		\RL{$\exists$ I}
		\BIC{$A(a)$ true}

		\RL{$\supset$ E}
		\BIC{$\perp$}

		\RL{$\exists$ E$^{v,a}$}
		\BIC{$\perp$}

		\RL{$\supset$ I$^w$}
		\UIC{$\neg \forall x : \tau . A(x)$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$(\exists x : \tau. \neg A(x)) \supset \neg (\forall
				x:\tau . A(x))$ true}
	\end{prooftree}

	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$\exists x:nat. A(s\ x)$ true}

		\AXC{}
		\RL{w}
		\UIC{$A(s\ a)$}

		\AXC{}
		\RL{}
		\UIC{$a:nat$}
		\RL{$s\_n$}
		\UIC{$s\ a: nat$}

		\RL{$\exists$ I}
		\BIC{$\exists y : nat.A(y)$ true}

		\RL{$\exists$ E$^{w,a}$}
		\BIC{$\exists y : nat. A(y)$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$\exists x : nat. A (s \ x)\supset \exists y : nat
				. A(y)$ true}
	\end{prooftree}
	We now show local soundness and completeness for $\exists$:
	\paragraph{Local Soundness}
$\Gamma, u:A(a)$ true, $a:\tau \vdash C$ true
	\begin{center}
		\AXC{$\mathcal{E}_1$}
		\noLine
		\UIC{$A(t)$ true}

		\AXC{$\mathcal{E}_2$}
		\noLine
		\UIC{$t:\tau$}

		\RL{$\exists$ I}
		\BIC{$\exists x : \tau . A(x)$ true}

		\AXC{}
		\RL{u}
		\UIC{$A(a)$ true}

		\AXC{}
		\RL{}
		\UIC{$a:\tau$}

		\noLine
		\BIC{$\mathcal{D}^{u,a}$}
		\noLine
		\UIC{$C$ true}

		\RL{$\exists$ E$^{u,a}$}
		\BIC{$C$ true}
		\DP
		$\implies$
		\begin{tabular}{c}
			\\$[\mathcal{E}_1 / u]([t/a]\mathcal{D})$
				\\ $C$ true
		\end{tabular}
	\end{center}
	(By substitution lemmas, we use both here)
	\\ 1: If $\Gamma ,a : \tau, \Gamma' \vdash A$ true and
$\Gamma \vdash t:\tau$ then $\Gamma, [t/a]\Gamma' \vdash
[t/a] A$ true
	\\ 2: If $\Gamma, u: B$ true, $\Gamma' \vdash A$ true and
$\Gamma \vdash B$ true then $\Gamma, \Gamma' \vdash A$ true
	\paragraph{Local Completeness}
	\begin{center}
		\begin{tabular}{c}
			$\mathcal{D}$
			\\ $\exists x : \tau . A(x)$ true
		\end{tabular}
		$\implies$
		%
		\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$\exists x : \tau . A(x)$ true}
		%
		\AXC{}
		\RL{u}
		\UIC{$A(a)$}
		%
		\AXC{}
		\RL{}
		\UIC{$a:\tau$}
		%
		\RL{$\exists$ I}
		\BIC{$\exists x: \tau . A(x)$}
		\RL{$\exists$ E$^{u,a}$}
		\BIC{$\exists x : \tau . A(x)$ true}
		\DP
	\end{center}
	Note that completeness isn't always an elimination and then an
	introduction, however, soundness must always introduce and
	then eliminate the rule.
	\paragraph{Existential Rules with Terms}
	% Fix other existentials to have BIC like this
	\begin{center}
		\AXC{$M:A(t)$ true}
		\AXC{$t:\tau$}
		\RL{$\exists$ I}
		\BIC{$\langle M,t \rangle : \exists x : \tau . A(x)$ true}
		\DP
		~
		\AXC{$M:\exists x : \tau . A(x)$ true}
		\AXC{}
		\RL{w}
		\UIC{$w:A(a)$ true}
		%
		\AXC{}
		\RL{}
		\UIC{$a:\tau$}
		\noLine
		\BIC{\vdots}
		\noLine
		\UIC{$N:C$ true}
		%
		\RL{$\exists$ E$^{w,a}$}
		\BIC{$let\ \langle w,a \rangle = M\ in\ N: C$ true}
		\DP
	\end{center}
	Soundness:

	\begin{center}
		\AXC{$\mathcal{E}_1$}
		\noLine
		\UIC{$M:A(t)$ true}

		\AXC{$\mathcal{E}_1$}
		\noLine
		\UIC{$t:\tau$}

		\RL{$\exists$ I}
		\BIC{$\langle M,t \rangle: \exists x : \tau . A(x)$ true}

		\AXC{}
		\RL{u}
		\UIC{$A(a)$ true}

		\AXC{}
		\RL{e}
		\UIC{$a:\tau$}

		\noLine
		\BIC{$\mathcal{D}^{u,a}$}
		\noLine
		\UIC{$N:C$ true}

		\RL{$\exists$ E$^{u,a}$}
		\BIC{$let \ \langle u,a \rangle = \langle M,t \rangle\ in \ N: C$ true}
		\DP
		$\implies$
		\begin{tabular}{c}
			\\$[\mathcal{E}_1 / u]([t/a]\mathcal{D})$
				\\ $C$ true
		\end{tabular}
	\end{center}
$let \langle u,a \rangle=\langle M,t \rangle \ in \ N \implies
$
	\begin{tabular}{c}
		$[M/u,t/a]N$
		\\ $[M/u][t/a]N$
	\end{tabular}
	\paragraph{Choice:}
	\begin{enumerate}
		\item Build $=, \leq, \ldots$ on nats into the logic
		\item Define formulas that describe $=,\leq, even, odd,
			      \ldots$

		      Could add the following rules:
		      \begin{center}
			      \AXC{$n < s \ n$}
			      \DP
			      ~
			      \AXC{$a < b$}
			      \AXC{$b < c$}
			      \BIC{$a < c$}
			      \DP
		      \end{center}
		      \vspace{2 em}
		      \begin{center}
			      \AXC{$n < m$}
			      \UIC{$n < s \ m$}
			      \DP
			      ~
			      \AXC{$n < m$}
			      \RL{I$_s$}
			      \UIC{$s\ n < s \ m$}
			      \DP
			      ~
			      \AXC{}
			      \RL{I$_0$}
			      \UIC{$0 < s \ n$}
			      \DP
			      ~
			      \AXC{$m < 0$ true}
			      \UIC{$C$ true}
			      \DP
			      ~
			      \AXC{$s\ n < s\ m$}
			      \UIC{$n < m$}
		      \end{center}
		      Some of these rules are redundant, we only need the last
		      four rules.

		      Are the first two rules and the last four rules equivalent?
		      If we have both sets, is our language sound and complete?

		      There are many choices we make here, but if we look at I$_s$
		      and E$_s$, we can see that we are guided by the possibility
		      of introducing and eliminating.
	\end{enumerate}

	What if we build on instead of defining formulas?
	\begin{flalign*}
		& \forall n:nat. \ 0 < s\ n  &
		\intertext{ Could also call this
			$less(0,n)$, but we wrote it in infix notation}
		& \forall n:nat. \ n<m \supset s\ n < s\ m
		\\ & \forall n : nat. \ s \ n < s\ m \supset n < m
		\\ & \forall n : nat. \ m < 0 \supset \perp
	\end{flalign*}

	We can prove $\forall x . s\ x < s\ 0 \supset P(x)$ in both ways
	that we defined $<$. If we define new formulas, it makes our
	proofs more compact. However, adding new rules makes us unsure
	about whether our system is consistent, therefore requiring us
	to prove consistency again.

	\paragraph{Consistency:} $\nvdash \perp$ true, i.e. there is no
	way of proving $\perp$ in our system.

	\paragraph{Rules for governing equality for nats}
	\begin{center}
		\AXC{}
		\UIC{$0 = 0$}
		\DP
		~
		\AXC{$m=n$}
		\UIC{$s\ m = s\ n$}
		\DP
		~
		\AXC{$s\ m = s\ n$}
		\UIC{$m = n$}
		\DP
		~
		\AXC{$0 = s\ m$}
		\UIC{$C$ true}
		\DP
		~
		\AXC{$s\ m = 0$}
		\UIC{$C$ true}
		\DP
	\end{center}
	Third choice could be writing a program instead.
	\section{02/05/19}
	\paragraph{So Far:} First-order Logic (independent of a given
	domain) + domain (for example natural numbers)
	\begin{center}
		nat type
		\AXC{}
		\RL{nat I$_z$}
		\UIC{$z:$nat}
		\DP
		\AXC{$n:nat$}
		\RL{nat I$_{s}$}
		\UIC{$suc\ n : nat$}
		\DP
	\end{center}
	What are good elimination rules for nats? How to reason
	inductively about nats?
	\subsection{Relation/Predicates}
$n \leq m$
	\begin{center}
		\AXC{}
		\RL{le$_z$}
		\UIC{$z \leq$ n}
		\DP
		\AXC{$n \leq m$}
		\RL{le$_s$}
		\UIC{$suc\ n \leq suc\ m$}
		\DP
		\AXC{}
		\RL{refl}
		\UIC{$n=n$}
	\end{center}
	Can encode these rules as:
	\\ le$_z$: $\forall n : nat. z \leq n$
	\\ le$_s$: $\forall n:nat. \forall m. nat. n \leq m \supset
suc\ n \leq suc\ m$
	\\ $ref: \forall x : nat . x = x$
	\\ These rules are called the \underline{signature} $\mathcal{Y}$

	What do I want to prove about our domain?
	\begin{enumerate}
		\item $\forall x : nat . x \leq x$
		\item $\forall x : nat. \neg (x=z) \supset \exists y:
			      nat. suc\ y = x$
		\item $\forall x : nat . \forall y : nat. \forall w: nat, x
			      \leq y \land y \leq w \supset x \leq w$
	\end{enumerate}
	Can prove these via induction.
	\paragraph{Elimination Rule} Induction Rule
	\begin{prooftree}
		\AXC{$t:nat$}
		\AXC{$A(z)$ true}
		\AXC{}
		\RL{}
		\UIC{$n:nat$}
		\noLine
		\UIC{$\ddots$}
		\AXC{}
		\RL{ih}
		\UIC{$A(n)$ true}
		\noLine
		\UIC{\vdots}
		\noLine
		\BIC{$A(suc\ n)$ true}
		\RL{$nat$ E$^{n,ih}$}
		\TIC{$A(t)$ true}
	\end{prooftree}
	Generalization built-in: $A(42)$ true.

	Different way of writing the previous rule:
	\begin{prooftree}
		\AXC{$\Gamma \vdash t : nat$}
		\AXC{$\Gamma \vdash A(z)$ true}
		\AXC{$\Gamma,n:nat,ih:A(n)$ true $\vdash A(suc\ n)$ true}
		\RL{$nat$ E$^{n,ih}$}
		\TIC{$\Gamma \vdash A(t)$ true}
	\end{prooftree}
	\paragraph{Example}
	\begin{prooftree}
		\AXC{}
		\RL{}
		\UIC{$\mathcal{Y},a:nat \vdash a:nat$}

		\AXC{$\mathcal{D}_1$}
		\noLine
		\UIC{$\mathcal{Y},a:nat \vdash z \leq z $ true}

		\AXC{$\mathcal{D}_2$}
		\noLine
		\UIC{$\mathcal{Y}, a:nat, n:nat,$}
		\noLine
		\UIC{$ih: n \leq n \vdash suc\ n \leq suc\ n$}

		\RL{$nat$ E$^{n,ih}$}
		\TIC{$\mathcal{Y}, a:nat \vdash a \leq a$ true}
		\RL{$\forall$ I$^a$}
		\UIC{$\mathcal{Y} \vdash \forall x : nat. x \leq x$}
	\end{prooftree}
	(The proof for $\mathcal{D}_1$ may not be correct/missing some steps, to be fixed)
	\begin{center}
		$\mathcal{D}_1 =$
		\AXC{}
		\RL{le$_z$}
		\UIC{$\mathcal{Y}, n:nat \vdash z \leq n$}
		\AXC{}
		\RL{nat I$_z$}
		\UIC{$\mathcal{Y} \vdash z : nat$}
		\BIC{$\mathcal{Y} \vdash z \leq z$}
		\DP
	\end{center}

	Let $\mathcal{Y}' = \mathcal{Y}, a: nath, n:nat, ih:
n\leq n$
	\\$\mathcal{D}_2 =$
\begin{center}
	\AXC{}
	\RL{ih}
	\UIC{$\mathcal{Y} \vdash n \leq n$}
	\AXC{}
	\RL{le$_s$}
	\UIC{$\mathcal{Y}' \vdash \forall n : nat. \forall m :
			nat. n \leq m \supset suc\ n \leq suc \ m$}
	\AXC{}
	\RL{}
	\UIC{$\mathcal{Y}' \vdash n : nat$}
	\RL{$\forall E$(2x)}
	\BIC{$\mathcal{Y}' \vdash n \leq n \supset suc\ n \leq suc\
			n$}
	\RL{$\supset$ E}
	\BIC{$\mathcal{Y}' \vdash suc\ n \leq suc\ n$}
	\DP
\end{center}
\paragraph{Elimination Rule with Proof Terms}
\begin{prooftree}
	\AXC{$t:nat$}
	\AXC{$M_z:A(z)$ true}
	\AXC{}
	\RL{}
	\UIC{$n:nat$}
	\noLine
	\UIC{$\ddots$}
	\AXC{}
	\RL{ih}
	\UIC{$f\ n:A(n)$ true}
	\noLine
	\UIC{\vdots}
	\noLine
	\BIC{$M_s : A(suc\ n)$ true}
	\RL{$nat$ E$^{n,ih}$}
	\TIC{$rec(t, M_z, n, ih, M_s) : A(t)$ true}
\end{prooftree}
Maybe it would be nicer to write $rec(t, M_z, n, ih, M_s)$ as:
\\$rec\ t$ with $f\ z \to M_z \mid f (suc\ n) \to M_s$

	Writing our earlier example as a program:
	\\ $\lambda a : nat. rec\ a$ with $f\ z \to le_z\ z \mid f\
suc \ n \to (le_s\ n\ n) (f\ n)$
	\paragraph{Example}
	\begin{scprooftree}{0.75}
		\AXC{}
		\UIC{$\mathcal{Y}, a : nat \vdash a : nat$}

		\AXC{$\mathcal{D}_1$}
		\noLine
		\UIC{$\mathcal{Y} \vdash \neg (z = z) \supset \exists y:
				nat. \ suc\ y = z$}

		\AXC{$\mathcal{D}_2$}
		\noLine
		\UIC{$\mathcal{Y}, n : nat, ih = \ldots  \vdash \neg(suc\ n = z)
				\supset \exists y : nat. \ suc \ y = suc\ n$}

		\TIC{$\mathcal{Y}, a : nat \vdash \neg (a=z) \supset \exists
				y : nat.\ suc\ y = a$}
		\RL{$\forall$ I$^a$}
		\UIC{$\mathcal{Y} \vdash \forall x : nat. \neg (x=z) \supset
				\exists y : nat. \ suc\ y = x$}
	\end{scprooftree}
	\begin{center}
		$\mathcal{D}_1 = $
		\AXC{$\mathcal{Y}, u: \neg (z=z) \vdash \neg (z=z)$}
		%
		\AXC{}
		\RL{refl}
		\UIC{$\mathcal{Y} \vdash \forall x : nat. x=x$}
		\RL{$\forall$ E}
		\UIC{$\mathcal{Y} \vdash z = z$}
		%
		\RL{$\supset$ E}
		\BIC{$\perp$}
		\RL{$\perp$ E}
		\UIC{$\mathcal{Y}, u: \neg (z=z) \vdash \exists y:nat. suc\
				y = z$}
		\RL{$\supset$ I$^u$}
		\UIC{$\mathcal{Y} \vdash \neg (z = z) \supset \exists y :
				nat . suc\ y = z$}
		\DP
	\end{center}
	The above is like a proof by contradiction.
	\\ Let $\mathcal{Y}' = \mathcal{Y}, n: nat.ih:\ldots$
	\begin{center}
		$\mathcal{D}_2 =$
		\AXC{}
		\RL{}
		\UIC{$\mathcal{Y}' \vdash n : nat$}
		\UIC{$\mathcal{Y}' \vdash suc\ n : nat$}
		\AXC{}
		\RL{refl}
		\UIC{$\mathcal{Y}' \vdash \forall x :nat.x = x$}
		\AXC{}
		\RL{}
		\UIC{$\mathcal{Y}' \vdash n : nat$}
		\UIC{$\mathcal{Y}' \vdash suc\ n : nat$}
		\RL{$\forall$ E}
		\BIC{$\mathcal{Y}', u : \neg (suc\ n = z): suc\ n = suc\
				n$}
		\RL{$\exists$ I}
		\BIC{$\mathcal{Y}', u: \neg (suc\ n = z) \vdash \exists y:
				nat. suc\ y = suc\ n$}
		\UIC{$\mathcal{Y} \vdash \neg (suc\ n = z) \supset \exists
				y:nat. suc\ y = suc\ n$}
		\DP
	\end{center}
	This is a weird proof since it never uses its IH and really is
	just proof on the cases. What does this program do?

$\lambda a : nat. rec\ a $ with $f\ z \to  \lambda u: \neg
(z=z). abort (u\ (refl\ z)) \mid f\ (suc\ n)
\to \lambda u: \neg (suc\ n = z).\langle ref\ (suc\ n), n
\rangle$

	This is a provably correct predecessor function. If we erase
	``Proofs for equality'' from the above program, we get:
	\\ $\lambda a : nat. rec\ a$ with $f\ z \to \_ \mid f(suc\ n)
\to n$
	\\ This is what we call program extraction. Note in the $z$
	case the program is undefined (zero has no predecessor).

	How do we come up with reduction rules for these kind of
	recursers?
	\paragraph{Reduction Rule:}~
	\\
	\begin{tabular}{l l}
		$rec\ z$ with & $f\ z \to M_z$
		\\ &$ \mid f\ (suc\ n) \to M_s$
	\end{tabular}
$\to M_z$
	\\
	\begin{tabular}{l l}
		$rec\ (suc\ m)$ with & $f\ z \to M_z$
		\\ &$ \mid f\ (suc\ n) \to M_s$
	\end{tabular}
$\to [m/n,f_m/f_n]M_s$, where
	\\ $f_m = rec\ m$ with $f\ z \to M_z \mid f\ (suc\ n) \to M_s$
	\\ $f_n$ is a placeholder for the recursive call. Like in
	functional languages, we recurse here by ``pasting'' $f_m$
	when we look for the recursive call.
	\begin{prooftree}
		\AXC{$\Gamma \vdash t : nat$}
		\AXC{$\Gamma \vdash M_z : A(z)$}
		\AXC{$\Gamma, n : nat, f\ n : A(n) \vdash M_s : A (suc\ n)$}
		\TIC{$\Gamma \vdash rec\ t$ with $f\ z \to M_z \mid f\ (suc\
				n) \to M_s$ : $A(t)$}
	\end{prooftree}
	\section{02/07/19}
	\subsection{Normal Proof}
	Let's try and prove something basic directly:
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$A$ true}
		\RL{$\supset$ I$^v$}
		\UIC{$B \supset A$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$A \supset B \supset A$ true}
	\end{prooftree}
	(Here we omitted an unused assumption for $B$ being true).

	The proof term for this is: $\lambda u : A.\lambda v:B.u$, it's
	a program that will just ignore its second input.

	The following is another way to prove the same conjecture:
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$A$ true}

		\AXC{}
		\RL{v}
		\UIC{$B$ true}

		\RL{$\land$ I}
		\BIC{$A \land B$ true}
		\RL{$\land $ E$_l$}
		\UIC{$A$ true}
		\RL{$\supset$ I$^v$}
		\UIC{$B \supset A$ true}
		\RL{$\supset$ I$^u$}
		\UIC{$A \supset B \supset A$ true}
	\end{prooftree}
	The proof term for this is: $\lambda u:A.\lambda v : B
. \underline{fst \langle u,v \rangle}$. However, with our
	reduction rules, we know that we can reduce $fst \langle u,v
\rangle$ to $u$ and end up with the same proof term as before.
	\paragraph{What are normal proofs?}
	\begin{enumerate}
		\item Can we characterize normal proof terms?
		\item Can we describe normal derivations?
	\end{enumerate}
	\paragraph{Normal (proof) terms} $M := \lambda x : A . M \mid
\langle M,N \rangle \mid inl^A\ m \mid inr^B\ M \mid R$

	\paragraph{Neutral terms} $R := fst\ R \mid snd\ R\mid x \mid
R\ M$


	The basic idea is that we want to rule out terms like $\lambda
u : A.\lambda v : B . fst \langle u,v \rangle$.

	A \textbf{normal term} cannot be reduced further.
	\\\begin{tabular}{l l}
		$(\lambda x : A . M) \ N$ & $\implies [N/x]M$
		\\ $fst \langle M,N \rangle$ & $\implies M$
		\\ $snd \langle M,N \rangle$ & $\implies N$
		\\ $case\ (inl\ M)\ of \ inl\ x \to N_1 \mid inr\ y \to N_2$ & $\implies [M/x]N_1$
	\end{tabular}
	\paragraph{Examples}
	\begin{itemize}
		\item $\lambda x : A \land B.fst \ x$ (we can have $fst$, but
		      not on a pair directly, else it would reduce)
		\item $\lambda x : A \land (B \land C). snd\ (fst\ x)$
	\end{itemize}
	\paragraph{Normal Derivations}
	\begin{equation*}
		A \text{ true }
		\begin{cases}
			\Gamma^{\downarrow} \vdash M:A \uparrow & \text{There is a normal derivation}
			\\ \Gamma^{\downarrow} \vdash R: A \downarrow & \text{There is a neutral derivation}
		\end{cases}
	\end{equation*}
	Intuitively, $\uparrow$ means applying intro-rules bottom
	up (we have a proof for this), whereas $\downarrow$ means
	synthesizing information top
	down (from the assumptions).

$\Gamma^{\downarrow} = x_1:A_1\downarrow, \ldots, x_n : A_n
\downarrow$

	Note, the superscript for both Gammas is $\downarrow$
	because when you have an assumption all you can do is
	synthesize information from it.

	\paragraph{Rules}
	\begin{prooftree}
		\AXC{$x : A \downarrow$}
		\UIC{$\Gamma^{\downarrow} \vdash x : A \downarrow$}
	\end{prooftree}
	Generally, introduction rules are $\uparrow$.
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow}, x : A \downarrow \ \vdash M : B
				\uparrow$}
		\RL{$\supset$ I$^x$}
		\UIC{$\Gamma^{\downarrow} \vdash \lambda x. M : A \supset
				B \uparrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash M : A \uparrow$}
		\AXC{$\Gamma^{\downarrow} \vdash N : B \uparrow$}
		\RL{$\land \uparrow$}
		\BIC{$\Gamma^{\downarrow} \vdash \langle M,n \rangle : A
				\land B \uparrow$}
	\end{prooftree}
	When do we extract information? With the elimination rules.
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash R : A \land B
				\downarrow$}
		\UIC{$\Gamma^{\downarrow} \vdash fst\ R : A \downarrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash R : A \land B
				\downarrow$}
		\UIC{$\Gamma^{\downarrow} \vdash snd\ R : B \downarrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash R : A \supset B
				\downarrow$}
		\AXC{$\Gamma^{\downarrow} \vdash M : A \uparrow$}
		\BIC{$\Gamma^{\downarrow} \vdash R \ M : B \downarrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash M : A \uparrow$}
		\UIC{$\Gamma^{\downarrow} \vdash inl\ M : A \lor B \uparrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash R : A \lor B \downarrow$}
		\AXC{$\Gamma^{\downarrow} , x : A \downarrow \ \vdash N_1 :
				C \uparrow$}
		\AXC{$\Gamma^{\downarrow}, x : B \downarrow \ \vdash N_z :
				C \uparrow$}
		\TIC{$\Gamma^{\downarrow} \vdash case\ R \ of \ inl\ x \to
				N_1 \mid inr\ x \to N_2 : C \uparrow$}
	\end{prooftree}
	Here all the Cs can be $\downarrow$ or $\uparrow$, but for
	us it will be much simpler to have it as $\uparrow$.

	Sometimes we may need to go in the other direction. Here's
	the switch from going $\downarrow$ to $\uparrow$.
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash R : A \downarrow$}
		\RL{$\uparrow \downarrow$}
		\UIC{$\Gamma^{\downarrow} \vdash R : A \uparrow$}
	\end{prooftree}
	\paragraph{Example}
	\begin{prooftree}
		\AXC{}
		\UIC{$x: A \land (B\land C) \downarrow \ \vdash x : A \land
				(B \land C) \downarrow$}
		\UIC{$x: A \land (B\land C) \downarrow \ \vdash snd\ x : B \land C \downarrow$}
		\UIC{$x : A \land (B \land C) \downarrow \ \vdash B \downarrow$}
		\UIC{$x : A \land (B \land C) \downarrow \ \vdash B \uparrow$}
		\UIC{$\lambda x . fst (snd\ x) : (A \land (B \land C)) \supset B \uparrow$}
	\end{prooftree}
	For the examples we originally saw at the beginning of this
	lecture, if we try to annotate them:
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$A \downarrow$}
		\UIC{$A \uparrow$}
		\RL{$\supset$ I$^v$}
		\UIC{$B \supset A \uparrow$}
		\RL{$\supset$ I$^u$}
		\UIC{$A \supset B \supset A \uparrow$}
	\end{prooftree}
	\begin{prooftree}
		\AXC{}
		\UIC{$A \downarrow$}
		\UIC{$A \uparrow$}

		\AXC{}
		\UIC{$B \downarrow$}
		\UIC{$B \uparrow$}

		\RL{$\land$ I}
		\BIC{$A \land B \uparrow$}
		\RL{$\land $ E$_l \times$ \Lightning}
		\UIC{$A \uparrow$}
		\RL{$\supset$ I$^v$}
		\UIC{$B \supset A \uparrow$}
		\RL{$\supset$ I$^u$}
		\UIC{$A \supset B \supset A \uparrow$}
	\end{prooftree}
	This proof isn't normal and we wouldn't be able to derive it
	as we have no rule to go from $A \land B \uparrow$ to $A
\uparrow$, only $A \land B \downarrow$ to $A \downarrow$.
	\begin{prooftree}
		\AXC{}
		\UIC{$x : A \supset B\downarrow \ \vdash x : A \supset B \downarrow$}
		\UIC{$x : A \supset B\downarrow \ \vdash x : A \supset B \uparrow$}
		\UIC{$\lambda x : A \supset B. X:(A \supset B) \supset (A
				\supset B) \uparrow$}
	\end{prooftree}
	The proof terms aren't necessarily unique. Consider: $\lambda
x : A \supset B. \lambda y : A . x\ y$

	Terms are $\beta$-normal form (none of the reductions apply).
	\paragraph{Soundness} If $\Gamma^{\downarrow} \vdash M : A
\uparrow$ then $\Gamma \vdash M : A$.
	\\ If $\Gamma^{\downarrow} \vdash R:A \downarrow$ then $\Gamma
\vdash R : A$.

	This is a way for us to relate one proof system to another.

	\paragraph{Proof by mutual structural induction on  the first
		derivation}
	\subparagraph{Case:} $\mathcal{D} =$
	\AXC{$\mathcal{D}_0$}
	\noLine
	\UIC{$\Gamma^{\downarrow} \vdash R : A \lor B \downarrow$}
	\AXC{$\mathcal{D}_1$}
	\noLine
	\UIC{$\Gamma^{\downarrow} , x : A \downarrow \ \vdash N_1 :
			C \uparrow$}
	\AXC{$\mathcal{D}_2$}
	\noLine
	\UIC{$\Gamma^{\downarrow}, x : B \downarrow \ \vdash N_z :
			C \uparrow$}
	\TIC{$\Gamma^{\downarrow} \vdash case\ R \ of \ inl\ x \to
			N_1 \mid inr\ x \to N_2 : C \uparrow$}
	\DP
	\\
	\begin{tabular}{l l}
		$\Gamma \vdash R : A \lor B$ & by IH(2) using $\mathcal{D}_0$
		\\ $\Gamma, x : A \vdash N_1 : C$ & by IH(1) using $\mathcal{D}_1$
		\\ $\Gamma, y : B \vdash N_2 : C$ & by IH(1) using $\mathcal{D}_2$
		\\ $\Gamma \vdash case\ R \ of \ inl\ x \to N_1 \mid inr\ y \to N_2 : C$ & by $\lor E^{x,y}$
	\end{tabular}
	\\This is a good example because we had to use both inductive
	hypotheses. We can think of this as writing mutually recursive
	functions, one that deals with normal derivations, one that
	deals with neutral derivations.
	\subparagraph{Case:} $\mathcal{D}=$
	\AXC{$\mathcal{D'}$}\noLine\UIC{$\Gamma^{\downarrow}\vdash R:A
			\downarrow$}\UIC{$\Gamma^{\downarrow} \vdash R : A
			\uparrow$}\DP
	\\ $\Gamma \vdash R : A$ by IH(2) using $\mathcal{D}'$
	\paragraph{Completeness} Our new system isn't complete
	(because we designed it that way, we cannot represent
	everything). To make this complete, we'd have to be able to go
	in both directions:
	\begin{prooftree}
		\AXC{$\Gamma^{\downarrow} \vdash M : A \uparrow$}
		\UIC{$\Gamma^{\downarrow} \vdash (M:A):A \downarrow$}
	\end{prooftree}
	The ``offending'' rule which makes proofs non-normal, however
	it allows us to prove completeness.

	Completeness: If $\Gamma \vdash M : A$ then
$\Gamma^{\downarrow} \vdash M : A \uparrow$ and
$\Gamma^{\downarrow} \vdash M : A \downarrow$

	\paragraph{Proof by induction on $\Gamma \vdash M : A$}
	\subparagraph{Case:} \AXC{$\Gamma \vdash A \supset
			B$}\AXC{$\Gamma \vdash A$}\RL{$\supset$ E}\BIC{$\Gamma
			\vdash B$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma \vdash A \supset B \downarrow$ & by IH($\mathcal{D}_1$)
		\\ $\Gamma \vdash A \uparrow$ & by IH($\mathcal{D}_2$)
		\\ $\Gamma \vdash B \downarrow$ & by rule $\supset$ E$\downarrow$
		\\ $\Gamma \vdash B \uparrow$ & $\uparrow \downarrow$
	\end{tabular}

	Why introduce a new ``offending'' rule to show completeness
	for a new system? Say we want to prove consistency of $\Gamma
\vdash A$ true.

	We have $\Gamma \vdash A$ true in one system and
	\\ $\Gamma \vdash A \uparrow, \Gamma \vdash A \downarrow$,
	\AXC{$\Gamma \vdash A \uparrow$}\UIC{$\Gamma \vdash A
			\downarrow$}\DP. But we cannot tell if $\perp$ can be proven
	from here.

	We will see that using the rules $\Gamma \vdash A \uparrow,
\Gamma \vdash A \downarrow$, we will develop Sequent Calculus
	(directed, easy to see that $\perp$ cannot be proven unless
	you have assumptions). We will then introduce the Cut-Rule,
	which can be proven admissible, not necessary, like the
	substitution rule. The Cut-Rule corresponds to the \AXC{$\Gamma \vdash A \uparrow$}\UIC{$\Gamma \vdash A
			\downarrow$}\DP and Sequent Calculus with the Cut-Rule will
	be complete, however because the Cut-Rule is admissible/not
	needed, we can remove it.

	Note: we say the proof term $M$ for completeness is conserved,
	but that is not exactly true, we may add additional
	annotations and so we say:

	Completeness: If $\Gamma \vdash (M)^{-} : A$ then
$\Gamma^{\downarrow} \vdash M : A \uparrow$ and
$\Gamma^{\downarrow} \vdash M : A \downarrow$
	\section{02/12/19}
	Going to go over how we show two proof systems are
	equivalent. Last class we saw:
	\\
	\begin{tabular}{l l}
		\textbf{Natural Deduction} & \textbf{Normal Natural Deduction}
		\\ $\Gamma \vdash M : A$ & $\Gamma^{\downarrow} \vdash m : A\uparrow$
		\\ & $\Gamma^{\downarrow} \vdash r : A \downarrow$
		\\ Term $M : = x \mid \lambda x : A . M \mid$ & Normal terms $m : = \lambda x . m \mid \langle m_1, m_2 \rangle \mid r$
		\\ $M_1\ M_2 \mid \langle M_1, M_2 \rangle \mid fst\ M \mid snd\ M$& Neutral terms $r : = x \mid fst\ r \mid snd\ r \mid r \ m \mid \underline{(m : A)}$
	\end{tabular}
	\\Note that showing normal natural $\to$ natural was easy,
	however to go the other way we had to introduce a new rule
	\underline{$(m : A)$}, which was:
	\begin{prooftree}
		\AXC{$\Gamma \vdash m : A \uparrow$}
		\UIC{$\Gamma \vdash (m:A) : A \downarrow$}
	\end{prooftree}

	\paragraph{Recall HW1} $m:= x \mid \lambda x . m \mid m_1\ m_2
\mid \langle m_1, m_2 \rangle \mid let\ \langle x,y \rangle =
m_1 \ in \ m_2$
	\\ $\Gamma \vdash m : A$
	\begin{prooftree}
		\AXC{$\Gamma \vdash m_1 : A \land B$}
		\AXC{$\Gamma, x : A, y:B \vdash m_2 : C$}
		\BIC{$\Gamma \vdash let\ \langle x,y \rangle = m_1\ in\ m_2:C$}
	\end{prooftree}
	If $\Gamma \vdash \underline{m}:A$ then $\Gamma \vdash
\underline{M}:A$. How to translate between languages? (We want
	to relate $m$ and $M$, this is very much like compiling one
	language to another)

$\to$ Function that translates $m$ to $M$: $(m)^-$\\
	\begin{tabular}{l l l}
		$(x)^-$ & $=$ & $x$
		\\ $(\langle m_1, m_2 \rangle)^-$ & $=$ & $\langle (m_1)^-, (m_2)^- \rangle$ (recursive)
		\\ $(let\ \langle x,y\rangle)^- = m_1\ in \ m_2$ & $=$ & $[fst\ (m_1)^- / x, snd\ (m_1)^- /y](m_2)^-$
	\end{tabular}
	\\(Note: another option for let: $let\ \langle x,y \rangle =
m_1\ in\ m_2 = (\lambda x . \lambda y. (m_2)^-\ (fst\ (m_1)^-)
) (snd\ (m_1)^-)$, however this will be much harder to prove
	equivalence for)
	\paragraph{Case:} $\mathcal{D} =$ \AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma \vdash m_1 : A
			\land B$}\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Gamma, x:A, y:B \vdash m_2 : C$}\BIC{$\Gamma
			\vdash let\ \langle x,y \rangle = m_1\ in \ m_2:C$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma \vdash (m_1)^- : A \land B$ & by IH on $\mathcal{D}_1$
		\\ $\Gamma \vdash fst\ (m_1)^- : A$, $\Gamma \vdash snd\ (m_1)^{-} : B$ & by IH on $\mathcal{D}_2$
		\\$\Gamma, x:A, y:B \vdash (m_2)^-:C$ & by IH on $\mathcal{D}_2$
			\\ $\Gamma \vdash [fst\ (m_1)^-/x, snd\ (m_1)^-/y](m_2)^- : C$ & by substitution lemma
			\\ $\Gamma \vdash (let\ \langle x,y \rangle)^- = m_1 \ in \ m_2 : C$ & by translation function
		% \\ $(let\ \langle x,y \rangle) = m_1 \ in\ m_2 = [fst\ (m_1)^-/x, snd\ (m_1)^-/y](m_2)^-$
	\end{tabular}

	We could also prove $let\ \langle x,y \rangle =
m_1\ in\ m_2 = (\lambda x . \lambda y. (m_2)^-\ (fst\ (m_1)^-)
) (snd\ (m_1)^-)$ by solely using implication elimination and introduction.

	% Diagram here comparing proof systems
	We will be able to show that the normal natural deduction
	system cannot prove bottom because sequent calculus cannot
	prove bottom, we didn't need the extra rule because the Cut
	Rule is admissible.

	If $\Gamma \vdash M :A$ then there exists a normal proof
$\Gamma \vdash m : A \uparrow$

	\paragraph{Normal ND}
	\begin{prooftree}
		\AXC{$\Downarrow \Gamma^{\downarrow} \vdash r : A
				\downarrow$ Elim-Rules}
		\UIC{$\Uparrow \Gamma^{\downarrow} \vdash m : A \uparrow$ Intro-Rules}
	\end{prooftree}
	\paragraph{Sequent Calculus}
	\begin{prooftree}
		\AXC{}
		\LL{initial rule}
		\UIC{$\underbrace{\Uparrow}_{\text{Left rules}} \Gamma
			\implies \underbrace{A}_{\text{Right rules}} \Uparrow$}
	\end{prooftree}
	\paragraph{Rules}
	Init: \AXC{$u : A \in \Gamma$}\UIC{$\Gamma \implies A$}\DP
	\\\\ Conjunction: \AXC{$\Gamma \implies A$}\AXC{$\Gamma \implies
			B$}\BIC{$\Gamma \implies A \land B$}\DP
	\\\\ \AXC{$\Gamma, u : A \land B, w: A \implies C$}\UIC{$\Gamma,
			u : A \land B \implies C$}\DP Here we see that our set of
	assumption grows, we extract $A$ from $A \land B$, like a $\downarrow$.
	\\\\ \AXC{$\Gamma, u : A \land B, w: B \implies C$}\UIC{$\Gamma,
			u : A \land B \implies C$}\DP Extract $B$.
	\\\\ Implication: \AXC{$\Gamma, u : A \implies B$}\UIC{$\Gamma
			\implies A \supset B$}\DP
	\AXC{$\Gamma, u : A \supset B, w:B \implies C$} \AXC{$\Gamma ,u
			: A \supset B \implies A$}\BIC{$\Gamma, u : A \supset B
			\implies C$}\DP
	\\\\ Top: \AXC{}\RL{T R}\UIC{$\Gamma \implies T$}\DP
	\\\\ Falsehood: \AXC{}\UIC{$\Gamma,u: \perp \implies C$}\DP
	\\\\ Disjunctions: \AXC{$\Gamma \implies A$}\UIC{$\Gamma
			\implies A \lor B$}\DP
	\AXC{$\Gamma \implies B$}\UIC{$\Gamma \implies A \lor B$}\DP
	\\\\\AXC{$\Gamma, u:A \lor B, v:A \implies C$}
	\AXC{$\Gamma, u:A \lor B, w:B \implies C$}
	\BIC{$\Gamma, u : A \lor B \implies C$}\DP
	\\\\ Quantifiers: \AXC{$\Gamma \implies A(a)$}\LL{R$\forall^a$}\UIC{$\Gamma
			\implies \forall x : \tau. A(x)$}\DP
	\AXC{$\Gamma \vdash t : \tau$}\AXC{$\Gamma, u : \underline{\forall x :
				\tau . A(x)}, w : \underline{A(t)} \implies C$}\BIC{$\Gamma, u : \forall x
			: \tau . A(x) \implies C$}\DP Can only instantiate witness
	once
	\\\\ \AXC{$\Gamma \vdash t: \tau$}\AXC{$\Gamma \implies
			A(t)$}\BIC{$\Gamma \implies \exists x : \tau . A(x)$}\DP
	\AXC{$\Gamma, u : \exists x : \tau . A(x), w : A (a) \implies
			C$}\RL{$\exists$ L}\UIC{$\Gamma, u: \exists x : \tau.A(x)
			\implies C$}\DP

$\Gamma$ accumulates everything we extract from rules, things
	are kind of inverted as to how they were with natural
	deduction. Note that you can keep $a:\tau$ in your assumptions
	for $\forall$ I and $\exists$ E.
	\paragraph{Example}
	\begin{prooftree}
		\AXC{$w:A \in \Gamma'$}
		\RL{init}
		\UIC{$\Gamma' \implies A$}

		\AXC{}
		\RL{init}
		\UIC{$\Gamma', v:B \implies B$}

		\RL{$\supset$ L}

		\BIC{$\Gamma' \implies B$}

		\AXC{}
		\RL{init}
		\UIC{$\Gamma', v : C \implies C$}
		\RL{$\supset$ L}

		\BIC{$\overbrace{\Gamma, u_1 : (A \supset B), u_2 : B \supset
					C}^{\Gamma'} \implies C$}
		\RL{$\land_1$ L, $\land_2$ L}
		\UIC{$\overbrace{u : (A \supset B) \land (B \supset C), w:A}^{\Gamma} \implies C$}
		\RL{$\supset$ R}
		\UIC{$u : (A \supset B) \land (B \supset C) \implies A
				\supset C$}
		\RL{$\supset$ R}
		\UIC{$\cdot \implies ((A \supset B) \land (B \supset C)) \supset
				A \supset C$}
	\end{prooftree}
	Now, in natural deduction:
	\begin{prooftree}
		\AXC{}
		\RL{u}
		\UIC{$(A \supset B) \land (B \supset C) \downarrow$}
		\RL{$\land$ E$_l$}
		\UIC{$A \supset B \downarrow$}

		\AXC{}
		\RL{w}
		\UIC{$A \downarrow \uparrow$}
		\RL{$\supset$ E}
		\BIC{$B \downarrow \uparrow$}

		\AXC{}
		\RL{u}
		\UIC{$(A \supset B) \land (B\supset C) \downarrow$}
		\RL{$\land$ E$_r$}
		\UIC{$B \supset C \downarrow$}

		\RL{$\supset$ E}
		\BIC{$C \downarrow \uparrow$}
		\RL{$\supset$ I$^{w}$}
		\UIC{$A \supset C \uparrow$}
		\RL{$\supset$ I$^u$}
		\UIC{$(A \supset B) \land (B \supset C) \supset A \supset C \uparrow$}
	\end{prooftree}
	So we see that init does not correspond to the assumptions, it
	corresponds to the $\uparrow \downarrow$.

	Is there a proof for $\cdot \implies \perp$? \underline{No.}
	(Obviously, we don't have a R rule for it and we have no assumptions. This
	system is complete and it is clearer to see that we don't have
	a proof for $\perp$ unlike natural deduction.)

	In natural deduction, we could have hypothetically had some
	proof like:
	\begin{prooftree}
		\AXC{$A \lor B$}
		\AXC{}
		\RL{}
		\UIC{A}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$\perp$}
		\AXC{}
		\RL{}
		\UIC{B}
		\noLine
		\UIC{\vdots}
		\noLine
		\UIC{$\perp$}
		\TIC{$\perp$}
	\end{prooftree}

	\paragraph{Soundness} If $\Gamma \implies A$ then
$\Gamma^{\downarrow} \vdash A \uparrow$ Induction on $\Gamma
\implies A$.
	\paragraph{Case:} $\mathcal{D} =$ \AXC{$u : A \in
			\Gamma$}\RL{init}\UIC{$\Gamma \implies A$}\DP
	\\
	\begin{tabular}{l l}
		$u:A \downarrow \in \Gamma^{\downarrow}$ &
		\\ $\Gamma^{\downarrow} \vdash A \downarrow$ & by assumption
		\\ $\Gamma^{\downarrow} \vdash A \uparrow$ & \textbf{by coercion}
	\end{tabular}

	Right rules are not interesting as they have direct
	correspondence to $\Gamma^{\downarrow} \vdash A \uparrow$ as
	that's how we defined them. Let's look at a left rule.
	\paragraph{Case:} $\mathcal{D}=$ \AXC{$\Gamma, u : A \land B, v
			: A \implies C$}\RL{$\land$ L$_1$}\UIC{$\Gamma, u:A \land B
			\implies C$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma^{\downarrow}, u : A \land B \downarrow, v : A \downarrow \vdash C \uparrow$ & by IH (1)
		\\ $\Gamma, u : A \land B \downarrow \vdash A \land B \downarrow$ & by assumption
		\\ $\Gamma, u : A \land B \downarrow \vdash A \downarrow$ & by $\land$ E$_l$ (2)
		\\$\Gamma^{\downarrow}, u : A \land B \downarrow \vdash C \uparrow$& by substitution lemma (1) + (2)
	\end{tabular}
	\section{02/14/19}
	% Put boxes around the tables like in the diagram from last lecture
	\begin{tabular}{l l l}
		ND & Normal ND & Sequent Calculus
		\\ $\Gamma \vdash A$ true $\to$ & $\Gamma \vdash A \uparrow$ & $\stackrel{\text{Soundness}}{\leftarrow} \Gamma \implies A$
		\\ & $\Gamma \vdash A \downarrow$ & Cut Rule
		\\ & \AXC{$\Gamma \vdash A\uparrow$}\UIC{$\Gamma \vdash A \downarrow$}\DP $\stackrel{\text{Complete}}{\rightarrow}$ & \AXC{$\Gamma \implies A$}\AXC{$\Gamma, A \implies C$}\BIC{$\Gamma \implies C$}\DP
	\end{tabular}
	\\ Today we want to prove:
	\begin{enumerate}
		\item Completeness of Sequent Calculus.
		      \\ If $\Gamma^{\uparrow} \vdash A \uparrow$ then $\Gamma
			      \implies A$
		\item Cut is \textbf{admissible}. If $\Gamma \implies A$ and
		      $\Gamma, A \implies C$, then $\Gamma \implies C$
	\end{enumerate}
	\paragraph{Remember}
	\begin{itemize}
		\item Right rules in $\Gamma \implies A$ correspond directly to
		      the intro rules in ND
		\item Left rules in $\Gamma \implies A$ extract more
		      information from an assumption present in
		      $\Gamma$.
	\end{itemize}
	\AXC{$\Gamma, A \land B, A \implies
			C$}\UIC{$\Gamma, A \land B \implies C$}\DP
	\paragraph{Attempt}
	\begin{enumerate}[(A)]
		\item If $\Gamma^{\downarrow} \vdash A \uparrow$ then $\Gamma
			      \implies A$
		\item If $\Gamma^{\downarrow} \vdash A \downarrow$ then $\Gamma
			      \implies A$
	\end{enumerate}
	This is incorrect and will easily breakdown, i.e.
	\paragraph{Consider} Elim rule for $A \land B$
	\\ Assumption: \AXC{$\Gamma^{\downarrow}\vdash A \land B
			\downarrow$}\UIC{$\Gamma^{\downarrow}\vdash A \downarrow$}\DP
	\\ (IH) $\Gamma \implies A \land B$
	\\ To show. $\Gamma \implies A$? We need to show what we
	assumed? That doesn't make sense.

	So what will we show instead?
	\begin{enumerate}[(A)]
		\item[(B)] If $\Gamma^{\downarrow} \vdash A \downarrow$ and
		      $\Gamma, A \implies C$ then $\Gamma \implies C$.
	\end{enumerate}
	\paragraph{Case} $\mathcal{D}=$ \AXC{$\Gamma^{\downarrow}
			\vdash A \land B \downarrow$}\UIC{$\Gamma^{\downarrow} \vdash
			A \downarrow$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma, A \implies C$ & by assumption
		\\ $\Gamma, A \land B, A \implies C$& by weakening (can throw in extra assumptions)
		\\ $\Gamma, A \land B \implies C$ & by $\land L$
		\\ $\Gamma \implies C$ & by IH
	\end{tabular}
	\paragraph{Case} $\mathcal{D} =$ \AXC{$\Gamma^{\downarrow}
			\vdash A \supset B
			\downarrow$}\AXC{$\Gamma^{\downarrow}\vdash A
			\uparrow$}\BIC{$\Gamma^{\downarrow}\vdash B \downarrow$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma, B \implies C$ & by assumption
		\\ $\Gamma \implies A$ & by IH (A)
		\\ $\Gamma, A \supset B \implies A$ & by weakening
		\\ $\Gamma, A \supset B, B \implies C$& by weakening
		\\ $\Gamma, A \supset B \implies C$ & by $\supset$ L
		\\ $\Gamma \implies C$ & by IH
	\end{tabular}
	\paragraph{Case} \AXC{$\Gamma^{\downarrow}\vdash A
			\downarrow$}\UIC{$\Gamma^{\downarrow} \vdash A \uparrow$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma, A \implies A$ & by init
		\\ $\Gamma \implies A$ & by IH
	\end{tabular}
	\paragraph{Case} \AXC{$\Gamma^{\downarrow}\vdash A
			\uparrow$}\UIC{$\Gamma^{\downarrow} \vdash A \downarrow$}\DP
	(The rule that makes our proofs non-normal)
	\\
$\Gamma \implies A$ by IH
	\\ Assuming $\Gamma, A \implies C$, we have $\Gamma \implies C$. That is the cut rule!
	\\\AXC{$\Gamma \implies A$}\AXC{$\Gamma, A \implies C$}\BIC{$\Gamma \implies C$}\DP
	\\ So the cut rule corresponds to non-normal proofs (as
	expected).
	\paragraph{Cut is admissible} If $\Gamma \stackrel{\mathcal{D}}{\implies} A$ and
$\Gamma, \underline{A} \stackrel{\mathcal{E}}{\implies} C$ then $\Gamma \implies C$,
	where $A$ is the principle formula/cut formula.

	When can we appeal to the IH?
	\begin{enumerate}
		\item The cut formula is getting smaller (will in some way
		      get to the base case)
		\item Either $\mathcal{D}$ is smaller and $\mathcal{E}$ stays
		      the same or $\mathcal{E}$ is smaller and $\mathcal{D}$
		      stays the same. i.e. one of them must be getting smaller.
	\end{enumerate}
	Initial sequences (base cases):
	\paragraph{Case}: $\mathcal{D} = $ \AXC{$A \in
			\Gamma$}\RL{init}\UIC{$\Gamma \implies A$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma = (\Gamma', A)$ (we know we have $A$ in $\Gamma$) &
		\\ $\underbrace{\Gamma', A}_{\Gamma}, A \implies C$ & by assumption ($\mathcal{E}$)
		\\ $\Gamma \implies C$ & by contraction ($\mathcal{E}$), don't need to use
		\\ & the second $A$ because we already have $A$
	\end{tabular}
	\paragraph{Case}: $\mathcal{E}=$ \AXC{}\RL{init}\UIC{$\Gamma,
			A \implies \underbrace{A}_C$}\DP
	\\ $\Gamma \implies A$ by $\mathcal{D}$
	\paragraph{Case}: $\mathcal{E}=$ \AXC{$C \in \Gamma$}\RL{init}\UIC{$\Gamma,
			A \implies C$}\DP
	\\ $\Gamma \implies C$ by $C \in \Gamma$ (init)
	Non base cases:
	\paragraph{Case}: $A$ is the principal formula and it is the
	cut form.
	\\ $\mathcal{D}=$\AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma \implies A$}\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Gamma
			\implies B$}\BIC{$\Gamma \implies A \land B$}\DP, $\mathcal{E}
= $\AXC{$\mathcal{E}'$}\noLine\UIC{$\Gamma, A\land B, A \implies C$}\UIC{$\Gamma, A
			\land B \implies C$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma, A \implies A \land B$ & by weakening $\mathcal{D}$
		\\ $\mathcal{F}: \Gamma, A \implies C$ & by IH $(A \land B, \mathcal{D}, \mathcal{E}')$
		\\ $\Gamma \implies C$ & by IH because $A < A \land B$ ($A, D_1, \mathcal{F}$)
	\end{tabular}
	\paragraph{Case}: $\mathcal{D}=$\AXC{$\mathcal{D}'$}\noLine\UIC{$\Gamma, A \implies
			B$}\UIC{$\Gamma \implies A \supset B$}\DP, $\mathcal{E} =$
	\AXC{$\mathcal{E}_1$}\noLine\UIC{$\Gamma, A \supset B \implies A$}\AXC{$\mathcal{E}_2$}\noLine\UIC{$\Gamma, A \supset
			B, B \implies C$}\BIC{$\Gamma, A \supset B \implies C$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma, B \implies A \supset B$ & by weakening on $\mathcal{D}$
		\\ $\Gamma, B \implies C$ & by IH ($A \supset B, \mathcal{D}, \mathcal{E}_2$) ($\mathcal{E}_2 < \mathcal{E}$)
		\\ $\mathcal{F}: \Gamma \implies A$ & by IH ($A \supset B, \mathcal{D}, \mathcal{E}_1$) ($\mathcal{E}_1 < \mathcal{E}$)
		\\ $\Gamma \implies B$ & by IH ($A, \mathcal{F}, \mathcal{D}'$) ($A < A \supset B$)
		\\ $\Gamma \implies C$ & by IH ($B, \ldots$) ($B < A \supset B$)
	\end{tabular}
	\\ Note that the order of our cuts here is important, if we
	cut in the wrong order it may not be justified as we may not
	know if the formula is getting smaller.
	\paragraph{Case}: \AXC{$\mathcal{D}$}\noLine\UIC{$\Gamma
			\implies A$}\DP, $\mathcal{E} =$\AXC{$\mathcal{E}_1$}\noLine\UIC{$\Gamma, A
			\implies C$}\AXC{$\mathcal{E}_2$}\noLine\UIC{$\Gamma, A
			\implies D$}\RL{$\land$ R}\BIC{$\Gamma, A \implies C \land
			D$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma \implies C$ & by IH ($A, \mathcal{D}, \mathcal{E}_1$) $\mathcal{E}_1 < \mathcal{E}$
		\\ $\Gamma \implies D$ & by IH ($A, \mathcal{D}, \mathcal{E}_2$) $\mathcal{E}_2 < \mathcal{E}$
	\end{tabular}

	\paragraph{Case}: $\mathcal{D}=$
	\AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma', B_1, \land B_2, B_1
			\implies A$}\UIC{$\underbrace{\Gamma', B_1 \land B_2}_{\Gamma}
			\implies A$}\DP,
	\AXC{$\mathcal{E}$}\noLine\UIC{$\underbrace{\Gamma_1',B_1
				\land B_2}_{\Gamma}, A \implies C$}\DP
	\\
	\begin{tabular}{l l}
		$\Gamma', B_1 \land B_2, B_1, A \implies C$ & by weakening $\mathcal{E}$
		\\ $\Gamma', B_1 \land B_2, B_1 \implies C$ & by IH($A, \mathcal{D}_1, \mathcal{E}$)
		\\ $\underbrace{\Gamma', B_1 \land B_2}_{\Gamma} \implies C$ & by $\land$ L$_1$
	\end{tabular}
	\section{02/19/19}
	\subsection{Sequent Calculus} $\Gamma \implies A$

	\AXC{$\Gamma \implies A$}
	\AXC{$\Gamma \implies B$}
	\BIC{$\Gamma \implies A \land B$}
	\DP
	%
	\AXC{$\Gamma, A \land B, A \implies C$}
	\UIC{$\Gamma, A \land B \implies C$}
	\DP
	%
	\AXC{$\Gamma, A \land B, B \implies C$}
	\UIC{$\Gamma, A \land B \implies C$}
	\DP
	%
	\AXC{$\Gamma, A \implies B$}
	\UIC{$\Gamma \implies A \supset B$}
	\DP
	%

	\AXC{$\Gamma, A \supset B \implies A$}
	\AXC{$\Gamma, A \supset B, B \implies C$}
	\BIC{$\Gamma, A \supset B \implies C$}
	\DP
	%
	\AXC{$A \in \Gamma$}
	\UIC{$\Gamma \implies A$}
	\DP
	%
	\AXC{}
	\UIC{$\Gamma, \perp \implies C$}
	\DP
	%
	\AXC{}
	\UIC{$\Gamma \implies \Gamma$}
	\DP
	%
	\AXC{$\Gamma \implies A$}
	\UIC{$\Gamma \implies A \lor B$}
	\DP
	%
	\AXC{$\Gamma \implies B$}
	\UIC{$\Gamma \implies A \lor B$}
	\DP
	%
	\AXC{$\Gamma, A \lor B, A \implies C$}
	\AXC{$\Gamma, A \lor B, B \implies C$}
	\BIC{$\Gamma, A \lor B \implies C$}
	\DP
	%
	\AXC{$\Gamma, a : \tau \implies A(a)$}
	\UIC{$\Gamma, \forall x : \tau. A(x)$}
	\DP

	\AXC{$\Gamma, \forall x : \tau. A(x), A(t) \implies C$}
	\UIC{$\Gamma, \forall x : \tau . A(x) \implies C$}
	\DP
	%
	\AXC{$\Gamma \implies A(t)$}
	\UIC{$\Gamma \implies \exists x : \tau. A(x)$}
	\DP
	\paragraph{Cut} If $\Gamma \implies A$ and $\Gamma, A
\implies C$ then $\Gamma \implies C$.

	We showed that:
	\\
	\begin{tabular}{l l }
		ND & Sequent Calc (without cut)
		\\ $\Gamma \vdash A$ true $\iff$ & $\Gamma \implies A$
	\end{tabular}

	\paragraph{What follows?}
	\begin{enumerate}
		\item There is no derivation in ND for $\perp$
		      \begin{itemize}
			      \item $\nvdash \perp$ true (since there is no proof $\cdot
				            \implies \perp$)
		      \end{itemize}
		\item If $\perp A \lor B$ then $\vdash A$ true or $\vdash B$
		      true
		\item If $\cdot \vdash \exists: \tau. A(x)$ true then $\vdash
			      A(t)$ true for some $t$
	\end{enumerate}
	\paragraph{Independence Results}
	Is it true that $\vdash A \lor \neg A$ true?

	If $\cdot \vdash A \lor \neg A$ true, then there must be some
	derivation $\cdot \implies A \lor \neg A$

	By inversion (looking at the rules for $\lor$ R$_1$, $\lor$
	R$_2$) either there is a proof for $\implies A$ or there is a
	proof for $\implies \neg A$, i.e. $A \implies \perp$
	\paragraph{Idea}
	\begin{enumerate}
		\item Apply right rules until we have to make a choice on the
		      right
		\item Apply all left rules until we have only propositions
		      left in $\Gamma$ that force a choice
	\end{enumerate}
	We have:
	\begin{itemize}
		\item
		      \underline{do}-care non-determinism ($\lor$ R$_1$, $\lor$
		      R$_2$, $\supset$ L, $\forall$ L, $\exists$ R)
		\item
		      \underline{don't}-care non-determinism ($\land $ R, $\land$
		      L$_1$, $\land$ L$_2$, $\forall$ R, $\exists$ L)

		      For the $\land$ assumption extraction rules, we don't care
		      because we can extract the assumptions at any stage.
	\end{itemize}
	\paragraph{Inversion Properties}
	\begin{enumerate}
		\item If $\Gamma \implies A \land B$ then $\Gamma \implies A$
		      and $\Gamma \implies B$ (basically what we mean by having a
		      don't care non-determinism)
		      \paragraph{Proof}

		      \begin{tabular}[t]{l l}
			      $\Gamma \implies A \land B$ & by assumption
			      \\ $\Gamma, A \land B, A \implies A$ & by init
			      \\ $\Gamma, A \land B \implies A$ by $\land$ L$_1$
			      \\ $\Gamma \implies A$ & by cut
			      \\ Similarly,
			      \\ $\Gamma, A \land B, B \implies B$ & by init
			      \\ $\Gamma, A \land B \implies B$ by $\land$ L$_2$
			      \\ $\Gamma \implies B$ & by cut
		      \end{tabular}
		      \\ Cut allows you to construct very short proofs.
		      \\ Otherwise you'll have to go the long way using induction,
		      like:
		      \paragraph{Case} \AXC{$\Gamma \implies A$}\AXC{$\Gamma
				      \implies B$}\BIC{$\Gamma \implies A \land B$}\DP
		      Therefore we immediately have $\Gamma \implies A$ and $\Gamma
			      \implies B$
		      \paragraph{Case} \AXC{$\mathcal{D}'$}\noLine\UIC{$\Gamma, C
				      \land D, C \implies A \land B$}\UIC{$\Gamma, C \land D
				      \implies A \land B$}\DP
		      \\
		      \begin{tabular}{l l}
			      $\Gamma, C \land D, C \implies A$ & by IH
			      \\ $\Gamma, C \land D, C \implies B$ & by IH
			      \\ $\Gamma, C \land D \implies A$ & by $\land$ L$_1$
			      \\ $\Gamma, C \land D \implies B$ & by $\land$ L$_1$
		      \end{tabular}
		\item If $\Gamma \implies A \supset B$ then $\Gamma, A \implies
			      B$
		\item If $\Gamma, A \land B \implies C$ then $\Gamma, A \land
			      B, A \implies C$
		\item If $\Gamma, A \land B \implies C$ then $\Gamma, A \land
			      B, B \implies C$

		      3 and 4 give you: If $\Gamma, A \land B \implies C$ then
		      $\Gamma, A, B \implies C$ (stronger inversion)
		\item If $\Gamma, A \lor B \implies C$ then $\Gamma, A \implies
			      C$ and $\Gamma, B \implies C$
	\end{enumerate}
	\subsection{Horn Clauses} $D := \overbrace{P}^{Atomic} \mid G
\supset D \mid \forall x : \tau . D$
	\\ Horn Goals $G := P \mid G_1 \land G_2$ (although usually
	just atomic because if you have a conjunction you can just ask
	multiple questions)
	\\ Atomic Formula $P := P(t_1, \ldots, t_n)$
	\\ Prolog is like the original form of this.

	For example, we can try to prove stuff about natural numbers:
	\\ $even\ z$ (Atomic formula)
	\\ $add \ (suc\ z)$
	\\ $\forall x:nat. even\ x \supset \underbrace{add\ (suc\
	x)}_{Head}$
	\\
	\begin{tabular}{l l}
		Prolog & Inf Rules
		\\ $add\ (suc\ x) :- $ & \AXC{}\UIC{$even\ z$}\DP \AXC{}\UIC{$odd\ z$}
		\\ $even\ x$ & \AXC{$even\ x$}\UIC{$add\ *suc\ x$}
	\end{tabular}

	\AXC{$P_1$}
	\AXC{\ldots}
	\AXC{$P_n$}
	\TIC{$C$}
	\DP
	\underline{Clause} $P_1 \land \ldots \land P_n \supset C$
	\paragraph{Graph Reachability} (good example for what can be
	represented)
	\\
	\begin{tabular}{l l}
		edge $a\ b$ & $\forall x, \forall y. edge\ x\ y \supset reach\ x\ y$
		\\ edge $b\ c$ & $\forall x \forall y \forall w.$
		\\ edge $c\ d$ & $reach\ x\ y \land reach\ y\ w$
		\\ edge $c\ a$ & $\supset reach\ x\ w$
	\end{tabular}
	\\This is our set of clauses. Left side are our axioms/facts,
	right side are clauses that let us get further with the axioms. This is widely used for things like databases.
	\paragraph{Search Problem} $\underbrace{\Gamma}_{\text{set of
	Horn Clauses}} \implies G$

	Programs you would write would look like:
	\begin{verbatim}
reach x y:-
    edge x y
reach x y:-
    reach x w,
    reach w y
\end{verbatim}
	Can I \underline{reach a d}? It will try the rules we wrote
	above.
	\paragraph{Uniform Proofs}
	\begin{enumerate}
		\item $\Gamma \implies G$ (don't care non-determinism, can
		      always eagerly split conjunctions)
		\item $\Gamma > D \implies P$ (pick a clause from $\Gamma$, do
		      care because we're making a choice)
	\end{enumerate}
	\section{02/21/19}
	\subsection{Horn Clauses, Logic Programming}
	Very limited subset of natural deduction.
	\paragraph{Uniform Proofs}
	\paragraph{Horn Clause} $D := P \mid G \supset P \mid \forall x
: \tau . D$
	\paragraph{Horn Goal} $G := P \mid G_1 \land G_2$
	\paragraph{Atomic Form} $P := p(1, \ldots, t_n)$
	\\
	\begin{tabular}{l l}
		$e\_z:$ & $even\ z$
		\\ $o\_sz:$ & $add(suc\ z)$
		\\ $e\_s:$ & $\forall x:nat. add \ x \supset even (suc\ x)$
		\\ $o\_s:$ & $\forall x : nat. even\ x \supset add(suc\ x)$
		\\ $r\_e:$ & $\forall x: node. \forall y:node . edge\ x\ y \supset reach\ x\ y$
		\\ $r\_tr:$ & $\forall x: node.\forall y: node. \forall w:node. reach\ x \ w \land reach\ w\ y \supset reach\ x \ y$
	\end{tabular}
	\paragraph{Plan} Extend the Horn Fragment to Hereditary Harrop
	Formulas (Higher-order logic programming) $\hat{=} \supset,
\forall, P$
	\\ Clauses $C := P \mid \forall x : \tau.C \mid C \supset C$

	We'll be able see if proofs exist for certain things:
	\\
	\begin{tabular}{l l}
		$\Delta$ & $\implies P$
		\\ $\Delta$ & $\implies reach\ a \ c$
		\\ $\Delta$ & $\implies odd\ (suc\ (suc\ z))$ (hopefully not true as $2$ is even)
		\\ $\Delta$ & $\implies even\ (suc\ (suc\ z))$
	\end{tabular}
	Our rules are as follows, which are just the
	sequent calculus rules that we need.
	\begin{center}
		\AXC{$P \in \Delta$}
		\UIC{$\Delta \implies P$}
		\DP
		%
		\AXC{$\Delta \implies G_1$}
		\AXC{$\Delta \implies G_2$}
		\RL{$\land$ R}
		\BIC{$\Delta \implies G_1 \land G_2$}
		\DP
		%
		\AXC{$\Delta, \forall x: \tau. D, [t/x]D \implies G$}
		\RL{$\forall$ L}
		\UIC{$\Delta, \forall x:\ \tau. D \implies G$}
		\DP
		%
		\AXC{$\Delta, G \supset P \implies G$}
		\AXC{$\Delta, G \supset P, P \implies G'$}
		\RL{$\supset$ L}
		\BIC{$\Delta, G \supset C \implies G'$}
		\DP
	\end{center}
	Recall that last class we proved:
	\paragraph{Inversion:} If $\Delta \implies G_1 \land G_2$ then
$\Delta \implies G_1$ and $\Delta \implies G_2$.

	So if the clause on the right is not atomic, we can split it
	up.
	\paragraph{Idea:} (we want to come up with a search strategy)
	\begin{enumerate}
		\item Apply init and $\land$ R until $\Delta \implies P$
		      (atomic formula)

		      We'll have two steps we can take: $\Delta
			      \stackrel{u}{\implies}G_1$, $\Delta \stackrel{e}{\implies}P$,
		      where $u$ is uniform and we work with the left rules.

		      \begin{center}
			      \AXC{$\Delta \stackrel{u}{\implies}G_1$}
			      \AXC{$\Delta \stackrel{u}{\implies}G_2$}
			      \BIC{$\Delta \stackrel{u}{\implies} G_1 \land G_2$}
			      \DP
			      %
			      \AXC{$\Delta \stackrel{e}{\implies}P$}
			      \UIC{$\Delta \stackrel{u}{\implies} P$}
			      \DP
			      \\ Where:
			      \AXC{$P \in \Delta$}
			      \UIC{$\Delta \stackrel{e}{\implies}P$}
			      \DP
			      %
			      \AXC{$\Delta, \forall x: \tau. \mathcal{D},
					      [t/x]\mathcal{D}{\implies} P$}
			      \UIC{$\Delta, \forall x: \tau. D {\implies} P$}
			      \DP
			      %
			      \AXC{$\Delta, G \supset P {\implies G}$}
			      \AXC{$\Delta, G \supset P, P {\implies} P'$}
			      \BIC{$\Delta, G \supset P {\implies} P'$}
			      \DP
		      \end{center}
	\end{enumerate}
	With this new proof system, we can show that it is equivalent
	to the Horn Fragment.
	\paragraph{Sound} If $\Delta \stackrel{u}{\implies}G$ then
$\Delta \implies G$
	\\ If $\Delta \stackrel{e}{\implies} P$ then $\Delta \implies
P$
	\\ (you can prove this via induction, associating the
	corresponding rules from our new system to the Horn Fragment
	rules)
	\paragraph{Complete} If $\Delta \implies G$ then $\Delta
\stackrel{u}{\implies} G$
	\paragraph{Example of Proof Search}
	\begin{scprooftree}{0.8}
		\AXC{}
		\RL{$e\_z$}
		\UIC{$\Delta \implies even\ z$}

		\AXC{}
		\RL{init}
		\UIC{$\Delta, add\ (suc\ z) \implies add\ (suc\ z)$}

		\RL{$\supset$ L}
		\BIC{$\Delta, even\ z \supset odd\ (suc\ z) \implies odd\
				(suc\ z)$}
		\RL{$\forall$ L$o\_s$}
		\UIC{$\Delta \implies odd\ (suc\ z)$}

		\AXC{}
		\RL{init}
		\UIC{$\Delta, even\ (suc\ (suc\ z)) \implies even\ (suc\
				(suc\ z))$}

		\RL{$\supset$ L}
		\BIC{$\Delta, odd\ (succ\ z) \supset even\ (suc\ (suc\ z))
				\implies even\ (suc\ (suc\ z))$}
		\RL{$\forall$ L $e\_s$}
		\UIC{$\Delta \implies even (suc\ (suc\ z))$}
	\end{scprooftree}
	The consecutive uses of L rules are called \textbf{focusing}
	($\supset$ L and $\forall$ L$o\_s$ are coupled together and
	$\supset$ L and $\forall$ L $e\_s$ are coupled together)

	We can do the proof either forwards (top to bottom) or
	backwards (bottom to top). Logic programming goes bottom
	up. Surprisingly, when you have to make
	a choice, you can stick with it as it won't make a
	difference. So we can now make some adjustments to our rules to
	achieve a narrower search space:
	\begin{enumerate}
		\item Apply init and $\land$ R until $\Delta \implies P$
		      (atomic formula)
		      \\$\Delta
		      \stackrel{u}{\implies}G_1$, \textcolor{orange}{$\Delta > D
				      \implies P$}
		      \begin{center}
			      \AXC{$\Delta \stackrel{u}{\implies}G_1$}
			      \AXC{$\Delta \stackrel{u}{\implies}G_2$}
			      \BIC{$\Delta \stackrel{u}{\implies} G_1 \land G_2$}
			      \DP
			      %
			      \AXC{\textcolor{orange}{$\Delta > D \implies P$}}
			      \AXC{\textcolor{orange}{$D \in \Delta$}}
			      \BIC{$\Delta \stackrel{u}{\implies} P$}
			      \DP
			      \\ Where:
			      \AXC{$P \in \Delta$}
			      \UIC{$\Delta \textcolor{orange}{> P} {\implies}P$}
			      \DP
			      %
			      \AXC{$\Delta \textcolor{orange}{>}
					      [t/x]\mathcal{D}{\implies} P$}
			      \UIC{$\Delta \textcolor{orange}{>} \forall x: \tau. D {\implies} P$}
			      \DP
			      %
			      \AXC{$\Delta, G \supset P {\implies G}$}
			      \AXC{$\Delta \textcolor{orange}{>} G \supset P, P {\implies} P'$}
			      \BIC{$\Delta \textcolor{orange}{>} G \supset P {\implies} P'$}
			      \DP
		      \end{center}
		\item Once we pick a clause from $\Delta$, we focus on it.
	\end{enumerate}
	Now how do we show this is sound and complete?
	\\ If $\Delta \implies G$ then $\Delta \stackrel{u}{\implies}
G$
	\\ If $\Delta \implies P$ then $\Delta > D \implies P$ for $D
\in \Delta$
	\paragraph{Case} $\mathcal{D} = $
	\AXC{$\mathcal{D}_1$}\noLine\UIC{$\Delta \implies G_1$}
	\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Delta \implies G_2$}
	\RL{$\land$ R}
	\BIC{$\Delta \implies G_1 \land G_2$}
	\DP
	\\
	\begin{tabular}{l l}
		$\Delta \stackrel{u}{\implies} G_1$ & by IH
		\\ $\Delta \stackrel{u}{\implies} G_2$ & by IH
		\\ $\Delta \stackrel{u}{\implies} G_1 \land G_2$ & by $\land$ R$_u$
	\end{tabular}
	\paragraph{Case} $\mathcal{D} = $
	\AXC{$\Delta, G_1 \supset P_1 \implies G_1$}
	\AXC{$\Delta, G_1 \supset P_1, P_1 \implies G$}
	\BIC{$\Delta, G_1 \supset P_1 \implies G$}
	\DP
	\subparagraph{To show} $\Delta, G_1 \supset P_1
\stackrel{u}{\implies} G$
	\\ \begin{tabular}{l l}
		$\Delta, G_1 \supset P_1 \stackrel{u}{\implies} G_1$ & by IH
		\\ $\Delta, G_1 \supset P_1, P_1 \stackrel{u}{\implies} G$ & by IH
	\end{tabular}
	\\ Where do we go from here? We have no implication rule (we
	worked hard to get rid of the rule). This suggests that we need
	a lemma.
	\paragraph{Postponement Lemma}
	If $\Delta, G_1 \supset P_1 \stackrel{u}{\implies}G_1$ and
$\Delta, G_1 \supset P_1, P_1 \stackrel{u}{\implies} G$ then
$\Delta, G_1 \supset P_1 \stackrel{u}{\implies} G$. Basically
	we can postpone working on the left for higher up in the tree.
	\paragraph{Case} $\mathcal{D} = $
	\AXC{$\Delta, G_1 \supset P_1 \implies G_1$}
	\AXC{$\Delta, G_1 \supset P_1, P_1 \implies P$}
	\BIC{$\Delta, G_1 \supset P_1 \implies P$}
	\DP
	\subparagraph{To show}: $(\Delta, G_1 \supset P_1) > D \implies
P$ where $D \in (\Delta, G_1 \supset P_1)$
	\\
	\begin{tabular}{l l}
		$\Delta, G_1 \supset P_1, P_1 > D' \implies P$ & by IH
		\\ $\Delta, G_1 \supset P_1 \stackrel{u}{\implies} G_1$ & by postponement lemma
	\end{tabular}
	\\ This is another form of the postponement lemma. Both forms
	of the postponement lemma can be proven via induction.
	% \paragraph{Beluga Examples for Prolog}
	\section{02/26/19}
	Logic Programming
	\paragraph{Recall} Horn Clause $C:=P(t_1 \ldots t_n) \mid G
\supset P(t_1 \ldots t_n) \mid \forall x : \tau . C$
	\\ Goals $G : = P(t_1 \ldots t_n) \mid G_1 \land G_2$
	\\ Invertible on the right (asynchronous)
	\\ Focusing (postpone certain choices) (synchronous)

$\Delta \implies G$ uniform
	\\ $\Delta > C \implies P(t_1 \ldots t_n)$ focusing
	\subsection{Higher-Order Logic Programming}
	(Hereditary Harrop formulas)
	\\ $F := P(t_1 \ldots t_n) \mid F_1 \supset F_2 \mid \forall x
: \tau. F$

	Horn Fragment:
	\\$P(t_1 \ldots t_n) \land Q(s_1 \ldots s_k) \supset R(w_1
	\ldots w_m) \to P(t_1 \ldots t_n) \supset Q(s_1 \ldots s_k)
	\supset R(w_1 \ldots w_m)$
\paragraph{Uniform Phase}
\AXC{$\Delta \implies [a/x] F$}
\RL{$\forall$ R$^a$}
\UIC{$\Delta \implies \forall x : \tau . F$}
\DP
%
\AXC{$\Delta, u : F_1 \implies F_2$}
\UIC{$\Delta \implies F_1 \supset F_2$}
\DP
%
\AXC{$\Delta > F \implies P(t_1 \ldots t_n)$}
\RL{$F \in \Delta$}
\UIC{$\Delta \implies P(t_1 \ldots t_n)$}
\DP
Where the last rule is new.
\paragraph{Focusing phase}
\AXC{}
\UIC{$\Delta > P(t_1 \ldots t_n) \implies P(t_1 \ldots t_n)$ }
\DP
\AXC{$\Delta > [t/x] F \implies P(t_1 \ldots t_n)$}
\UIC{$\Delta > \forall x : \tau . F \implies P(t_1 \ldots
		t_n)$}
\DP

\AXC{$\Delta \implies F_1$}
\AXC{$\Delta > F_2 \implies P(t_1 \ldots t_n)$}
\BIC{$\Delta > F_1 \supset F_2 \implies P(t_1 \ldots t_n)$}
\DP

(To not reprove things like $F_1$, you could keep a memoization
table on the side)
\\ ``Reflect'' natural deduction into HHF using one predicate
\underline{nd A}
\\
\begin{tabular}{l l}
	\textbf{ND Rules}                                                                                                             & \textbf{HHF}
	\\ \AXC{}\RL{$T$ I}\UIC{$T$ true}\DP & $nd\_top$I: nd top
	\\ \AXC{$A$ true}\AXC{$B$ true}\RL{$\land$ I}\BIC{$(A \land B)$ true}\DP & nd\_andI: $\forall A:o.\forall B:o$ ($o$ is our predicate)
	\\ & nd A $\supset$ (nd $B \supset $ nd (and $A\ B$))
	\\ \AXC{$A \land B$ true}\RL{and$E_1$}\UIC{$A$ true}\DP & nd\_andE$_1$:$\forall A :o.\forall B:o.$ nd (and $A\ B$) $\supset$ nd $A$
	\\
	\\ \AXC{}
	\RL{u}
	\UIC{$A$ true}\noLine\UIC{$\vdots$}\noLine\UIC{$B$ true}\RL{$\supset$ I$^u$}\UIC{$(\textcolor{orange}{A \supset B})$ true}\DP & \textbf{Hypothetical derivation}, use $\supset$ from HHF
	\\    & nd\_impI: $\forall A : o . \forall B:o. \underline{(nd\ A \supset nd\ B)} \supset nd\ (\textcolor{orange}{imp}\ A\ B)$
	\\ & (underline corresponds to the hypothetical derivation)
	\\ \AXC{$A \lor B$ true}\AXC{}
	\RL{u}
	\UIC{$A$ true}\noLine\UIC{$\vdots$}\noLine\UIC{$C$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}\noLine\UIC{$\vdots$}\noLine\UIC{$C$ true}
	\TIC{$C$ true}
	\DP
	\\ & nd\_orE: $\forall A: o. \forall B: o. \forall C: o$ nd (or $A\ B$) $\supset$
	\\ & \underline{(nd $A \supset$ nd $C$)} $\supset$ \underline{($nd\ B \supset nd\ C$)} $\supset nd\ C$
	\\\\ \AXC{$A \land B$ true} \AXC{}
	\RL{u}
	\UIC{$A$ true}
	\AXC{}
	\RL{v}
	\UIC{$B$ true}
	\noLine
	\BIC{$\vdots$}
	\noLine
	\UIC{$C$ true}
	\RL{$\land$ E}
	\BIC{$C$ true}
	\DP
\end{tabular}
\\
\begin{tabular}{l l}
	\\ \underline{Judgment} $\vdash$ even $n$
	\\ Rules:
	\\ \AXC{}\RL{ev\_z}\UIC{$\vdash$ even $0$}\DP & ev\_z: even $z$
	\\ \AXC{$\vdash$ even $n$}\UIC{$\vdash$ even $(ss\ n)$}\DP & ev\_s: $\forall n$: nat. even $n \supset$ even $(ss\ n)$
\end{tabular}

Translating HHF to FOL:
\begin{tabular}{l l}
	o: & type
	\\ top: & o
	\\ and: & o $\to$ o $\to$ o
	\\ imp: & o $\to$ o $\to$ o
	\\ or: & o $\to$ o $\to$ o
	\\ all: & ? $\to$ o
	\\ nd & is predicate on o
	\\ nd: & o $\to$ type
\end{tabular}
\paragraph{Phases with terms}
\paragraph{Uniform Phase}
\AXC{$\Delta \implies  \textcolor{orange}{M:}[a/x] F$}
\RL{$\forall$ R$^a$}
\UIC{$\Delta \implies \textcolor{orange}{\lambda a.M:}\forall x : \tau . F$}
\DP
%
\AXC{$\Delta, u : F_1 \implies \textcolor{orange}{M:}F_2$}
\UIC{$\Delta \implies \textcolor{orange}{\lambda u. M :}F_1
		\supset F_2$}
\DP
%

\AXC{$\textcolor{orange}{x:}F \in \Delta\ \Delta > F \implies \textcolor{orange}{R:}P(t_1 \ldots t_n)$}
\UIC{$\Delta \implies \textcolor{orange}{R:}P(t_1 \ldots t_n)$}
\DP
Where the last rule is new.
\paragraph{Focusing phase}
\AXC{}
\UIC{$\Delta > \textcolor{orange}{R:}P(t_1 \ldots t_n) \implies
		\textcolor{orange}{R:}P(t_1 \ldots t_n)$ }
\DP
\AXC{$\Delta > \textcolor{orange}{R\ t:}[t/x] F \implies
		\textcolor{orange}{R_0:} P(t_1 \ldots t_n)$}
\UIC{$\Delta > \textcolor{orange}{R:}\forall x : \tau . F
		\implies  \textcolor{orange}{R_0:}P(t_1 \ldots
		t_n)$}
\DP

\AXC{$\Delta \implies \textcolor{orange}{M:}F_1$}
\AXC{$\Delta > \textcolor{orange}{R \ M:}F_2 \implies \textcolor{orange}{R_0:}P(t_1 \ldots t_n)$}
\BIC{$\Delta > \textcolor{orange}{R:}F_1 \supset F_2 \implies \textcolor{orange}{R_0:}P(t_1 \ldots t_n)$}
\DP
% Beluga example of ND

Can define inference rules in Beluga and proof terms and use it
as a proof checker.
% \\ $\ldots, nd (\& \ A\ B) \implies nd\ (\& \ B\ A)
% \stackrel{nd\_andI}{\to} \ldots, nd\& A\ B \miplies nd\ B$
% ($nd\_andE_2$)
% \\$\ldots, nd(\& A\ B) \implies nd\ A$ ($nd\_andE_1$)

% A framework for defining logics and proofs:
% \\ Harper, Hansell, Plotkin LIC JACM
% \\ Dep $\lambda$-calc = logical framework LF
% \\ $M: = \lambda x. M \mid R$
% \\ $R : = x \mid C \mid R\ M$
% \\ Types $A:= a \ M_1\  M_n' \mid \Pi x : A .B$
% \\ $A \to B \hat{=} \Pi x: A . B$ where $x \in FV(B)$
\section{02/28/19}
\paragraph{Midterm} (Homework 1 and 2, no normal, sequent, etc.)
\begin{enumerate}
	\item ND: propositional \& $1^{st}$ order
	\item Inductive proofs
	\item New \underline{rules} (and prove how they preserve
	      provability)
\end{enumerate}
\paragraph{Example}
\textbf{Source Language}
\\ Terms $M := \lambda x. M \mid M_1 \ M_2 \mid nor\ (x.M_1)
	(y.M_2) \mid abort_l M_0 \ M_1 \mid abort_r M_0\ M_2$
\\ Types $A := A_1 \supset A_2 \mid A_1 \overline{\lor} A_2$
\\ Contexts $\Gamma := \cdot \mid \Gamma, x :A$
\\ \noindent \rule{\textwidth}{0.5pt}
\\ \textbf{Target Language}
\\ Terms $N : = \lambda x.N \mid N_1\ N_2 \mid (N_1, N_2)
	\mid fst\ N \mid snd\ N \mid abort\ N$
\\ Types $B:= B_1 \supset B_2 \mid B_1 \land B_2 \mid \perp$
\\ Contexts $\Delta := \cdot \mid \Delta, x:B$

Want to show that source language preservers provability of
target language.

Rules:

\begin{prooftree}
	\AXC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
	\AXC{$\Gamma \vdash M_1 : A_1$}
	\BIC{$\Gamma \vdash abort_L\ M_0\ M_1 : C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
	\AXC{$\Gamma \vdash M_2 : A_2$}
	\BIC{$\Gamma \vdash abort_R\ M_0\ M_2 : C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma, x:A_1 \vdash M_1 : p$}
	\AXC{$\Gamma, y:A_2 \vdash M_2 : q$}
	\BIC{$\Gamma \vdash nor (x.M_1) (y.M_2) : A_1 \overline{\lor} A_2$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma, x:A_1 \vdash M : A_2$}
	\UIC{$\Gamma \vdash \lambda x . M : A_1 \supset A_2$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M_0 : A_1 \supset A_2$}
	\AXC{$\Gamma \vdash M_1 : A_1$}
	\BIC{$\Gamma \vdash M_0 \ M_1 : A_2$}
\end{prooftree}
Our rules are not annotated in a certain way to ensure type
uniqueness because we don't care about that right now, but if
we wanted to guarantee type uniqueness, we'd have to annotate
our terms more.
\paragraph{Local Soundness}
\begin{center}
	\AXC{$\mathcal{D}_1$}
	\noLine
	\UIC{$\Gamma, x:A_1 \vdash M_1 : p$}
	\AXC{$\mathcal{D}_2$}
	\noLine
	\UIC{$\Gamma, y:A_2 \vdash M_2 : q$}
	\BIC{$\Gamma \vdash nor (x.M_1)(y.M_2) : A_1 \overline{\lor}
			A_2$}
	\AXC{$\mathcal{D}'$}
	\noLine
	\UIC{$\Gamma \vdash M' : A_1$}
	\BIC{$\Gamma \vdash abort_L (nor (x.M_1) (y.M_2)) M' : C$}
	\DP
	$\implies$
	\begin{tabular}{l}
		$[\mathcal{D}'/x, C/p] \mathcal{D}_1$
		\\ $\Gamma \vdash [M'/x]M_1 : C$
	\end{tabular}
\end{center}
We end up with the following reduction rule:
\\ $abort_L (nor(x.M_1) (y.M_2))M' \implies [M'/x]M_1$

In general, with hypothetical derivations for soundness, you
will end up with a substitution.

We then repeat this for abort right and combine them, just like
for conjunction local soundness, where we had two elimination
rules and we made two proof trees.

\paragraph{Local Completeness}
\begin{center}
	\scalebox{0.7}{\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
		\DP
		$\implies$
		\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
		\RL{weakening}
		\UIC{$\Gamma, x :A_1 \vdash M_0 : A_1 \overline{\lor} A_2$}
		%
		\AXC{}
		\RL{}
		\UIC{$\Gamma, x:A_1 \vdash x:A_1$}
		\BIC{$\Gamma, x:A_1 \vdash abort_L\ M_0\ x :p$}
		\AXC{$\mathcal{D}$}
		\noLine
		\UIC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
		\RL{weakening}
		\UIC{$\Gamma, y :A_2 \vdash M_0 : A_1 \overline{\lor} A_2$}
		%
		\AXC{}
		\RL{}
		\UIC{$\Gamma, y:A_2 \vdash y:A_2$}
		\BIC{$\Gamma ,y:A_2 \vdash abort_R\ M_0\ y :q$}
		\RL{$\overline{\lor}$ I$^{x,y, p, q}$}
		\BIC{$\Gamma \vdash nor (x.abort_L\ M_0\ x)(y.abort_R M_0\ y) : A_1 \overline{\lor} A_2$}
		\DP}
\end{center}
\paragraph{Translation function}~
\begin{align*}
	\llbracket M \rrbracket & = N
	\\ \llbracket \lambda x. M \rrbracket & = \lambda x. \llbracket M \rrbracket
	\\ \llbracket x \rrbracket & = x
	\\ \llbracket nor (x.M_1) (y.M_2) \rrbracket & = (\lambda x. \llbracket M_1 \rrbracket, \lambda y.\llbracket M_2 \rrbracket)
	\\ \llbracket abort_L\ M_0\ M_1 \rrbracket & = abort_L [(fst\ \llbracket M_0 \rrbracket)\llbracket M_1 \rrbracket]
	\\ \llbracket A \rrbracket & = B
	\\ \llbracket A_1 \supset A_2 \rrbracket & = \llbracket A_1 \rrbracket \supset \llbracket A_2 \rrbracket
	\\ \llbracket A_1 \overline{\lor} A_2 \rrbracket & = \neg \llbracket A_1 \rrbracket \land \neg \llbracket A_2 \rrbracket = (\llbracket A_1 \rrbracket \supset \perp) \land (\llbracket A_2 \rrbracket \supset \perp)
	\\ \llbracket \Gamma \rrbracket & = \Delta
	\\ \llbracket \cdot \rrbracket & = \cdot
	\\ \llbracket \Gamma, x:A \rrbracket & = \llbracket \Gamma \rrbracket, x:\llbracket A \rrbracket
\end{align*}
\paragraph{Thm} If $\Gamma \vdash M:A$ then $\llbracket \Gamma
	\rrbracket \vdash \llbracket M \rrbracket: \llbracket A \rrbracket$.
\paragraph{Proof} by induction on $\mathcal{D} :: \Gamma \vdash M
	: A$
\subparagraph{Case} $\mathcal{D} =$ \AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma, x:A_1 \vdash
		M_1 : p$}\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Gamma, y:A_2 \vdash
		M_2 : q$}
\RL{$\overline{\lor}$ I$^{x,y,p,q}$}
\BIC{$\Gamma \vdash nor(x.M_1)(y.M_2) : A_1 \overline{\lor}
		A_2$}
\DP
\\
\begin{tabular}{l l}
	$\llbracket \Gamma \rrbracket \vdash \llbracket nor(x.M_1)(y.M_2) \rrbracket : \llbracket A_1 \overline{\lor} A_2 \rrbracket$ &
	\\ $\llbracket \Gamma \rrbracket \vdash (\lambda x. \llbracket M_1 \rrbracket, \lambda y. \llbracket M_2 \rrbracket) : \neg \llbracket A_1 \rrbracket \land \neg \llbracket A_2 \rrbracket$ & (Want to show)
	\\ $\mathcal{E}_1 :: \llbracket \Gamma ,x:A_1 \rrbracket \vdash \llbracket M_1 \rrbracket : p$ & by IH on $\mathcal{D}_1$
	\\ $[\perp/p]\mathcal{E}_1 :: \llbracket \Gamma \rrbracket, x : \llbracket A_1 \rrbracket \vdash \llbracket M_1 \rrbracket : \perp$
	\\ $\mathcal{E}_2 :: \llbracket \Gamma \rrbracket, y: \llbracket A_2 \rrbracket \vdash \llbracket M_2 \rrbracket : \perp$ & IH on $\mathcal{D}_2$
\end{tabular}
\begin{prooftree}
	\AXC{$[\perp/p]\mathcal{E}_1$}
	\noLine
	\UIC{$\llbracket \Gamma \rrbracket,  x: \llbracket A_1
			\rrbracket \vdash \llbracket M_1 \rrbracket : \perp$}
	\RL{$\supset$ I}
	\UIC{$\llbracket \Gamma \rrbracket \vdash \lambda
			x. \llbracket M_1 \rrbracket : \neg \llbracket A_1 \rrbracket$}
	\AXC{$[\perp/p]\mathcal{E}_2$}
	\noLine
	\UIC{$\llbracket \Gamma \rrbracket,  y: \llbracket A_2
			\rrbracket \vdash \llbracket M_2 \rrbracket : \perp$}
	\RL{$\supset$ I}
	\UIC{$\llbracket \Gamma \rrbracket \vdash \lambda
			x. \llbracket M_2 \rrbracket : \neg \llbracket A_2
			\rrbracket$}
	\RL{$\land$ I}
	\BIC{$\llbracket \Gamma \rrbracket \vdash (\lambda
			x. \llbracket M \rrbracket, \lambda y. \llbracket M_1
			\rrbracket) : \neg \llbracket A_1 \rrbracket \land \neg
			\llbracket A_2 \rrbracket$}
\end{prooftree}
\subparagraph{Case} $\mathcal{D} =$
\AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma \vdash M_0 : A_1
		\overline{\lor} A_2$}
\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Gamma \vdash M_1 : A_1$}
\BIC{$\Gamma \vdash abort_L\ M_0\ M_1 : C$}
\DP
\\
\begin{tabular}{l l}
	$\llbracket \Gamma \rrbracket \vdash \llbracket abort_L\ M_0\ M_1 \rrbracket : \llbracket C \rrbracket$ &
	\\ $\llbracket \Gamma \rrbracket \vdash abort [(fst\ \llbracket M_0 \rrbracket)\llbracket M_1 \rrbracket] : \llbracket C \rrbracket$ & (want to show)
	\\ $\mathcal{E}_1 :: \llbracket \Gamma \rrbracket \vdash \llbracket M_0 \rrbracket : \neg \llbracket A_1 \rrbracket \land \neg \llbracket A_2 \rrbracket$ & IH on $\mathcal{D}_1$
	\\ $\mathcal{E}_2 :: \llbracket \Gamma \rrbracket \vdash \llbracket M \rrbracket : \llbracket A_1 \rrbracket$ & IH on $\mathcal{D}_2$
\end{tabular}
\begin{prooftree}
	\AXC{$\mathcal{E}_1$}
	\noLine
	\UIC{$\llbracket \Gamma \rrbracket \vdash \llbracket M_0
			\rrbracket : \neg \llbracket A_1 \rrbracket \land \neg
			\llbracket A_2 \rrbracket$}
	\RL{$\land$ E$_L$}
	\UIC{$\llbracket R \rrbracket \vdash fst \llbracket M_0
			\rrbracket : \neg \llbracket A_1 \rrbracket$}
	\AXC{$\mathcal{E}_2$}
	\noLine
	\UIC{$\llbracket \Gamma \rrbracket \vdash \llbracket M_1
			\rrbracket : \llbracket A \rrbracket$}
	\RL{$\supset$ E}
	\BIC{$\llbracket \Gamma \rrbracket \vdash (fst \llbracket M_0
			\rrbracket)\llbracket M_1 \rrbracket : \perp$}
	\RL{$\perp$ E}
	\UIC{$\llbracket \Gamma \rrbracket \vdash
			abort[(fst\llbracket M_0 \rrbracket)\llbracket M_1
					\rrbracket] : \llbracket C \rrbracket$}
\end{prooftree}
\paragraph{Type Uniqueness}
Rules annotated for type uniqueness:

\begin{prooftree}
	\AXC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
	\AXC{$\Gamma \vdash M_1 : A_1$}
	\BIC{$\Gamma \vdash abort_L^C\ M_0\ M_1 : C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma \vdash M_0 : A_1 \overline{\lor} A_2$}
	\AXC{$\Gamma \vdash M_2 : A_2$}
	\BIC{$\Gamma \vdash abort_R^C\ M_0\ M_2 : C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Gamma, x:A_1 \vdash M_1 : p$}
	\AXC{$\Gamma, y:A_2 \vdash M_2 : q$}
	\BIC{$\Gamma \vdash nor (x:A_1.M_1) (y:A_2.M_2) : A_1
			\overline{\lor} A_2$}
\end{prooftree}
If $\Gamma \vdash M : A_1'$ and $\Gamma \stackrel{\mathcal{E}}{\vdash} M:A_2 '$ then
$A_1' = A_2'$
\paragraph{Proof} by induction on $\mathcal{D} :: \Gamma
	\vdash M : A_1'$
\subparagraph{Case} $\mathcal{D} =$
\AXC{$\mathcal{D}_1$}\noLine\UIC{$\Gamma, x:A_1 \vdash M_1 :
		p$}
\AXC{$\mathcal{D}_2$}\noLine\UIC{$\Gamma, y:A_2 \vdash M_2 :
		q$}
\RL{$\overline{\lor}$ I$^{x,y,p,q}$}
\BIC{$\Gamma \vdash nor(x:A_1.M_1)(y:A_2.M_2)$}
\DP
\\
\begin{tabular}{l l}
	$M = nor (x:A_1.M_1)(y:A_2.M_2)$ & by assumption
	\\ $A_1' = A_1 \overline{\lor} A_2$ & by assumption
	\\ $\mathcal{E} :: \Gamma \vdash nor(x:A_1.M_1)(y:A_2.M_2) : A_2'$ & by assumption
	\\ $\mathcal{E}_1 :: \Gamma, x:A_1 \vdash M_1 : p'$ & by inversion
	\\ $\mathcal{E}_2 :: \Gamma, y:A_2 \vdash M_2 : q'$ & by inversion
	\\ $A'_2 = A_1 \overline{\lor} A_2$ & by inversion
\end{tabular}
\section{03/14/19}
\subsection{Modal Logic (S4)} Logic in a type of world. In
particular we will look at S4 Modal Logic. In S4, we have two
laws:
\begin{itemize}
	\item Reflexivity + Transitivity to reason about the truth in
	      different worlds
	\item We will distinguish between ``global'' notion of truth
	      (valid/validity) and ``local'' notion of truth (two worlds)

	      Computationally we can think of it as a network topology
	      (every computer lives in its own world). Want to talk about
	      truth of a program at a given node in the network and truth
	      at every possible node in a network.

	      We want to see what the difference between validity and truth is.
\end{itemize}
\paragraph{Today:}
\begin{itemize}
	\item Necessity: A proposition $A$ is necessarily true
	      i.e. valid, globally true, true in every possible world

	      Can extend this with:
	      \begin{itemize}
		      \item Possibility (it is possible that in some world it is
		            true)
		      \item ``Time'': it is true in the next timestamp (lax
		            modality), not thinking of absolute time (e.g. at exactly
		            5:05 pm it will be true), but rather clock ticks, think of
		            time in an abstract fashion
	      \end{itemize}
\end{itemize}
Distinguish between $\underbrace{\text{validity}}_{A\text{
			valid}}$ and $\underbrace{\text{truth}}_{A\text{ true}}$.
\paragraph{Def. of Validity} If $\cdot \vdash A$ true then $\
	\vdash A$ valid
\\ If $\ \vdash A$ valid then $\ \vdash A$ true
\\ We can express that things are true unconditionally and
everyone will be able to access that truth
\\ $\underbrace{A_1 \text{ valid}, \ldots, A_n \text{
			valid}}_{\Delta : \text{global assumptions}}; \underbrace{B_1
		\text{ true}, \ldots, B_k \text{ true}}_{\Gamma : \text{local
			assumptions}} \vdash C$ true
\\ So we are distinguishing between what everyone knows and
what I know.
\\ So how can we then prove something is true?
\begin{prooftree}
	\AXC{$A$ true $\in \Gamma$}
	\UIC{$\Delta ; \Gamma \vdash A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$A$ valid $\in \Delta$}
	\UIC{$\Delta ; \Gamma \vdash A$ true}
\end{prooftree}
\paragraph{Substitution Principles:}
\begin{enumerate}
	\item If $\Delta; \Gamma \vdash A$ true and $\Delta; \Gamma, A$
	      true$, \Gamma' \vdash C$ true then $\Delta;\Gamma, \Gamma'
		      \vdash C$ true
	\item If $\Delta; \cdot \vdash B$ true and $\Delta, B$
	      valid$,\Delta' ; \Gamma \vdash C$ true then $(\Delta,
		      \Delta'); \Gamma \vdash C$ true
\end{enumerate}
\paragraph{Necessity:} $\square A$ internalizes validity
\\ $A$ is necessarily true

Prop. $A, B := T \mid A \supset B \mid A \land B \mid \square
	A$

Term $M, N := \lambda x.M \mid M\ N \mid box\ M \mid let\ box\
	u = M\ in\ N$

\paragraph{Introduction:}
\begin{prooftree}
	\AXC{$\Delta ; \cdot \vdash A$ true}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
\end{prooftree}
\paragraph{Elimination:}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash \square A$ true}
	\UIC{$\Delta;\Gamma \vdash A$ true}
\end{prooftree}
Alternative?
\begin{center}
	\AXC{$\Delta; \Gamma \vdash \square A$ true}
	\UIC{$\Delta;\cdot \vdash A$ true}
	\DP
	$\implies$ UNSOUND
\end{center}
\paragraph{Local Soundness:}
\begin{center}
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$\Delta; \cdot \vdash A$ true}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
	\UIC{$\Delta; \Gamma \vdash A$ true}
	\DP
	$\implies$
	\begin{tabular}{c}
		$\mathcal{D}^{\text{weak}}$
		\\ $\Delta; \Gamma \vdash A$ true
	\end{tabular}
\end{center}
\paragraph{Local Completeness:}
\begin{center}
	\begin{tabular}{c}
		$\mathcal{D}$
		\\$\Delta; \Gamma \vdash \square A$ true
	\end{tabular}
	$\implies$
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
	\UIC{$\Delta; \Gamma \vdash A$ true}
	\noLine
	\UIC{$\vdots$}
	\noLine
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
	\DP
	(\textbf{Too weak})
\end{center}
So what elimination rule should we have? Take inspiration from
disjunction elimination.
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash \square A$ true}
	\AXC{$\Delta, A$ valid$; \Gamma \vdash C$ true}
	\BIC{$\Delta; \Gamma \vdash C$ true}
\end{prooftree}
\paragraph{Revisiting Local Soundness}
\begin{center}
	\AXC{$\mathcal{D}_1$}
	\noLine
	\UIC{$\Delta; \cdot \vdash A$ true}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
	\AXC{$\mathcal{D}_2$}
	\noLine
	\UIC{$\Delta, u: A$ valid$; \Gamma \vdash C$ true}
	\RL{$\square$ E}
	\BIC{$\Delta; \Gamma \vdash C$ true}
	\DP
	$\implies \Delta; \Gamma \vdash C$ true (Substution Lemma) $[\mathcal{D}_1/u]\mathcal{D_2}$
\end{center}
\paragraph{Local Completeness}
\begin{center}
	\begin{tabular}{c}
		$\mathcal{D}$
		\\ $\Delta; \Gamma \vdash \square A$ true
	\end{tabular}
	$\implies$
	\AXC{$\mathcal{D}$}
	\noLine
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
	\AXC{$A$ valid $\in \Delta$}
	\UIC{$\Delta, A$ valid$; \cdot \vdash A$ true}
	\UIC{$\Delta, A$ valid$; \Gamma \vdash \square A$ true}
	\BIC{$\Delta; \Gamma \vdash \square A$ true}
	\DP
\end{center}
\paragraph{Examples}
We want to prove: $A \supset \square A, \square A
	\supset A, \square A \supset \square \square A$

\begin{scprooftree}{0.7}
	\AXC{}
	\UIC{$\cdot; \square (A \supset B)$ true$, \square A$ true
		$\vdash \square A$ true}

	\AXC{$A$ valid$; \Gamma \vdash \square (A \supset B)$ true}

	\AXC{\ldots}
	\UIC{$A$ valid$, A \supset B$ valid$; \cdot \vdash A \supset
			B$ true}

	\AXC{\ldots}
	\UIC{$\ldots \vdash A$ true}
	\RL{$\supset$ E}
	\BIC{$A$ valid$, A \supset B$ valid$; \cdot \vdash B$ true}
	\RL{$\square$ I}
	\UIC{$A$ valid$, A \supset B$ valid$; \Gamma \vdash \square
			B$ true}
	\RL{$\square$ E}
	\BIC{$\cdot; \square(A \supset B)$ true $,\square A$ true
		$\vdash \square A$ true}

	\RL{$\square$ E}
	\BIC{$ \cdot; \overbrace{\square (A \supset B)\text{ true }, \square A\text{ true}}^{\Gamma}\vdash \square B$ true}
	\RL{$\supset$ I}
	\UIC{$\cdot; \square(A \supset B)$ true$ \cdot \vdash\square()$}
	\RL{$\supset$ I$^u$}
	\UIC{$\cdot; \cdot \vdash \square(A \supset B) \supset
			\square A \supset \square B$ true}
\end{scprooftree}
In general, we want to promote validity to truths/assumptions.
\begin{prooftree}
	\AXC{$\cdot; \square A$ true $\vdash \square A$ true}
	\AXC{}
	\UIC{$A$ valid$; \square A$ true $\vdash A$ true}
	\RL{$\square$ E}
	\BIC{$\cdot; \square A$ true $\vdash A$ true}
	\RL{$\supset$ I}
	\UIC{$\cdot; \cdot \vdash \square A \supset A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\cdot; \square A$ true $\vdash \square A$ true}

	\AXC{}
	\UIC{$A$ valid$; \cdot \vdash A$ true}
	\RL{$\square$ I}
	\UIC{$A$ valid$; \cdot \vdash \square A$ true}
	\RL{$\square$ I}
	\UIC{$A$ valid$; \square A$ true $\vdash \square \square A$ true}
	\RL{$\square$ E}
	\BIC{$\cdot; \square A$ true $\vdash \square \square A$ true}
	\UIC{$\cdot; \cdot \vdash \square A \supset \square \square
			A$ true}
\end{prooftree}

\paragraph{Variables}
We have two different classes of variables (depending on where
they come from)
\begin{prooftree}
	\AXC{$x:A$ true $\in \Gamma$}
	\UIC{$\Delta; \Gamma \vdash x : A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$u:A$ valid $\in \Delta$}
	\UIC{$\Delta; \Gamma \vdash u:A$ true}
\end{prooftree}
\paragraph{Rules with Terms}
\begin{prooftree}
	\AXC{$\Delta; \cdot \vdash M : A$ true}
	\UIC{$\Delta; \Gamma \vdash box\ M : \square A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash M:\square A$ true}
	\AXC{$\Delta, u:A$ valid$; \Gamma \vdash N : C$ true}
	\BIC{$\Delta; \Gamma \vdash let\ box\ u = M\ in\ N : C$ true}
\end{prooftree}
\paragraph{Staged Programming}
Distinguish between code that is \underline{generated} \textbf{AND} code
that is actually doing the work of generating code (\underline{code
	generator}, for example, $\square$ can be the code generator and
$A$ can be the code that is generated)

Reminder from 302: \texttt{pow 2}$\to $ squaring function $x * x * 1$
\\ \texttt{pow 3} $\to x * x * x * 1$
\begin{algorithmic}
	\State {\texttt{(* pow n x = $x^n$*)}}
	\State {\texttt{pow : int -> $\square$ (int -> int)}}
	\State {\texttt{let rec pow n =}}
	\If {$n = 0$}
	\State {\texttt{box($\lambda$x.1)}}
	\Else
	\State {\texttt{box f = pow (n-1) in}}
	\State {\texttt{box($\lambda$x.x*f x)}}
	\EndIf
\end{algorithmic}
\texttt{pow 2} $\neq$ \texttt{box ($\lambda$x. x * x * 1)}
\\ \underline{Instead:} \texttt{box ($\lambda$x . x *
	\underline{($\lambda$x$_1$.x$_1$*($\lambda$x$_0$.1) x$_1$) x})}
\\ Administrative redeces
\section{03/19/19}
Papers posted on myCourses:
\begin{itemize}
	\item Davies, Pfenning: A judgmental reconstruction of modal
	      logic, MSCS 2001
	\item Nanevski, Pfenning, Pientka: Contextual Modal Type
	      Theory, ACM Transactions on Computational Logic, 2008
\end{itemize}
Don't have to read the whole papers, just look at them with
your notes and read the sections relevant to what we covered.

\paragraph{Recap}
$\mathcal{A} := A \supset B \mid \square A$
\\ $\square A \hat{=} A$ is true in every world ``$A$ valid''
\\ $\underbrace{\Delta}_{\substack{\text{global assumptions}\\A
		\text{ valid}}};
	\underbrace{\Gamma}_{\substack{\text{current local
			assumptions}\\ \mathcal{A} \text{ true}}} \vdash
	A$ true
\begin{prooftree}
	\AXC{$u:A$ valid $\in \Delta$}
	\UIC{$\Delta ; \Gamma \vdash A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta ; \cdot \vdash A$ true}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash \square A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash \square A$ true}
	\AXC{$\Delta, u:A$ valid$; \Gamma \vdash C$ true}
	\BIC{$\Delta; \Gamma \vdash C$ true}
\end{prooftree}
We saw the power function:
\\$pow : int \to \square (int \to int)$
	\\ $pow\ 3 \nrightarrow box(fun\ x \to x * x * x * 1)$
	\\ $pow\ n = if\ n = 0 \ then \ \mybox{?}\ else\ \mybox{?}$,
	where $\mybox{?}$ after the then is a hole for $n$
	\\$\forall x : nat. even\ x \supset \mybox{?}$

Because of these holes, we want to redefine things a bit (like
in code, we want to be able to import things without having to
change overall logic):
$\mathcal{A} := A \supset B \mid [\psi] A$
\\ $[\psi] A \hat{=} A$ is true in every world where we have
assumptions $\psi$
\\ $[\psi] A \stackrel{\sim}{=} \square (\psi \supset A)$
\\ $[x_1:B_1, \ldots, x_n:B_n] A \stackrel{\sim}{=} \square
	(B_1 \supset B_2 \supset \ldots \supset B_n \supset A)$
\\ $\implies$ Logically equivalent (we haven't expanded the
proof system)
\\ $\implies$ Computationally different
\\ $\stackrel{\sim}{=}$ Structure of proofs is different
\\ $\underbrace{\Delta}_{\substack{\text{global assumptions}\\ [\psi]A}};
	\underbrace{\Gamma}_{\substack{\text{current local
			assumptions}\\ \mathcal{A} \text{ true}}} \vdash
	A$ true
\begin{prooftree}
	\AXC{$u:[\psi]A \in \Delta$}
	\AXC{$\Delta; \Gamma \vdash \psi$}
	\RL{hyp$^*$}
	\BIC{$\Delta ; \Gamma \vdash A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta ; \psi \vdash A$ true}
	\RL{$\square$ I, Context switch}
	\UIC{$\Delta; \Gamma \vdash [\psi] A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash [\psi] A$ true}
	\AXC{$\Delta, u:[\psi]A; \Gamma \vdash C$ true}
        \RL{$\square$ E$^u$}
	\BIC{$\Delta; \Gamma \vdash C$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta, \Gamma \vdash A_1$ true}
	\AXC{\ldots}
	\AXC{$\Delta; \Gamma \vdash A_n$ true}
        \RL{ctx}
	\TIC{$\Delta; \Gamma \vdash x_1 : A_1, \ldots, x_n : A_n = \psi$}
\end{prooftree}
\begin{prooftree}
	\AXC{}
	\RL{$n$-times}
	\UIC{$\Delta; x_! : B_1, \ldots, x_n : B_n \vdash A$ true}
	\RL{$\supset$ I}
	\UIC{$\Delta ; \cdot \vdash B_1 \supset B_2 \supset \ldots
			\supset B_n \supset A$}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash \square (B_1 \supset B_2 \supset
			\ldots \supset B_n \supset A)$}
\end{prooftree}
\paragraph{Examples}
{$\square (C \supset A) \supset \square (C \supset D
		\supset A)$}
\begin{prooftree}
	\AXC{}
	\UIC{$\cdot; [x:C] A$ true $\vdash [x:C] A$ true}
	\AXC{}
	\UIC{$u:[x:C]A$ valid$; C$ true$, D$ true $\vdash C$ true}
	\RL{hyp$^*$}
	\UIC{$u:[x:C]A$ valid$; C$ true$, D$ true $\vdash A$ true}
	\RL{$\square$ I}
	\UIC{$u:[x:C]A$ valid$; [x:C]A$ true $\vdash [x:C, y:D] A$
	true}
	\RL{$\square$ E}
	\BIC{$\cdot ; [x:C] A$ true $\vdash [x:C, y:D] A$ true}
	\RL{$\supset$ I}
	\UIC{$\cdot \vdash [x:C] A \supset [x:C, y:D] A$ true}
\end{prooftree}
In this proof we don't waste time using $\supset$ E and
instead use hyp$^*$, nor do we use $\supset$ I.
\begin{scprooftree}{0.8}
	\AXC{$\ldots$}
	\AXC{}
	\UIC{$u:[A]B, v:[A]([B]C); A$ true $\vdash A$ true}
	\UIC{$u:[A]B, v:[A]([B]C); A$ true $\vdash [B]C$ true}
	\AXC{}
	\UIC{$u:[A]B, v:[A]([B]C), w:[B]C; A$ true $\vdash A$ true}
	\RL{hyp$^*$}
	\UIC{$u:[A]B, v:[A]([B]C), w:[B]C;A$ true $\vdash B$ true}
	\RL{hyp$^*$}
	\UIC{$u: [A]B, v:[A]([B]C), w:[B]C; A$ true $\vdash C$ true}
	\RL{$\square$ E}
	\BIC{$u:[A]B, v:[A]([B]C) ; A$ true $\vdash C$ true}
	\RL{$\square$ I}
	\UIC{$u : [A]B, v:[A]([B]C); \Gamma \vdash [A]C$ true}
	\RL{2 - times $\square$ E}
	\BIC{}
	\UIC{}
	\UIC{$\cdot; \underbrace{[A]B \text{ true}, [A]([B] C)
				\text{ true}}_{\Gamma} \vdash [A]C$ true}
\end{scprooftree}
For the last line, we can't use $\square$ I right away, as
we'd drop all the assumptions we have. We therefore have to
transfer these assumptions to our global context such that we
can use them. It is hard to reason directly from
assumptions.

This proof is similar to $(A \supset B \supset C) \supset (A
	\supset C)$, however the proof structure changes a lot.

\begin{prooftree}
	\AXC{}
	\UIC{$\cdot ; A$ true $\vdash A$ true}
	\RL{$\square$ I}
	\UIC{$\cdot ; \vdash [A]A$ true}
\end{prooftree}
Similar to $[\cdot]A \supset A$ true.

If $\psi$ in hyp$^*$ is empty, then things become trivially
true, we don't have to prove everything in $\psi$ and we get
an axiom.

We cannot prove $[A] ([B] C)$ true $\vdash [B]([A]C)$
true. We only have reflexivity and transitivity, no symmetry.
\begin{prooftree}
	\AXC{\ldots}
	\AXC{?}
	\UIC{$u:[A]([B] C); B$ true $\vdash [A]C$ true}
	\UIC{$u:[A]([B]C);\Gamma \vdash [B]([A]C)$ true}
	\RL{$\square$ E}
	\BIC{$\cdot ; [A] ([B] C)$ true $\vdash [B]([A]C)$ true}
\end{prooftree}
However, we can prove:
\\ $[A][B] C \supset [[] B] [A] C$
\\ $[A,B] C \supset [A \land B] C$
\\ $[A,B]C \supset [B,A]C$

Importing a global piece of code, with terms:
\begin{prooftree}
	\AXC{$u:[\psi]A \in \Delta$}
	\AXC{$\Delta; \Gamma \vdash \overbrace{\sigma}^{\text{Substitution}} : \psi$}
	\RL{hyp$^*$}
	\BIC{$\Delta ; \Gamma \vdash clo(u,
		\underbrace{\sigma}_{\text{Explicit/suspended substitution calculus}}) : A$ true}
\end{prooftree}
Where clo is a closure.
\begin{prooftree}
	\AXC{$\Delta ; \psi \vdash M:A$ true}
	\RL{$\square$ I, Context switch}
	\UIC{$\Delta; \Gamma \vdash box (\psi.M) : [\psi] A$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash M : [\psi] A$ true}
	\AXC{$\Delta, u:[\psi]A; \Gamma \vdash N : C$ true}
	\BIC{$\Delta; \Gamma \vdash let\ box\ u = M\ in\ N : C$ true}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta, \Gamma \vdash M_1 : A_1$ true}
	\AXC{\ldots}
	\AXC{$\Delta; \Gamma \vdash M_n : A_n$ true}
	\TIC{$\Delta; \Gamma \vdash M_1/x_1, \ldots, M_n/x_n : x_1 : A_1, \ldots, x_n : A_n$}
\end{prooftree}
Comparing \texttt{pow} with global contexts to imported
contexts (note on the RHS we still expect an input $x:int$ to
generate the code):\\
\begin{minipage}{0.5\linewidth}
	\texttt{pow : int $\to \square$ (int $\to$ int)}
	\\ \texttt{let rec pow n = }
	\\ \phantom{a}\hspace{1 em} \texttt{if n = 0 then box(fun x $\to$ 1)}
	\\ \phantom{a}\hspace{1 em} \texttt{else let box $\underbrace{p}_{int
				\to int}$ = pow (n-1) in}
	\\ \phantom{a}\hspace{2 em} \texttt{box (fun x $\to$ x * p
		x)}
\end{minipage}
\begin{minipage}{0.5\linewidth}
	\texttt{pow : int -> [x : int] int}
	\\\texttt{let rec pow n =}
	\\ \phantom{a}\hspace{1 em} \texttt{if n = 0 then box (x
		. 1)}
	\\ \phantom{a}\hspace{1 em} \texttt{else let box
	$\underbrace{p}_{[x':int]int}$ = pow (n-1) in}
	\\ \phantom{a}\hspace{2 em} \texttt{box (x . x * clo(p, x/x'))}
\end{minipage}
\\ Running version 1 gives us:
\\ \texttt{pow 2 $\to$ let box p = pow 1 in}
\\ \phantom{pow 2 $\to$}\hspace{1 em}\texttt{box (fun x $\to$
	x * p x)}
\\ \phantom{pow 2} $\to$ \texttt{let box p = box (fun x$_1
		\to$ x$_1$ * (fun x$_0 \to$ 1) x$_1$) in}
\\ \phantom{pow 2 $\to$}\hspace{1 em}\texttt{box (fun
	x$_2\to$ x$_2$ * (fun x$_1 \to$x$_1$ * (fun
	x$_0\to$1)x$_1$)x$_2$)}
\\
\\ Running version 2 gives us:
\\ \texttt{pow 2 $\to$ let box p = pow 1 in}
\\ \phantom{pow 2 $\to$}\hspace{1 em}\texttt{box (x$_2$ .
	x$_2$ * clos(p, x$_2$/x$_1$))}
\\ \phantom{pow 2} $\to$ \texttt{let box p = box (x$_1
	$ . x$_1$ * 1) in}
\\ \phantom{pow 2 $\to$}\hspace{1 em}\texttt{box (x$_2$
	. x$_2$ * clo (p, x$_2$/x$_1$))}
\\ \phantom{pow 2}$\to$ \texttt{box (x$_2$ . x$_2$ * x$_2$ *
	1)}
\\
Therefore, in the second version, we do not need to introduce
functions (functions are too complicated for what we want to
achieve). Clearly the second version is much more efficient and does
the same thing when we compare them side by side. It generates code
depending on the runtime environment we provide it.

Another example:
\texttt{let rec length l =}
\\\phantom{a} \hspace{1 em} \texttt{match l with}
\\ \phantom{a} \hspace{2 em} \texttt{|[] $\to$ ?}
\\ \phantom{a} \hspace{2 em} \texttt{|h::t $\to$ \mybox{?}}
\\ \texttt{[l:$\alpha$ list, h:$\alpha$, t:$\alpha$ list]int},
we substitute in \texttt{l}.
\section{03/21/19}
\subsection{Recap of Box Notation}
\begin{prooftree}
	\AXC{$x:A \in \Gamma$}
	\UIC{$\Delta; \Gamma \vdash x : A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$u:[\psi]A \in \Delta$}
	\AXC{$\Delta; \Gamma \vdash \sigma : \psi$}
	\RL{hyp$^{*}$}
	\BIC{$\Delta; \Gamma \vdash $clo$(u, \sigma) : A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash M_1 : A_1$}
	\AXC{$\ldots$}
	\AXC{$\Delta; \Gamma \vdash M_n : A_n$}
	\TIC{$\Delta; \Gamma \vdash \underbrace{M_1/x_1 \ldots
				M_n/x_n}_{\sigma}: \underbrace{\psi}_{x_1:A_1 \ldots x_n:A_n}$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \psi \vdash M : A$}
	\RL{$\square$ I}
	\UIC{$\Delta; \Gamma \vdash$ box$(\psi.M): [\psi] A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \vdash M : [\psi] A$}
	\AXC{$\Delta, u : [\psi] A; \Gamma \vdash N : C$}
	\RL{$\square$ E}
	\BIC{$\Delta; \Gamma \vdash$ let box $u = M\ in \ N : C$}
\end{prooftree}
Today:
\begin{enumerate}
	\item Revisiting substitution op
	\item Subject reduction
	\item ND $\to$ Sequent Calculus
	\item Cut for contextual $\square$
\end{enumerate}
\paragraph{Reduction}
\begin{tabular}{l l}
	$(\lambda x.M)N$ & $\to [N/x]M$
	\\ let box $u = $ box$(\psi.M)$ in $N$ & $\to \llbracket \psi.M/u \rrbracket N$
\end{tabular}
\\ Coming up with the let reduction is tricky. \texttt{let box u =
	box(x.x+1) in box(y.y*clo(u,y/x))}
\paragraph{Idea}
\begin{itemize}
	\item Replace $u$ by \texttt{(x.x+1)}
	\item Followed by applying the substitution $[y/x](x+1)$
\end{itemize}
$\to$ \texttt{box(y.y*$\underbrace{y+1}_{[y/x](x+1)})$}

\paragraph{$[M/x] N$ = $N'$}
Replace $x$ (from $\Gamma$, local context) with $M$ in $N$.

Capture avoiding!

\begin{align*}
	[M/x]x & =M
	\\ [M/x]y & =y, x \neq y
	\\ [M/x](\lambda y. N) & = \lambda y.[M/x]N, y \notin FV(M)
	\\ &                    \text{(avoid capture ``local'')}
	\\ [M/x](box(\psi.N)) & = box(\psi.N)
	\\ & \text{($N$ can only contain
		things in $\psi$ due to intro rule, no $x$)}
	\\ [M/x](let\ box\ u = N_1\ in\ N_2)  & = let\ box\ u = [M/x]N_1\ in
	\ [M/x]N_2, u \notin FMV(M)
	\\ & \text{(avoid capture ``global'', i.e.\ bound from let)}
	\\ [M/x](clo(u, \sigma)) & = clo(u, [M/x]\sigma)
\end{align*}
(Other substitution)
\begin{align*}
	\llbracket \psi.M/u \rrbracket N             & = N'
	\intertext{Replace $u$ (from
		global $\Delta$ with $(\psi.M)$
		in $N$)}
	\llbracket \psi. M / u \rrbracket x          & = x
	\llbracket \psi. M/u \rrbracket (\lambda y.N) = \lambda y. \llbracket \psi.M/u \rrbracket N
	\intertext{Don't
		need
		to
		take
		care
		of
		capture,
		since
		$M$
		is
		closed
		wrt
		$\psi$;
		in
		particular
		$y$
		cannot
		occur
		in
		$M$}
	\llbracket \psi.M/u \rrbracket(box (\phi.N)) & = box(\phi.\llbracket \psi.M/u \rrbracket N)
	\\ \llbracket \psi.M/u \rrbracket(let\ box\ v = N_1\ in\ N_2) & = let\ box\ v = \llbracket \psi.M/u \rrbracket N_1\ in \llbracket \psi.M/u \rrbracket N_2, v \notin FMV(M)
	\\ \llbracket\psi.M/u\rrbracket clo(u, \sigma) & = [\llbracket \psi.M/u \rrbracket \sigma] M
	\\ clo(v, \llbracket \psi. M/u \rrbracket \sigma) & = clo(v, \llbracket \psi.M/u\rrbracket \sigma)
\end{align*}
Tough to come up with the closure rule here:
\\ \texttt{let box u = box (x.x+1) in
	box(y.y*clo(u,y/x))$\to$box(y.y*(y+1))}
\paragraph{Idea}
\begin{enumerate}
	\item
	      \begin{enumerate}
		      \item Replace $u$ with $x+1$
		      \item Replace any free occurrence of $u$ in $(y/x)$!
	      \end{enumerate}
	\item Eliminated the closure by applying $[y/x]$ to $(x+1)$, $[y/x](x+1)$
\end{enumerate}
\paragraph{Subject Reduction} If $\Delta; \Gamma \vdash M : A$ and $M
	\to M'$ then $\Delta; \Gamma \vdash M : A$.
\\ Case Analysis on $M \to M'$
\paragraph{Case:} $(\lambda x.M)N \to [N/x]M$
\\
\begin{tabular}{l l}
	$\Delta; \Gamma \vdash (\lambda x.M)N:B$ & by assumption
	\\                                           $\Delta; \Gamma \vdash N : A$
	\\ $\Delta; \Gamma \vdash \lambda x.M :A \supset B$ & by inversion on $\supset$ E
	\\ $\Delta; \Gamma, x : A \vdash M:B$ & by inversion on $\supset$ I
	\\ $\Delta; \Gamma \vdash [N/x]M:B$ & by substitution Lemma for local context
\end{tabular}
\paragraph{Case:}let box $u =$ box$(\psi.M)$ in $N \to \llbracket
	\psi.M/u \rrbracket N$
\\
\begin{tabular}{l l}
	$\Delta; \Gamma \vdash $ let box $u = $ box$(\psi.M)$ in $M : B$ & by assumption
	\\ $\Delta; u: [\psi]A ; \Gamma \vdash N : B$ & by inversion $\square$E
	\\ $\Delta; \Gamma \vdash$ box$(\psi.M):[\psi]A$
	\\ $\Delta; \psi \vdash M : A$ & by inversion $\square$ I
	\\ $\Delta; \Gamma \vdash \llbracket \psi. M/u \rrbracket N:B$ & by substitution lemma for \underline{global context}
\end{tabular}

So now we also want to show consistency, much like we did using
normal proofs and sequent calculus. What was the idea behind sequent
calculus?
\paragraph{Sequent Calculus} (only normal derivations)
\\ A way of proving consistency (we are not able to prove $\cdot ;
	\cdot \vdash \perp$)
\subparagraph{Normal ND}
\begin{prooftree}
	\AXC{$\Downarrow \Gamma^{\downarrow} \vdash r : A
			\downarrow$ Elim-Rules}
	\UIC{$\Uparrow \Gamma^{\downarrow} \vdash m : A \uparrow$ Intro-Rules}
\end{prooftree}
\subparagraph{Sequent Calculus}
\begin{prooftree}
	\AXC{}
	\LL{initial rule}
	\UIC{$\underbrace{\Uparrow}_{\text{Left rules}} \Gamma
		\implies \underbrace{A}_{\text{Right rules}} \Uparrow$}
\end{prooftree}

New rules:

\begin{prooftree}
	\AXC{$\Delta; \psi \implies A$}
	\RL{$\square$ R}
	\UIC{$\Delta; \Gamma \implies [\psi] A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma, x : A \implies B$}
	\RL{$\supset$ R}
	\UIC{$\Delta; \Gamma \implies A \supset B$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta; \Gamma \implies A$}
	\AXC{$\Delta; \Gamma, x : A \supset B, y : B \implies C$}
	\RL{$\supset$ L}
	\BIC{$\Delta; \Gamma, x : A \supset B \implies B$}
\end{prooftree}
\begin{prooftree}
	\AXC{}
	\RL{initial}
	\UIC{$\Delta; \Gamma, A \implies A$}
\end{prooftree}
\begin{prooftree}
	\AXC{$\Delta, u : [\psi]A; \Gamma, x:[\psi]A \implies C$}
	\RL{$\square$L}
	\UIC{$\Delta; \Gamma, x: [\psi] A \implies C$}
\end{prooftree}
\begin{prooftree}
	\AXC{$(\Delta, u:[\psi]A);\Gamma \implies \psi$}
	\AXC{$\Delta, u:[\psi]A; \Gamma, A \implies C$}
	\RL{reflect}
	\BIC{$\Delta, u:\underbrace{[\psi]A}_{\psi \supset A}; \Gamma \implies C$}
      \end{prooftree}
      \section{03/26/19}
      Recap of modal logic (with boxes):

      $\square A$, $A$ is necessarily true or $A$ is true in every
      world.
      \paragraph{So far:}
      $\underbrace{\Delta}_{\text{global}};
      \underbrace{\Gamma}_{\text{local}} \vdash A$ true
      \\ ``explicit'' box and let-box
      \subsection{Alternative (implicit) characterization of $\square A$}
      \paragraph{Today:} Alternative characterization of $\square A$.
      \begin{itemize}
      \item Kripke-style interpretation
      \item S4: Accessibility Relation over worlds
        \begin{itemize}
        \item Reflexive
        \item Transitive
        \end{itemize}
      \end{itemize}
      $\underbrace{\Gamma_1; \Gamma_2 ; \ldots ;
        \Gamma_n}_{\substack{\text{Context stack}\\\text{initial
            world}}} \vdash A$ true
      \paragraph{Idea:} Consider $\Gamma_i$. Then every assumption in
      $\Gamma_i$ is reachable from the worlds (context) $\Gamma_1;
      \ldots; \Gamma _{i - 1}$
      \paragraph{Based:} R.Davies, F. Pfenning
      \\ A modal analysis of staged computation, ACM 2001.
      \paragraph{Goal:} Treat the elimination rule for $\square A$
      differently - implicit - (box - unbox), no let-box like we had
      before.

      We use $\Psi$ for a context stack. This will keep track of the
      order that assumptions were added (we will know in what world it
      was introduced).
      \\ $\Psi = \cdot; \Gamma_1 ; \Gamma_2 ; \ldots ; \Gamma_n$
      \paragraph{Variable Rule}
      \begin{prooftree}
        \AXC{$x : A \in \Gamma$}
        \UIC{$\Psi; \Gamma \vdash x : A$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Psi; \Gamma; \cdot \vdash M : A$}
        \UIC{$\Psi; \Gamma \vdash box\ M : \square A$}
      \end{prooftree}
      Here we force ourselves not to refer directly to the assumptions
      we have from the other worlds, adding a new assumption from the
      current world.
      \begin{prooftree}
        \AXC{$\Psi; \Gamma \vdash M : \square A$}
        \UIC{$\Psi;\Gamma ; \Gamma_1 ; \ldots ; \Gamma_n \vdash
          unbox_n\ M : A$}
      \end{prooftree}
      We import the fact that $A$ is valid in our current world, have
      to bring in the other worlds.
      \paragraph{Note:} $n$ can be $0$. This rule degenerates to:
      \begin{prooftree}
        \AXC{$\Psi; \Gamma \vdash M : \square A$}
        \UIC{$\Psi;\Gamma \vdash
          unbox_0\ M : A$}
      \end{prooftree}
      Properties such as reflexivity and transitivity will be
      reflected in the operations and structural properties of context
      stacks.
      \paragraph{Local Soundness}
      \begin{center}
        \AXC{$\mathcal{D}$}
        \noLine
        \UIC{$\Psi; \Gamma; \cdot \vdash M : A$}
        \RL{$\square$ I}
        \UIC{$\Psi; \Gamma \vdash box\ M : \square A$}
        \UIC{$\Psi; \Gamma; \Gamma_1 ; \ldots ; \Gamma_n \vdash
          unbox_n\ (box\ M) : A$}
        \DP
        \begin{tabular}{l}
          Modal fusion + modal weakening on $\mathcal{D}$
          \\ $\implies \Psi; \Gamma; \Gamma_1; \ldots; \Gamma_n \vdash \{n/1\} M : A$
          \\ where $\{n/1\}$ means replace index $1$ by $n$
        \end{tabular}
      \end{center}
      Two weakening properties used:
      \begin{enumerate}
      \item Weakening within a context $\Gamma$.
      \item Weakening with respect to context stacks. In particular:
        If $\Psi; \Gamma \vdash A$ true then $\Psi; \Gamma; \Gamma_1;
        \ldots; \Gamma_n \vdash A$ true
      \end{enumerate}
      \paragraph{Example:} Assume there is an $x : A$ in $\Gamma$
      s.t. $\Psi ; \Gamma \vdash x : \square A$. What is the witness/rule that
      allows us to prove: $\Psi ; \Gamma; \Gamma_1 ; \ldots ; \Gamma_n
      \vdash A$? Use unboxing similar to in local soundness:
      $\Psi ; \Gamma; \Gamma_1 ; \ldots ; \Gamma_n
      \vdash unbox_n\ x : A$. Keeping these indices is mainly only
      useful from a programming point of view (so we'll know where the
      assumption comes from), but otherwise we could get rid of it.
      \\ Just weakening isn't enough to prove soundness, it only does
      the transformation: $\Psi; \cdot \to \Psi; \cdot ; \Gamma_1 ;
      \ldots ; \Gamma_n$. We require an additional thing called fusion.
      \paragraph{Context Fusion (Modal Fusion)}
      If $\Psi; \Gamma; \Gamma' ; \Psi' \vdash C$ true then $\Psi;
      (\Gamma, \Gamma') ; \Psi' \vdash C$ true
      \\ Can only hold if we allow reflexivity ($\Gamma$ is accessible
      from $\Gamma$)
      \paragraph{Example}
      \begin{prooftree}
        \AXC{}
        \RL{var}
        \UIC{$\square(A \supset B) \vdash \square (A \supset B)$}
        \RL{$\square_1$ E}
        \UIC{$\square(A \supset B); A \vdash A \supset B$ true}
        \AXC{}
        \RL{var}
        \UIC{$\square(A \supset B); A \vdash A$ true}
        \RL{$\supset$ E}
        \BIC{$\square(A \supset B); A \vdash B$ true}
      \end{prooftree}
      How does this change when we use modal fusion?
      \begin{prooftree}
        \AXC{}
        \RL{var}
        \UIC{$\square(A \supset B), A \vdash \square (A \supset B)$ true}
        \RL{$\square_0$ E}
        \UIC{$\square(A \supset B), A \vdash A \supset B$ true}
        \AXC{}
        \RL{var}
        \UIC{$\square(A \supset B), A \vdash A$ true}
        \RL{$\supset$ E}
        \BIC{$\square(A \supset B), A \vdash B$ true}
      \end{prooftree}
      So we see that the index of the unbox changes.
      \paragraph{Local Completeness}
      \begin{center}
        \AXC{$\mathcal{D}$}
        \noLine
        \UIC{$\Psi; \Gamma \vdash \square A$ true}
        \DP
        $\implies$
        \AXC{$\mathcal{D}$}
        \noLine
        \UIC{$\Psi; \Gamma \vdash \square A$ true}
        \RL{$\square$ E}
        \UIC{$\Psi; \Gamma; \cdot \vdash A$ true}
        \RL{$\square$ I}
        \UIC{$\Psi; \Gamma \vdash \square A$ true}
        \DP
      \end{center}
      \subsection{Translating explicit (box - let box) to implicit
        (box - unbox)}
      \begin{tabular}{l l}
        $\lambda x.let\ box\ u = x \ in\ u : \square A \supset A$& $\to \lambda x.unbox\ (x)$
      \end{tabular}
      \\ However we need to keep track of the depths of the lets for
      the index of unboxing.
      \\ Call the explicit box system $E$, the implicit box system
      $M$.
      \paragraph{Environment} $\rho := \cdot \mid \rho, box\ u = E$
      \paragraph{Environment stack} $R := \cdot \mid R ; \rho$
      \\ $\underbrace{R}_{\text{Given the environment stack}} \triangleright E \to
      M$
      \begin{prooftree}
        \AXC{}
        \RL{tx\_var}
        \UIC{$R \triangleright x \to x$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$R \triangleright E \to M$}
        \RL{tx\_lam}
        \UIC{$R \triangleright \lambda x. E \to \lambda x. M$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$R; \cdot \triangleright E \to M$}
        \UIC{$R \triangleright box\ E \to box\ M$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$R; \rho, box\ u = E_1 \triangleright E_2 \to M$}
        \UIC{$R, \rho \triangleright let\ box\ u = E_1\ in\ E_2 \to M$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$R_0; \rho_n' \triangleright E \to M$}
        \UIC{$R \triangleright u \to unbox_n\ M$}
      \end{prooftree}
      where $R$ is $R_0; \underbrace{\rho_n}_{\rho_n', box\ u = E,
        \rho_n''} ; \ldots ; \rho_1$. So we force things in-line with
      their index.

      What is the relationship between context stacks $(\Psi; \Gamma)$
      and the ``global'' context $\Delta$?
      \\ $\Psi; \Gamma \models R : \Delta$
      \\ Intuitively:
      \begin{prooftree}
        \AXC{$\Theta_n; \ldots ; \Theta_{i-1}l \Gamma_i \vdash \rho_i : \Theta_i$}
        \UIC{$\Psi_0; \Gamma_n; \ldots; \Gamma_0 \vdash \cdot; \rho_n;
          \ldots ; \rho_0 : \Delta$}
      \end{prooftree}
      Where $\Delta$ is $\Theta_n, \Theta_{n-1}, \ldots,
      \Theta_0$, we have to carve it up into different subsets in
      order to split it into different sections $\rho_i$, since
      $\Delta$ is one flat object. $\Theta_i$ has access to each of
      the previous $\Theta_j$ (as we see above).
      \paragraph{Soundness Theorem} If $\Delta, \Gamma
      {\vdash}_e E : A$, $R \triangleright E \to M$ and
      $\Psi; \Gamma \models R : \Delta$ then
      $\Psi; \Gamma \vdash M : A$ (need to recover what $\Psi$ is,
      which is why we have the third assumption to tell us something
      about $R$ from $\Psi; \Gamma$).
      \paragraph{Case:} \AXC{}
      \RL{tx\_var}
      \UIC{$R \triangleright x \to x$}
      \DP
      \\
      \begin{tabular}{l l}
        $\Delta; \Gamma {\vdash}_e x : A$& by assumption
        \\ $x : A \in \Gamma$ & by variable rule (e)
        \\ $\Psi; \Gamma {\vdash}_i x : A$ & by var-rule (i)
      \end{tabular}
      \paragraph{Case:} \AXC{$R \triangleright E \to M$}\UIC{$R
        \triangleright \lambda x.E \to \lambda x . M$}\DP
      \\
      \begin{tabular}{l l}
        $\Delta; \Gamma \vdash \lambda x.M : A$& by assumption
        \\ $\Delta; \Gamma, x:A_1 \vdash M: A_2$ and $A = A_1 \to A_2$ & by assumption
        \\ $\Psi; \Gamma \models R : A$ & by assumption
        \\ $\Psi; \Gamma, x : A_1 \models R : \Delta$ & by weakening
        \\ $\Psi; \Gamma, x : A_1 {\vdash}_i M : A_2$ & by i.h.
        \\ $\Psi ; \Gamma {\vdash}_i \lambda x.M : A_1 \to A_2$ & by tx\_lam (i)
      \end{tabular}
      \section{03/28/19}
      \subsection{Recap of Modal Logic}
      \paragraph{Explicit}
      $\Delta; \Gamma \vdash E : A$
      \\ $E := \ldots \mid \ box\ E \mid let\ box\ u = E_1 \
      in \ E_2$
      \\ $\Delta$ contains assumptions, $A$ valid
      \\ $\Gamma$ contains assumptions, $A$ true
      \paragraph{Implicit} Called implicit because we don't have let
      box.
      \\ $\underbrace{\Gamma_1 ; \ldots ; \Gamma_n \vdash M :
        A}_{\text{context stack}}$
      \\ $M := \ldots \mid box\ M \mid unbox_n\ M$
      \begin{prooftree}
        \AXC{$\Sigma; \Gamma; \cdot \vdash M : A$}
        \UIC{$\Sigma; \Gamma \vdash box\ M : \square A$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Sigma; \Gamma \vdash M : \square A$}
        \UIC{$\Sigma; \Gamma; \Gamma_1; \ldots; \Gamma_n \vdash
          unbox_n : A$}
      \end{prooftree}
      Where $\Sigma$ is the context stack.
      \paragraph{Example:}
      \begin{prooftree}
        \AXC{}
        \UIC{$\Gamma_0 \vdash \square (A \supset B)$}
        \RL{$\square$ E$_{n=1}$}
        \UIC{$\Gamma_0 ; \cdot \vdash A \supset B$}

        \AXC{}
        \RL{$\square$ E$_{n=1}$}
        \UIC{$\Gamma_0 ; \cdot \vdash A$}
        \RL{$\supset$ E}
        \BIC{$(\square (A \supset B), \square A); \cdot \vdash B$}
        \RL{$\square$ I}
        \UIC{$(\underbrace{\square (A \supset B), \square A}_{\Gamma_0}) \vdash B$}
      \end{prooftree}
      Note that the empty context is still a context, so unboxing the
      empty context still requires $n=1$.

      Proof term:
      \begin{itemize}
      \item Implicit:
        $\lambda x : \square (A \supset B).\lambda y: \square A. box ((unbox_1\ x) (unbox_1\ y))$
      \item Explicit:
        $\lambda x : \square (A \supset B).\lambda y: \square A. let\
        box\ u = x\ in\ let\ box\ v = y\ in\ box(uv)$
      \end{itemize}
      \begin{prooftree}
        \AXC{}
        \UIC{$\square A \vdash \square A$}
        \RL{$\square$ E$_{n=2}$}
        \UIC{$\square A; \cdot ; \cdot \vdash A$}
        \RL{$\square$ I}
        \UIC{$\square A ; \cdot \vdash \square A$}
        \RL{$\square$ I}
        \UIC{$\square A \vdash \square \square A$}
      \end{prooftree}
      \begin{itemize}
      \item Implicit: $\lambda x : \square A. box(box\ (unbox_2\ x))$
      \item Explicit: $\lambda x:\square A. let\ box\ u = x\ in\ box$
      \end{itemize}
      Proof for the explicit proof term:
      \begin{prooftree}
        \AXC{}
        \RL{}
        \UIC{$\cdot ; \square A \vdash \square A$}
        \AXC{}
        \RL{}
        \UIC{$A$ valid$; \cdot \vdash A$}
        \RL{$\square$ I}
        \UIC{$A$ valid$; \square A \vdash \square A$}
        \RL{$\square$ E}
        \BIC{$\cdot ; \square A \vdash \square \square A$}
      \end{prooftree}
      The goal was to show that the implicit and explicit systems are
      equivalent. In order to do so, we introduced the idea of an
      environment, that allows us to lookup what we need to unbox. We
      build and keep track of what these $u$ variables are bound to.
      \paragraph{Environment} $\rho := \cdot \mid \rho_1\ box\ u = E$
      \paragraph{Environment Stack} $R : = \cdot \mid R; \rho$
      \\ $\Sigma; \Gamma \models R : \Delta$
      \\ $\Delta; \Gamma \models \rho : \Delta'$
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \models \rho : \Delta'$}
        \AXC{$\Delta ;\Gamma \vdash E : \square A$}
        \BIC{$\Delta; \Gamma \models \underbrace{\rho, box\ u =
            E}_{\substack{let\ box\ u_1 = E_1\ in \\ let\ box\ u_2 =
              E_2\ in \\ \vdots}} :
          \underbrace{\Delta', u :A}_{\text{valid assumption}}$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{}
        \UIC{$\Delta; \Gamma \models \cdot : \cdot$}
      \end{prooftree}

      Environment Stacks:
      \begin{prooftree}
        \AXC{$\Sigma \vdash R : \Delta_1$}
        \AXC{$\Delta_1; \Gamma \vdash \rho : \Delta_2$}
        \BIC{$\Sigma; \Gamma \vdash R : \rho : (\Delta_1, \Delta_2)$}
      \end{prooftree}
      We can carve out our full list of global assumptions $\Delta$
      into these sections $\rho$ for a context stack. Recall that in
      the explicit language we kind of ``forget'' how many boxes we
      have to traverse, as long as its valid we have access to it.
      \paragraph{Theorem:} If $\Sigma; \Gamma \models R; \rho :
      \Delta$, $\Delta; \Gamma \vdash E : A$ and $(R ;
      \rho) \triangleright E \to M$ (Translation) then $\Sigma; \Gamma
      \vdash M : A$
      \paragraph{Case:} (Variable $x : A \in \Gamma$)
      \\\begin{tabular}{l l}
        $(R; \rho) \triangleright x \to x$&
        \\ $\Delta; \Gamma \vdash_e x : A$ & by assumption
        \\ $x:A \in \Gamma$ & by assumption
        \\ $\Sigma, \Gamma \vdash_i x : A$
        \end{tabular}
        \paragraph{Case:} Functions
        \\ \AXC{$(R; \rho) \triangleright E \to M$}
        \UIC{$(R; \rho) \triangleright \lambda x. E \to \lambda x. M$}
        \DP
        \\
        \begin{tabular}{l l}
          $\Delta; \Gamma \vdash \lambda x. E : A$& by assumption
          \\ $\Delta; \Gamma, x : B_1 \vdash E : B_2$ & by inversion
          \\ $A = B_1 \supset B_2$
          \\ $\Sigma; \Gamma \models (R; \rho) : \Delta$ & by assumption
          \\ $\Sigma; (\Gamma, x ; B_1) \models (R; \rho) : \Delta$ & by weakening contexts in a context stack
          \\ $\Sigma; (\Gamma, x : B_1) \vdash M : B_2$ & by IH
          \\ $\Sigma; \Gamma \vdash \lambda x. M : B_1 \supset B_2$ & by $\supset$ I
        \end{tabular}
        \paragraph{Case:} Box
        \\ \AXC{$R; \rho; \cdot \triangleright E \to M$}
        \UIC{$(R; \rho) \triangleright box\ E \to box\ M$}
        \DP
        \\
        \begin{tabular}{l l}
          $\Delta; \Gamma \vdash box\ E : \square A$& by assumption
          \\ $\Delta; \cdot \vdash E : A$ & by inversion on $\square$ I
          \\ $\Sigma; \Gamma \models R; \rho : \Delta$ & by assumption
          \\ \colorbox{orange}{$(\Sigma; \Gamma); \cdot \models R; \rho ; \cdot : \Delta$} & by $\textcolor{orange}{\Delta ; \cdot \Gamma \cdot : \cdot}$ and above line (see proof tree below) \\ & (note the RHS gives us $(\Delta, \cdot)$, but that's the same as $\Delta$)
          \\ $(\Sigma; \Gamma); \cdot \vdash M : A$ & by IH
          \\ $\Sigma; \Gamma \vdash box\ M : \square A$ & by $\square$ I (implicit)
        \end{tabular}
      \begin{prooftree}
        \AXC{$\Sigma' \vdash R' : \Delta_1$}
        \AXC{$\Delta_1; \textcolor{orange}{\Gamma} \vdash \rho : \Delta_2$}
        \BIC{$\Sigma'; \textcolor{orange}{\Gamma} \vdash R' : \rho : (\Delta_1, \Delta_2)$}
      \end{prooftree}
      \paragraph{Case:} Let-Box
      \\ \AXC{\colorbox{orange}{$R; (\rho, box\ u = E_1) \triangleright E_2 \to M$}}
      \UIC{$(R; \rho) \triangleright let\ box\ u = E_1 \ in E_2 \to
        M$}
      \DP
      \\
      \begin{tabular}{l l}
        $\Delta; \Gamma \vdash E_1 : \square B$& by inversion on $\square E$
        \\ \colorbox{orange}{$(\Delta, u : B\ valid); \Gamma \vdash E_2 : A$} & by inversion on $\square$ E
        \\ $\Sigma; \Gamma \models R ; \rho : \Delta$ & by assumption
        \\ $\Sigma \models R : \Delta_1$ & by typing def on env.\ stacks
        \\ $\Delta_1 ; \Gamma \vdash \rho : \Delta_2$, $\Delta = \Delta_1, \Delta_2$ & by typing def of env.\ stacks
        \\ $(\underbrace{\Delta_1, \Delta_2}_{\Delta}) ; \Gamma \vdash E_1 : \square B$ & from above
        \\ $\Delta_1; \Gamma \vdash \rho, box\ u = E_1 : (\Delta_2, u:B\ valid)$
        \\ \colorbox{orange}{$\Sigma; \Gamma \models; (\rho, box\ u = E_1) : \Delta, u : B\ valid$} & by typing def of env.\ stacks
        \\ $\Sigma; \Gamma \vdash M : A$ & \colorbox{orange}{by IH}
      \end{tabular}
      \paragraph{Case:} $u$ (from $\Delta$)
      \\\AXC{$(R; \rho_n') \triangleright E \to M$}
      \UIC{$(R; \underbrace{\rho_n}_{\rho_n', box\ u = E, \rho_n''};
        \ldots; \rho_1) \triangleright u \to unbox_n\ M$}
      \DP
      \\
      \begin{tabular}{l l}
        $\underbrace{\Sigma}_{\Sigma_0; \Gamma_n; \ldots; \Gamma_1}; \Gamma \models R; \rho_n; \ldots; \rho_1 : \underbrace{\Delta_0, \Delta_n \ldots, \Delta_1}_{\Delta}$& by assumption
        \\ $\Delta_0 \vdash \rho_n : \Delta_n$ and $\Delta_n = \Delta_n', u : A\ valid, \Delta_n'$& typing def on env.\ stacks $n$ times
        \\ $\Delta_0, \Delta_n'; \Gamma_n \vdash E : \square A$ & by previous rules
        \\ $\Sigma; \Gamma_n \vdash M : \square A$ & by IH
        \\ $\Sigma; \Gamma_n ; \ldots; \Gamma_1; \Gamma \vdash unbox_n\ M : A$ & by typing rule for $\square$ E$_n$
      \end{tabular}
      \section{04/02/19}
      \subsection{Modality: Possibility}
      \begin{tabular}{l l}
        $A$ true& is a proposition $A$ true? (is there a proof for $A$ true?)
        \\ $A$ valid & $A$ is true in every possible world
        \\ & $\to$ we cannot presuppose any knowledge about $A$
        \\ & $\to$ Intervalize validity using $\square$A
        \\ & $A$ is necessarily true
        \\ $A$ poss & $A$ is true in \underline{some} world
        \\ & $\to A$ is possibly true
        \\ & $\to$ Internalizing possibility using $\diamond A$
        \\ & $\to$ How can we use the knowledge that $A$ is possible?
      \end{tabular}
      Certain things to keep in mind:
      \begin{enumerate}
      \item If $A$ is true, then $A$ is possible.
      \item If $A$ is possible and assuming $A$ is true $C$ is
        possible, then $C$ is possible. We can encapsulate the logic
        of $A$ being possible by further getting something else possible.
      \end{enumerate}
      $$\underbrace{\Delta}_{\substack{\text{global}\\A\text{
            valid}}};
      \underbrace{\Gamma}_{\substack{\text{local}\\A\text{ true}}}
      \vdash A \text{ true}$$
      \paragraph{Intro for Diamond:}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash A$ poss}
        \RL{$\diamond$ I}
        \UIC{$\Delta; \Gamma \vdash \diamond A$ true}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash A$ true}
        \UIC{$\Delta; \Gamma \vdash A$ poss}
      \end{prooftree}
      This is a silent rule, we don't need to use this because
      $A$ is true means $A$ is possible, however we can use it to be explicit.
      \paragraph{Elim for Diamond:}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash \diamond A$ true}
        \AXC{$\Delta; A$ true $\vdash C$ poss}
        \BIC{$\Delta; \Gamma \vdash C$ poss}
      \end{prooftree}
      \paragraph{Examples}
        {$\square (A \supset B) \supset \diamond A \supset \diamond B$ true}
      \begin{prooftree}
        \AXC{}
        \UIC{$(A \supset B)$ valid$; \diamond A$ true $\vdash \diamond
          A$ true}
        \AXC{}
        \UIC{$(A \supset B)$ valid$; A$ true $\vdash A \supset B$
          true}
        \AXC{}
        UIC{$\ldots ; A$ true $\vdash A$ true}
        \BIC{$(A \supset B)$ valid$; A$ true $\vdash B$ true}
        \UIC{$(A \supset B)$ valid$; A$ true $\vdash B$ poss}
        \RL{$\diamond$ E}
        \BIC{$(A \supset B)$ valid$; \diamond A$ true $\vdash B$ poss}
        \RL{$\diamond$ I}
        \UIC{$(A \supset B)$ valid$; \diamond A$ true $\vdash \diamond
          B$}
      \end{prooftree}
      \paragraph{Introducing proof terms}
      Proof Terms $M := x \mid \lambda x. M \mid M\ N \mid \langle
      M,N \rangle \mid \ldots \mid box(M) \mid let\ box\ u = M\ in\ N
      \mid dia \ E$
      \\ Proof Expressions $E:= M \mid let\ dia\ x = M\ in\ E$
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash E : A$ poss}
        \RL{$\diamond$ I}
        \UIC{$\Delta; \Gamma \vdash dia\ E : \diamond A$ true}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash M : \diamond A$ true}
        \AXC{$\Delta; A$ true $\vdash E : C$ poss}
        \BIC{$\Delta; \Gamma \vdash let\ dia\ x = M\ in\ E : C$ poss}
      \end{prooftree}
      \begin{prooftree}
        \AXC{}
        \RL{hyp$^*$}
        \UIC{$\cdot ; A$ true $\vdash A$ poss}
        \RL{$\diamond$ I}
        \UIC{$\cdot; A$ true $\vdash \diamond A$ true}
        \RL{$\supset$ I}
        \UIC{$\cdot; \cdot \vdash A \supset \diamond A$ true}
      \end{prooftree}
      Proof term for this is $\lambda x : A . dia\ x$

      Proof term for previous example is $let\ box\ u = x\ in \
      \lambda x:\square(A \supset B).\lambda y: \diamond A. dia(let\
      dia\ y' = y\ in\ u\ y')$
      \paragraph{Local Soundness}
      \begin{center}
        \AXC{$\mathcal{D}$}
        \noLine
        \UIC{$\Delta; \Gamma \vdash A$ poss}
        \RL{$\diamond$ I}
        \UIC{$\Delta; \Gamma \vdash \diamond A$ true}
        %
        \AXC{$\mathcal{E}$}
        \noLine
        \UIC{$\Diamond; A$ true $\vdash C$ poss}
        \BIC{$\Delta; \Gamma \vdash C$ poss}
        \DP
        $\implies$
        \begin{tabular}{c}
          $\mathcal{E}'$
          \\ $\Delta; \Gamma \vdash C$ poss
          \\ $\mathcal{E}'$ comes from 2.
        \end{tabular}
      \end{center}
      (Note that 2. says: If $A$ is possible and assuming $A$ is true,
      $C$ is possible, then $C$ is possible)

      This gives us another substitution lemma. If $\Delta; \Gamma
      \vdash E : A$ poss and $\Delta; x:A$ true $\vdash F : C$ poss then
      $\Delta, \Gamma \vdash \langle E/x \rangle F$ poss

      With the reduction rule: $let\ dia\ x = dia\ E\ in\ N \implies
      \langle E/x\rangle N$.

      What is the substitution here? Is it the usual substitution?
      Recall that $[N/x] M$ and $\llbracket N/u \rrbracket M$ were
      defined inductively on $M$, since that's also what allowed us to
      prove:
      \begin{itemize}
      \item  If $\Delta; \Gamma \vdash N : A$ true and $\Delta; \gamma, x
        : A $ true $\vdash M : C$ true then $\Delta, \Gamma \vdash [N/x]
        M:C$ true.
      \item If $\Delta; \cdot \vdash A$ true and $\Delta, u : A$ valid
        $;\Gamma \vdash M : C$ true then $\Delta, \Gamma \vdash
        \llbracket N/u \rrbracket M : C$ true
      \end{itemize}
      We went from the proof of $M$ to its leaves and then we plugged
      in $N$.

      But the new substitution rule tries to modify things that were
      only introduced in the diamond operator (working on the $E$
      instead of $N$), which is why we use a new symbol to indicate
      this type of substitution.

      Expr. $E := M \mid let\ dia\ x = M\ in\ E$
      \\ $\langle N/x \rangle F = [N/x] F$ (if it is in $M$, we
      fallback to the usual operation)
      \\ $\langle let\ dia\ y = N\ in E /x \rangle F = let\ dia\ y =
      N\ in \langle E/x \rangle F$ (we pull out the let, rearranging
      structure)

      To prove the substitution lemma, we'd do induction on the first
      judgment/derivation.
      \paragraph{Case} $E = M$
      \\
      \begin{tabular}{l l}
        $\Delta; \Gamma \vdash M$ poss& by assumption
        \\ $\Delta; \Gamma \vdash M$ true & (that's by the case we are in, i.e. inversion not on let but silent rule)
        \\ $\Delta; x : A$ true $\vdash F : C$ poss
        \\ $\Delta; \Gamma \vdash [M/x] F : C$ poss & (reg. subst)
      \end{tabular}
      \section{04/04/19}
      What we've seen so far for $S4$:
      \\
      \begin{tabular}{l l}
        $A$ true& $A$ is true ``here'' (locally)
        \\ $A$ valid, $\square A$ & $A$ true holds in \underline{every} accessible world
        \\ $A$ pos, $\diamond A$ & $A$ true holds in \underline{some} accessible world
      \end{tabular}
      \\ Computationally, we can say:
      \\\begin{tabular}{l l}
          $\square A$& mobile code of type $A$
          \\ $\diamond A$ & remote `$A$'
        \end{tabular}
        \\ Proof terms $M := x \mid \lambda x. M \mid M\ N \mid box\
        M \mid let\ box\ u = M\ in\ N\mid dia\ E$
        \\ Proof Expression $E, F:= M \mid let\ dia\ x = M\ in\ E$
      \paragraph{Box}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash M : \square A$}
        \AXC{$\Delta, u :: A$ valid $\vdash N : C$}
        \BIC{$\Delta, \Gamma \vdash let\ box\ u = M : C\ in\ N$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Delta; \cdot \vdash M : A$}
        \UIC{$\Delta; \Gamma \vdash box\ M : \square A$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$u :: A$ valid $\in \Delta$}
        \UIC{$\Delta; \Gamma \vdash u : A$}
      \end{prooftree}
      \paragraph{Diamond}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash M : \diamond A$}
        \AXC{$\Delta; x : A \vdash E \div C$ poss}
        \BIC{$\Delta; \Gamma \vdash let\ dia\ x = M\ in\ E \div C$ poss}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash E \div A$ poss}
        \UIC{$\Delta; \Gamma \vdash dia\ E: \diamond A$}
      \end{prooftree}
      \begin{prooftree}
        \AXC{$\Delta; \Gamma \vdash M : A$}
        \UIC{$\Delta; \Gamma \vdash M \div A$ poss}
      \end{prooftree}
      Where $\div$ is equivalent to $:$ but used to put emphasis on
      the fact that $A$ poss (used in the paper), but also redundant
      as we can just use $\div$ instead of writing poss.

      Is $(A \supset B) \supset \diamond A \supset \diamond B$ true?
      \\ Option 1, proving from $B$ true:
      \begin{prooftree}
        \AXC{}
        \UIC{$\cdot; x : A \supset B, y : \diamond A \vdash A \supset
          B$ true}
        \AXC{? Stuck because we cannot use $\diamond$ E}
        \UIC{$\cdot; x : A \supset B, y : \diamond A \vdash A$ true}
        \BIC{$\cdot ; x : A \supset B, y: \diamond A \vdash B$ true}
        \RL{coercion poss-true}
        \UIC{$\cdot ; x : A \supset B, y: \diamond A \vdash B$ poss}
        \UIC{$\cdot; x : A \supset B, y: \diamond A \vdash \diamond B$
        true}
    \end{prooftree}
    Note that if we had no distinction between truth and possibility,
    we couldn't be stuck here and we'd be able to prove something that
    isn't true.

    The following is ``ill-typed'' (not even syntactically legal)
    \\ $\lambda x : A \supset B. \lambda y : \diamond A. dia \underline{(x (let\
      dia\ w = y\ in\ w))}$
    \\ Would be legal with no distinction between truth and possibility.
      \\ Option 2:
      \begin{prooftree}
        \AXC{}
        \UIC{$\cdot; x : A \supset B, y : \diamond A \vdash \diamond
          A$ true}
        \AXC{? Stuck, $A \supset B$ only true locally, lost information}
        \UIC{$\cdot; w : A \vdash B$ poss}
        \BIC{$\cdot ; x : A \supset B, y: \diamond A \vdash B$ poss}
        \UIC{$\cdot; x : A \supset B, y: \diamond A \vdash \diamond B$
        true}
    \end{prooftree}
    \paragraph{Another Example}
    \begin{prooftree}
      \AXC{}
      \UIC{$\cdot; x : \diamond \square A \vdash \diamond \square A$
        true}
      \AXC{}
      \UIC{$\cdot ; y : \square A \vdash A$ poss}
      \RL{$\diamond$ E}
      \BIC{$\cdot; x : \diamond \square A \vdash A$ poss}
      \UIC{$\cdot; x : \diamond \square A \vdash \diamond A$ true}
      \UIC{$\cdot ; \cdot \vdash \diamond \square A \supset \diamond A
        $ true}
    \end{prooftree}
    Alternatively, to get $A$ poss:
    \begin{prooftree}
      \AXC{$\Delta; \Gamma \vdash M : \square A$}
      \AXC{$\Delta, u ::A$ valid$; \Gamma \vdash N \div C$ poss}
      \BIC{$\Delta; \Gamma \vdash let\ box\ u = M\ in\ N \div C$ poss}
    \end{prooftree}
    This rule is not required in the proof above, but it could become
    necessary if we have nested $\square$ and $\diamond$.

    $\square A \supset \diamond \square A$ is true.
    \\ $\diamond (A \land B) \supset \diamond A \land \diamond B$ is
    true.
    \\ $\diamond A \land \diamond B \supset \diamond(A \land B)$ is
    not true, the diamonds on the LHS can be for different worlds.
    \\ $\diamond \square A \supset \square A$ is not true, we do not
    have symmetry.

    \begin{prooftree}
      \AXC{}
      \UIC{$\cdot; x : \diamond(A \land B) \vdash \diamond(A \land B)$
        true}
      \AXC{}
      \UIC{$\cdot; y : A \land B \vdash A \land B$ true}
      \RL{$\land$ E$_1$}
      \UIC{$\cdot; y : A \land B \vdash A$ true}
      \UIC{$\cdot; y : A \land \vdash A$ poss}
      \BIC{$\cdot; x : \diamond (A \land B) \vdash A $ poss}
      \UIC{$\cdot; x : \diamond (A \land B) \vdash \diamond A$ true}
    \end{prooftree}
    Where we commit to a world and show that we can get $A$ from it.
    \paragraph{Going back to substitution and reductions}
    ~\\
    \begin{tabular}{l l}
      $let\ box\ u = box\ M\ in\ N$&$\implies \llbracket M/x \rrbracket$
      \\ $let\ dia\ x = dia\ E\ in\ F$ & $\implies \langle E/x \rangle F$
      \\ $(\lambda x . N) M$ & $\implies [M/x]N$
    \end{tabular}
    \\ $\langle M/x \rangle F = [M/x] F$
    \\ $\langle let\ dia\ y = M\ in\ E/x \rangle F = let\ dia\ y = M\
    in \langle E/x \rangle F$
    \\ If $\Delta; \Gamma \vdash E \div A$ poss and $\Delta; x  : A$
    true $\vdash F \div C$ poss then $\Delta; \Gamma \vdash \langle
    E/x \rangle F \div C$ poss.
    \\ If $\Delta; \Gamma \vdash E : A$ true and $\Delta; x  : A$
    true $\vdash F \div C$ poss then $\Delta; \Gamma \vdash [M/x]F \div C$ poss.
    \paragraph{Case} $\mathcal{D} = $
    \AXC{$\mathcal{D'}$}
    \noLine
    \UIC{$\Delta; \Gamma \vdash M : A$ true}
    \UIC{$\Delta; \Gamma \vdash M \div A$ poss}
    \DP
    \\
    \begin{tabular}{l l}
      $\Delta; x : A$ true $\vdash F \div C$ poss& by ass
      \\ $\Delta; \Gamma \vdash [M/x]F \div C$ poss & by IH (2)
      \\ $\Delta; \Gamma \vdash \langle M/x \rangle F \div C$ poss & by def of $\langle \cdot \rangle$
    \end{tabular}
    \paragraph{Case} $\mathcal{D} =$
    \AXC{$\mathcal{D}_1$}
    \noLine
    \UIC{$\Delta; \Gamma \vdash M : \diamond B$}
    \AXC{$\mathcal{D}_2$}
    \noLine
    \UIC{$\Delta; x : B$ true $\vdash E \div A$ poss}
    \RL{$\diamond$ E}
    \BIC{$\Delta; \Gamma \vdash let\ dia\ y = M\ in\ E \div A$ poss}
    \DP
    \\
    \begin{tabular}{l l}
      $\Delta; \underline{x : A}$ true $\vdash F \div C$ poss& by ass
      \\ $\Delta; y : B$ true $\vdash \langle E/x \rangle F \div C$ poss & by IH(1)
      \\ $\Delta; \Gamma \vdash let\ dia\ y = M\ in\ \langle E/x \rangle F \div C$ poss & by $\diamond$ E
      \\ $\Delta; \Gamma \vdash \langle let\ dia\ y = M\ in\ E/x \rangle F \div C$ poss & by def $\langle \cdot \rangle$
    \end{tabular}
    \paragraph{Case}
    \AXC{$\mathcal{D}'$}
    \noLine
    \UIC{$\Delta; x : A$ true $\vdash N : C$ true}
    \UIC{$\Delta; x : A$ true $\vdash N \div C$ poss}
    \DP
    \\
    \begin{tabular}{l l}
      $\Delta; \Gamma \vdash M : A$ true& by ass
      \\ $\Delta; \Gamma \vdash [M/x]N : A$ true & by substitution lemma for $A$ true
    \end{tabular}
    \paragraph{Case} $\mathcal{D} =$
    \AXC{$\mathcal{D}_1$}
    \noLine
    \UIC{$\Delta; x : A \vdash N : \diamond B$}
    \AXC{$\mathcal{D}_2$}
    \noLine
    \UIC{$\Delta; y : B$ true $\vdash E \div C$ poss}
    \RL{$\diamond$ E}
    \BIC{$\Delta; x : A \vdash let\ dia\ y = N\ in\ E \div C$ poss}
    \DP
    \\
    \begin{tabular}{l l}
      $\Delta; \Gamma \vdash M : A$ true & by ass
      \\ $\Delta; \Gamma \vdash [M/x]N: \diamond B$ true & by substitution lemma for ($A$ true)
      \\ $\Delta; \Gamma \vdash let\ dia\ y = [M/x]N\ in\ E \div C$ poss & by $\diamond$ E
      \\ $\Delta; \Gamma \vdash [M/x](let\ dia\ y = N\ in\ E) \div C$ poss & by def of $[\cdot]$
    \end{tabular}

    The modality we've seen is equivalent to lax modality: $\diamond
    \square A = \circ A$
    \section{04/09/19}
    Earlier throughout the term, all of our assumptions had the same
    structure, they shared structural properties. Today we will see a
    different structure.
    \subsection{Linear Logic}
    \paragraph{Substructural Logic}
    Let's assume we want to model the following:
    \begin{enumerate}
    \item If one has one dollar, the none can buy a coke. $D \supset
      C$
    \item If one has one dollar, then one can buy a sandwich. $D
      \supset S$
    \end{enumerate}
    \begin{prooftree}
      \AXC{}
      \RL{}
      \UIC{$\Gamma \vdash D \supset C$ true}
      \AXC{}
      \RL{}
      \UIC{$\Gamma \vdash D$ true}
      \RL{$\supset$ E}
      \BIC{$\Gamma = D \supset C, D \supset S, \mathbf{D} \vdash C$ true}
      \AXC{}
      \RL{}
      \UIC{$\Gamma \vdash D \supset S$ true}
      \AXC{}
      \RL{}
      \UIC{$\Gamma \vdash D$ true}
      \RL{$\supset$ E}
      \BIC{$\Gamma \vdash S$ true}
      \RL{$\land$ I}
      \BIC{$D \supset C, \mathbf{D} \supset S, D \vdash C \land S$ true}
      \RL{$\supset$ I}
      \UIC{$D \supset C, D \supset S \vdash D \supset (C \land S)$ true}
    \end{prooftree}
    This proof is correct in our system, but it doesn't make sense in
    the real world, if you have one dollar you can't buy a coke
    \textbf{and} a sandwich. We could fix this by counting how many
    dollars we have or spending the money, however this will
    overcomplicate our logic. Notice that the assumption $D$ is used
    in both the left and right branches of the $\land$ I.
    \paragraph{Linear Logic} Every assumption is used
    \underline{exactly} once.
    \\ We don't have weakening, we have to use all our dollars, can't
    keep any.
    \paragraph{Affine Logic} Every assumption is used at most once.
    \paragraph{Relevant Logic} Every assumption is used at least once.
    \paragraph{Ordered Logic} Every assumption has to be used exactly
    once in the order it was introduced.
    \\
    \begin{tabular}{l | c c c}
      &exchange&weakening&contraction
      \\ Linear Logic & $\checkmark$ & $\times$ & $\times$
      \\ Affine Logic & $\checkmark$ & $\checkmark$ & $\times$
      \\ Relevant Logic & $\checkmark$ & $\times$ & $\checkmark$
      \\ Order Logic & $\times$ & $\times$ & $\times$
    \end{tabular}
    $$\underbrace{\Delta}_{\substack{\text{List
          of}\\\text{resources=}\\\text{assumptions}\\\text{that can
          be used}\\\text{exactly once}}} \vdash A \text{ true}$$
    \paragraph{Substitution principle}
    If $\Delta \vdash A$ true and $\Delta', A$ true $\vdash C$ true
    then $\Delta, \Delta' \vdash C$ true
    \paragraph{Simultaneous Conjunction} $A \otimes B$
    \\ ``Given some resources we can achieve both $A$ and $B$ at the
    same time.''
    \begin{prooftree}
      \AXC{$\Delta_1 \vdash A$ true}
      \AXC{$\Delta_2 \vdash B$ true}
      \BIC{$\Delta_1, \Delta_2 \vdash A \otimes B$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta_1 \vdash A \otimes B$ true}
      \AXC{$\Delta_2, A$ true$, B$ true $\vdash C$ true}
      \BIC{$\Delta_1, \Delta_2 \vdash C$ true}
    \end{prooftree}
    Very similar to the alternative conjunction rule we've seen many
    times, although in this case it is literally a different
    conjunction rule, we can get both $A$ and $B$ at the same time.

    \paragraph{Alternative Conjunction} Internal choice: With the set
    of resources we can achieve $A$ and $B$ - but \underline{not} at
    the same time! This sounds like a disjunction, but a disjunction
    is an external choice, i.e. the cashier chooses whether we get a
    coke or a sandwich, not us. In this case we get to choose.
    \begin{prooftree}
      \AXC{$\Delta \vdash A$ true}
      \AXC{$\Delta \vdash B$ true}
      \BIC{$\Delta \vdash A \& B$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta \vdash A \& B$ true}
      \UIC{$\Delta \vdash A$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta \vdash A \& B$ true}
      \UIC{$\Delta \vdash B$ true}
    \end{prooftree}
    \paragraph{Implication} $A \multimap B$
    \begin{prooftree}
      \AXC{$\Delta, A$ true $\vdash B$ true}
      \UIC{$\Delta \vdash A \multimap B$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta_1 \vdash A \multimap B$ true}
      \AXC{$\Delta_2 \vdash A$ true}
      \BIC{$\Delta_1, \Delta_2 \vdash B$ true}
    \end{prooftree}
    \paragraph{External Choice} $A \oplus B$
    \begin{prooftree}
      \AXC{$\Delta \vdash A$ true}
      \UIC{$\Delta \vdash A \oplus B$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta \vdash B$ true}
      \UIC{$\Delta \vdash A \oplus B$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta' \vdash A \oplus B$ true}
      \AXC{$\Delta, A$ true $\vdash C$ true}
      \AXC{$\Delta, B$ true $\vdash C$ true}
      \TIC{$\Delta, \Delta' \vdash C$ true}
    \end{prooftree}
    So $D \supset C$ and $D \supset S$ become $D \multimap C$ and $D
    \multimap S$. But say we want to buy multiple cokes, will we just
    copy the proposition multiple times? No. So now we want to
    distinguish between truth and validity like we have before.

    $$\overbrace{\Gamma}^{\text{unrestricted}};\underbrace{\Delta}_{\substack{\text{List
          of}\\\text{resources=}\\\text{assumptions}\\\text{that can
          be used}\\\text{exactly once}}} \vdash A \text{ true}$$
    To accommodate unrestricted (intuitionistic) assumptions, we want
    to distinguish between
    \\ $A$ valid - unrestricted
    \\ $A$ true - resource

    Internalize the fact that $A$ is valid
    \\ $\implies !A$ (``of course'')
    \begin{prooftree}
      \AXC{$\Gamma ; \cdot \vdash A$ true}
      \UIC{$\Gamma ; \cdot \vdash !A$ true}
    \end{prooftree}
    Since we don't have weakening, we can't allow additional resources
    on the LHS. This is a refinement of the box modality that we've
    seen.

    \begin{prooftree}
      \AXC{$\Gamma; \Delta \vdash !A$ true}
      \AXC{$\Gamma, A$ valid$; \Delta' \vdash C$ true}
      \BIC{$\Gamma; (\Delta, \Delta') \vdash C$ true}
    \end{prooftree}
    \paragraph{Menu} Formalizing a restaurant menu: $CAD(60)$
    \\ $\multimap$ (Soup \& Salad) ``internal choice'', you can choose
    one of these
    \\ $\otimes$ Salmon
    \\ $\otimes$ (Carrots $\oplus$ Asparagus) ``external choice'',
    this is a seasonal item, you have no choice as to whether carrots
    or asparagus are available
    \\ $\otimes ((CAD(5) \multimap Mousse) \& 1)$
    \\ $\otimes$ coffee $\otimes$
    $\underbrace{\text{!(Coffee)}}_{\text{unlimited refills}}$

    \paragraph{Top:} Consume all resources
    \begin{prooftree}
      \AXC{}
      \UIC{$\Delta \vdash$ T true}
    \end{prooftree}
    Useful because sometimes we might not use up resources,
    i.e. leftover money after buying meal from menu, flush additional resources.
    \paragraph{Unit:} Trivial Goal which requires \underline{no}
    resources
    \begin{prooftree}
      \AXC{}
      \UIC{$\cdot \vdash 1$ true}
    \end{prooftree}
    \begin{prooftree}
      \AXC{$\Delta \vdash 1$ true}
      \AXC{$\Delta' \vdash C$ true}
      \BIC{$\Delta, \Delta' \vdash C$ true}
    \end{prooftree}
    Useful for when things are optional, i.e. you can buy a dessert or
    skip it.
    \paragraph{Example}
    \begin{prooftree}
      \AXC{}
      \UIC{$\varphi; \cdot \vdash D \multimap C$ true}
      \AXC{}
      \UIC{$\varphi; D$ true $\vdash D$ true}
      \BIC{$D \multimap C$ valid$, D \multimap S$ valid$;D\ true
        \vdash C$ true}
      \AXC{}
      \UIC{$\varphi; \cdot \vdash D \multimap S$ true}
      \AXC{}
      \UIC{$\varphi; D$ true $\vdash D$ true}
      \BIC{$D \multimap C$ valid$, D \multimap S$ valid$;D\ true
        \vdash S$ true}
      \BIC{$D \multimap C$ valid$, D \multimap S$
        valid$;\underbrace{D,D}_{D\ true,D\ true} \vdash C
        \otimes S$ true}
    \end{prooftree}
    Two different formulations, $D \multimap D \multimap C \otimes S$
    \\ $D \otimes D \multimap C \otimes S$
\end{document}