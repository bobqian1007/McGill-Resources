\documentclass[12 pt]{article}
\usepackage{hyperref, fancyhdr, setspace, enumerate, amsmath,
  lastpage, amssymb, algpseudocode, bussproofs, tikz, listings,
  marvosym, stmaryrd, collectbox, wasysym}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{positioning}
\EnableBpAbbreviations
\usepackage[margin=1 in]{geometry}
\allowdisplaybreaks
% \usepackage[dvipsnames]{xcolor}   %May be necessary if you want to color links
\hypersetup{
  % colorlinks=true, %set true if you want colored links
  linktoc=all,     %set to all if you want both sections and subsections linked
  linkcolor=black,  %choose some color if you want links to stand out
}
% New environment to scale prooftrees, from https://tex.stackexchange.com/questions/104554/how-to-scale-prooftree-environment-bussproofs-package
\newenvironment{scprooftree}[1]%
  {\gdef\scalefactor{#1}\begin{center}\proofSkipAmount \leavevmode}%
  {\scalebox{\scalefactor}{\DisplayProof}\proofSkipAmount \end{center}
}
%New command \mybox to box something
\newcommand{\mybox}{%
\collectbox{%
	\setlength{\fboxsep}{3pt}%
	\fbox{\BOXCONTENT}%
	}%
}

\usepackage{graphicx}
\graphicspath{{Images/}}
\author{Julian Lore}
\date{Last updated: \today}
\title{COMP 330: Theory of Computation}
\pagestyle{fancy}
\lhead{COMP 330}
\chead{\leftmark}
\rhead{Julian Lore}
\cfoot{Page \thepage \ of \pageref{LastPage}}
\newcommand{\tab}[1]{\hspace{.2\textwidth}\rlap{#1}}
\newenvironment{rcases}
  {\left.\begin{aligned}}
  {\end{aligned}\right\rbrace}
\begin{document}
\onehalfspacing
\maketitle
\tableofcontents
\section{09/03/19}
\paragraph{Language}
Let $\Sigma$ be a finite alphabet (set). Let $\Sigma^*$ be all possible
sequences of elements from alphabet (infinitely many sequences). A
\textbf{language} $L$ is any subset of $\Sigma^*$. It will tell you for
every possible string whether it is in $L$ or not. An algorithm $A$
decides a language $L$ if it can say whether $x\in L$ or $x\notin L$
(can answer yes or no).

Example: alphabet is $\{0,1\}$. Our language can be all prime numbers
represented as binary numbers. We can then make an algorithm that
decides if a binary string $x$ is a prime or not (i.e.\ is it in our language?).

Generally however, we will ask ourselves, if we can define a language,
can we come up with an algorithm to decide it?

$$\text{All languages} \supset \text{Languages we can describe}
\supset \text{Languages that are decidable}$$
\begin{itemize}
\item $|\text{All languages}| = \mathbb{R}$
\item $|\text{Languages we can describe}| = \mathbb{N}$
\item $|\text{Languages we can decide}| = \mathbb{N}$ (however it is
  much smaller than what we can describe). Clearly things that are
  decidable are describable, as the algorithm to decide it can also
  describe it.
\end{itemize}
\paragraph{Post Correspondence Problem}You are given a set of tiles
that have strings.
\\
\begin{tabular}{|c| c| c| c| c |c|}
  \hline aaa&a&bbb&aa&&b
  \\ bb & bb & a & a & bb &
  \\ \hline
\end{tabular}
\\ Is there a sequence of these tiles that the concatenation of the
top string is the same as the bottom string?
% \\ Solution for our example:
% \\
% \begin{tabular}{|c| c| c| c| c |c|}
%   \hline aa&a&bbb&aa&&b
%   \\ bb & bb & a & a & bb &
                              %     \\ \hline
% \end{tabular}
\\ The general version of the problem is $n$ tiles, $u_1/v_1 \ldots
u_n/v_n$ where each $u_i$ and $v_i$ are sequences of letters. Is there
a $k$ and a sequence $\langle i_1, i_2, \ldots, i_k \rangle$ ($1 \leq
i_j \leq n, \forall j \in \{1,\ldots,n\}$), such that $u_{i_1} \ldots
u_{i_k} = v_{i_1} \ldots v_{i_k}$.
\paragraph{Theorem} The Post Correspondence Problem cannot be decided by any
algorithm/computer program. No algorithm can give a no answer in a
finite amount of time. We can, however, give yes answers/find a
solution if one exists.
\section{09/05/19}
To prove the theorem, we use a reduction technique. If PCP was
decidable then another undecidable problem, the halting problem, would
also be decidable. We will often reduce problems to others in this
course.
\paragraph{The Halting Problem}
Note that an algorithm is just text. An algorithm can receives text as
input and thus can receive the text of an algorithm as input.

So the Halting Problem is as follows: Given two texts $A$ and $B$, $A$
being an algorithm, $B$ being an input. Will $A$ halt (instead of loop
forever) on input $B$?

Back to PCP, any algorithm that can decide PCP can be converted to an
algorithm to decide the Halting Problem. Thus we conclude that PCP
cannot be decided.

\paragraph{Computability Theory}
Consists of the ability to distinguish between all languages,
describable languages and decidable languages, the difference between
describable and decidable languages being the most important.
\paragraph{Complexity Theory} Distinguishing between languages we can
decide, languages we can check efficiently and languages we can decide
efficiently (polynomial).
\paragraph{Example} Map coloring, can we color a map such that all the
neighbors have different colors? Without a color restriction, we can
just use different colors for each area. How about with 2 colors? This
is the 2-coloring problem. This can easily be checked, an area cannot
have two neighbors that are also neighbors. Or we can just try
coloring the map with two colors and see if we get a conflict.

How about 3 colors? Try coloring the map. But when trying to color,
when we reach a neighbor, we have a choice between either of the two
remaining colors. So naturally we should try both. Then checking this
becomes exponential.

Note that checking the validity of an $n$-coloring is much simpler
than finding said $n$-coloring. Finding is exponential, but checking
just requires verifying the neighbors and is polynomial.

\paragraph{Summary of $K$-coloring of maps}
\begin{itemize}
\item $K = 1$, can only color maps with zero or one region.
\item $K = 2$, impossible when three regions are all neighbors,
  otherwise valid. Easy to decide.
\item $K = 3$, no known efficient algorithm to decide, easy to check.
\item $K \geq 4$, all maps are $K$-colorable (there exists a long
  proof for $4$, people managed to reduce the infinite cases of maps
  to about $300,000$ cases that were checked). No easy to find, easy
  to verify.
\end{itemize}
$3$-coloring of maps is a special type of problem (NP-complete
problems), as solving this efficiently would solve many other problems
efficiently.
\paragraph{Examples of NP-Complete Problems}
\begin{itemize}
\item SAT:\ given a boolean formula (logic formula), does there exist
  a truth assignment such that the formula is true?
\item Traveling Salesman:\ given a set of cities and distances between
  them, find the shortest path to visit each city once.
\item Knapsack:\ given items with weights, is there a subset of them
  of weight $K$?
\end{itemize}
Many practical problems are NP-Complete. If we can solve one
efficiently, they can all be solved efficiently. In practice, some
special cases of the problems can be solved efficiently.
\paragraph{Tractable Problems (P)} Problems for which we can
efficiently (polynomial) decide whether an instance of a problem is a
yes or no, i.e.\ is this map $2$-colorable?
\\ Examples:
\begin{itemize}
\item $2$-colorability of maps
\item Primality testing
\item Solving $N \times N \times N$ Rubik's cubes
\item Finding a word in a dictionary
\item Sorting
\end{itemize}
$P$ stands for Polynomial-Time computable. Sometimes problems may be
efficiently solvable but it might not be provable.

Back to complexity theory, $\text{Decidable languages} \supset NP
\supset P$. NP-Complete problems are a subset of NP problems. If we
can bring the complete problems to P, then $NP = P$. We tend to
believe $P \neq NP$ as all attempts to show they're equal so far have
failed.

PSpace Completeness: problems that require polynomial space to be solved but can
still take very long. Again, if any of these problems can be done in
polynomial time, then they can all be solved in polynomial time.
\\ Example: Geography game. This is a two player game. Given a set of
country names, the first player chooses a country, then the other
player must choose a country whose name starts with the last letter of
the country chosen by the previous player. Someone wins if their
opponent cannot choose a country.
\\ Generalized geography game consists of an arbitrary set of names
$w_1, \ldots, w_n$ instead. Is there a winning strategy for the
starting player? Intuitively, you can solve this by enumerating all
possibilities. You won't be able to use more than $n$ names, but you
may have to enumerate many possibilities. So you can check all
possibilities without using much space (polynomial).

PSpace is a superset of NP (although we don't know if they're unequal
or not), which also has a complete subset.

\paragraph{Theoretical Computer Science}
Want to find efficient solutions to many problems, this is the
algorithm and data structures part.

We also want to prove that some problems are not computable within a
certain time or space.

We also consider new models of computation (like quantum
computers). This won't disrupt our notion of computability (whether
something can be computed) but it will disrupt our notion of
complexity, as lots of things will be faster/easier to compute.

\subsection{Deterministic Finite Automata and Regular Expressions}
DFAs consists of labeled nodes (states corresponding to the memory of
a device, the device only knows what state it is in) with edges
between them, allowing the device to move from one state to another
depending on the input (edges are labeled).

\paragraph{Examples of DFAs}
\begin{itemize}
\item Swing doors (before motion detectors) had a front pad and a rear
  pad.

  It would have a closed state and an open state. In the closed state,
  if someone is on the front pad and no one is on the rear pad, the
  door would go to the open state until no one is on either pad. If in
  the closed state but someone is on the rear pad, it should never
  open. We can draw a DFA for this.
\end{itemize}
\section{09/10/19}
\paragraph{DFA} A finite automaton is a 5-tuple $(Q, \Sigma, \delta,
q_0, F)$ where:
\begin{itemize}
\item $Q$: States
\item $\Sigma$: Alphabet (fixed string inputs it can take)
\item $\delta: Q \times \Sigma \to Q$: Transition function (how you should go from a certain state to
  another if your next symbol is something from the alphabet, read
  symbols one by one), displayed by arrows from state to state. For
  the simple module, we assume every state has a transition state for
  every symbol of the alphabet. We can describe $\delta$ either via a
  picture of the DFA or with a table.
\item $q_0 \in Q$: Start state. Indicated by an incoming arrow from nowhere. There
  is only one start state in a DFA as it is deterministic.
\item $F \subseteq Q$: Accept states. There can be multiple accept states, identified
  by an extra circle in the node. If you reach the end of the string
  and are in an accept state, the automaton will accept the string,
  otherwise it will reject it.

  If $F = Q$, then all strings will be accepted, i.e.\ the language is $\Sigma^*$.
\end{itemize}
Note that the empty string is a valid input. It will only be accepted
if the start state is an accept state.
\subsection{Regular Languages} Let $M = (Q, \Sigma, \delta, q_0, F)$
be a finite state automaton and $w = w_1w_2\ldots w_n, n \geq 0$ be a
string where each $w_i$ is from the alphabet $\Sigma$. $M$
\textbf{accepts} $w$ if states $s_0,s_1, \ldots, s_n$ exist such that:
\begin{itemize}
\item $s_0=q_0$ (we start at the starting state)
\item $s_{i+1} = \delta(s_i, w_{i+1}), i = 0, \ldots, n-1$ (every
  intermediate state and its corresponding symbol fits the transition function)
\item $s_n \in F$ (the final state is an accept state)
\end{itemize}
A finite automaton $M$ \textbf{recognizes language} $A$ if $A =
\left\{w \mid M \text{ accepts w}\right\}$. The finite automaton has
to accept every string in the language and reject every string that
isn't in the language.

A language is \textbf{regular} if some finite automaton recognizes it.

We saw examples of $0,1$ strings that have at least $1$ and end in an
even amount of $0$s, as well as an example of numbers being multiples
of $3$. If you sum the digits of a number in base $10$ and get modulo
$10$ of it and end up with $0,3,6$ or $9$, then the number is a
multiple of $3$. This is a finite automaton. You can reconstruct this
as a finite automaton by simulating $\mod 3$, counting the remainder
by transitioning to states. In general, if we work $\mod n$, we'll
need $n$ states.
\section{09/12/19}
\paragraph{Automata for multiples of $N$ base $B$}
If a number in base $10$ ends in an even number, then the number is
even. Similarly, for binary, we just check if it ends with
$0$. Automata can check just that.

Similarly, there exists automata for other mods, such as $3$. We have $3$ states, one for each possible
remainder.
% Appending a $0$ to a binary string will double the
% number. So if the number was already a multiple of $3$, it'll remain a
% multiple of $3$. However, appending a $1$ will give you a remainder
% of $1$.
\begin{itemize}
\item $q_0 \stackrel{0}{\to} q_0$: adding a $0$ doubles the number, if
  it was already a multiple of $3$ it'll remain a multiple of $3$.
\item $q_0 \stackrel{1}{\to} q_1$: doubles the number and adds $1$, so
  a multiple of $3$ gets a remainder of $1$
\item $q_1 \stackrel{0}{\to} q_2$: doubles, remainder of $1$ becomes $2$
\item $q_1 \stackrel{1}{\to} q_0$: doubles and adds $1$, so the
  remainder becomes $2 + 1$, i.e.\ no remainder, a multiple of $3$.
\item $q_2 \stackrel{0}{\to} q_1$: doubles, remainder of $2$ becomes
  $1$
\item $q_2 \stackrel{1}{\to} q_2$: doubles, adds one, stays a
  remainder of $2$
\end{itemize}

We can use this strategy to generalize automata for different mods and
bases. Simply look at what happens with the remainder at a certain
state when you multiply by $2$ (or $10$ or $16$, etc.)

We can also reduce the size of some of these automata. Note that
making a finite automata for checking if something is $0\mod 3$ in
base $3$ consists solely of checking the last digit. $q_i$ will
indicate that the last viewed digit is $i$. So we accomplish this with
$3$ states. However, we can combine $q_1$ and $q_2$ to make this an
automaton with only $2$ states, multiple of $3$ or not.
\subsection{Regular Operations}
$A$ and $B$ are languages. Then we define:
\begin{itemize}
\item \textbf{Union}: $A \cup B = \left\{x \mid x \in A \text{ or } x
    \in B\right\}$
\item \textbf{Concatenation}: $A \circ B = \left\{xy \mid x \in A
    \text{ and } y \in B\right\}$
\item \textbf{Star}: $A^* = \left\{x_1x_2\ldots x_k \mid k \geq 0
    \text{ and each }x_i \in A\right\}$ (includes $\varepsilon$)
\end{itemize}
If $A$ and $B$ are finite, their union and concatenation are finite,
however a star is infinite (unless the language consists only of the
empty string).

\subsection{Kleene's Theorem}
\paragraph{Union}
The class of regular languages is closed
under the union operation. i.e.\ $L_A, L_B$ regular $\implies L_A \cup
L_B$ regular.

\paragraph{Proof}
Let $M_A = (Q_A, \Sigma, \delta_A, q_{0A}, F_A),M_B = (Q_B, \Sigma,
\delta_B, q_{0B}, F_B)$ be DFAs accepting $L_A$ and $L_B$.

Consider:
\begin{align*}
M_{\cup} &= (Q_A \times Q_B, \Sigma, \delta_\cup, (q_{0A},
  q_{0B}), F_{\cup})
  \\ \delta_\cup((q,q'),s) &= (\delta_A(q,s),
  \delta_B(q',s)), \forall q,q',s
  \\ F_\cup & = \left\{(q,q') \mid q\in
  F_A \text{ or }q' \in F_B\right\} = (F_A \times Q_B) \cup (Q_A
  \times F_B) \neq F_A \times F_B
  \\L_\cup & = L_A \cup L_B
\end{align*}.
Essentially our states are now
pairs of both states from the original machines and we simulate the
transitions of the original machines. We accept if either part of the
pair is an accept state from $M_A$ or $M_B$. Technically $M_A$ and
$M_B$ don't need to share the same alphabet, however, this is often
the case.

If we make the accepting states $F_A \times F_B$, then the language
would be the \textbf{intersection} of the languages, which proves that
the class of regular languages is closed under intersection.

\paragraph{Concatenation} Regular languages closed under
concatenation. $L_A, L_B$ regular $\implies L_A \circ L_B$ regular. We
will use NFAs rather than DFAs to prove this.

\subsection{Non-Deterministic Finite Automata}
It is now possible to have more than one transition given one
symbol. It is even possible to have no transitions at some state given
a symbol. In this case, the machine will stop/reject. Additionally, we
will also allow empty $\varepsilon$ transitions, if there's an
$\varepsilon$ transition from $q_i$ to $q_j$, the machine can move
from $q_i$ to $q_j$ without consuming any input.

With these relaxations, it will now be possible to be in multiple
states when reading the same symbol/part of the string. A string is
accepted if one of the \textbf{possible} final states given the string
is an accepting state.

Formally we define an NFA as:

$(Q, \Sigma, \delta, q_0, F)$ such that:
\begin{itemize}
\item $Q$: States
\item $\Sigma$: Alphabet
\item $\delta: Q \times \Sigma_{\varepsilon} \to \mathcal{P}(Q)$:
  transition function, where $\Sigma_{\varepsilon} = \Sigma \cup \varepsilon,
  \mathcal{P}(Q) = \left\{S : S \supset Q\right\}$
\item $q_0 \in Q$: Start state.
\item $F \subseteq Q$: Accept states.
\end{itemize}

An NFA $N = (Q,\Sigma, \delta, q_0, F)$ with $w = w_1w_2\ldots w_n$
($n \geq 0$) being a string with each $w_i \in \Sigma$,
\underline{accepts} $w$ if $\exists m \geq n$(might exceed $n$ steps
as we allow empty transitions) $, \exists s_0, s_1, \ldots, s_m$ and
$\exists y_1y_2\ldots y_m=w$ with each $y_i \in \Sigma_{\varepsilon}$
such that:
\begin{itemize}
\item $s_0 = q_0$
\item $s_{i+1}\in \delta(s_i, y_{i+1})$, for $i = 0, \ldots, m-1$
\item $s_m \in F$
\end{itemize}
\section{09/17/19}
\subsection{NFA-DFA Equivalence}
\paragraph{Theorem} Every NFA has an equivalent DFA.
\paragraph{Corollary} A language is regular iff some NFA recognizes
it.
\paragraph{Conversion without empty transitions}
Let $N = (Q, \Sigma, \delta, q_o, F)$ be an NFA with no empty
transitions accepting language $A$. The following describes $M = (Q',
\Sigma, \delta', q_0', F')$, a DFA accepting $A$.
\begin{itemize}
\item The states of the DFA should be the set of all possible subset
  of states in the NFA, i.e.\ if we can be in states $q_1$ and $q_2$
  in the NFA at the same time, then the DFA should have a state
  $q_{\{1,2\}}$. Formally, $Q' = \mathcal{P}(Q) = \left\{R \mid R
    \subseteq Q\right\}$ (this includes all possible subsets, we may
  not need all of them)
\item $\delta'(R, a) = \left\{q \in Q \mid \exists r \in R, q \in
    \delta(r,a)\right\}$ (note this is a set, it defines a transition
  on a whole set $R$, which essentially is just the union of all the
  possible transitions from each of these states). This will bring us
  from a subset of states to another subset of states.
\item $q'_0 = \{q_0\}$ (same initial state, but as a singleton as it
  must be a set)
\item $F' = \left\{R \in Q' \mid R \cap F \neq \emptyset\right\}$ (at
  least one of the states in $R$ is an accepting state in the NFA)
\end{itemize}
A convenient way to represent the possible states we can be in is with
a binary string, that is:
$$q_{w_nw_{n-1}\ldots w_1} = q_{R} : (w_i = 1 \iff i \in R)$$
e.g.\ $q_{0000} = q_{\emptyset}, q_{1001} = q_{\{1,4\}}$
\paragraph{With empty transitions}~ \\Define $E(R) = \left\{q \mid q
  \text{ can be reached from }R \text{ by traveling along }0 \text{ or
    more }\varepsilon \text{ arrows}\right\}$
\\
Everything will be the same as above, except for the transition
function and the starting state:
$$\delta'(R, a) = \left\{q \in Q \mid \exists r \in R, q \in
  E(\delta(r,a))\right\}, \forall a \neq \varepsilon$$
$$q_0' = E(q_0)$$
\paragraph{Regular Operations: Kleene's theorem for NFAs}
The class of regular languages is closed under union. Let $N_A = (Q_A,
\Sigma, \delta_A, q_{0A}, F_A)$ be an NFA accepting $L_A$ and $N_B =
(Q_B,\Sigma, \delta_B, q_{0B}, F_B)$ be an NFA accepting $L_B$ ($Q_A
\cap Q_B = \emptyset$, for simplicity). Now consider $N_\cup =
(\{q_0\}\cup Q_A \cup Q_B, \Sigma, \delta_\cup, q_0, F_{\cup})$ with
\begin{itemize}
\item $\delta_{\cup}(q_0, \varepsilon) = \left\{q_{0A},q_{0B}\right\},
  \delta_\cup (q_0, a) = \emptyset$ for all $a \neq \varepsilon$
\item $\delta_\cup(q, a) = \delta_X (q,a)$ for all $q\in Q_X$, $X\in
  \left\{A,B\right\}$ and for all $a$
\item $F_\cup = F_A \cup F_B$
\item $L_\cup = L_A \cup L_B$
\end{itemize}
Informally, this is equivalent to adding a new starting state with a
$\varepsilon$ transition to both of the starting states of $N_A$ and
$N_B$. Because a string in $L_A \cup L_B$ is accepted by at least
$N_A$ or $N_B$ (possibly both), then $N_\cup$ will accept it as the
$\varepsilon$ transitions of the starting states will simulate passing
the input to both machines.

The class of regular languages is closed under concatenation.  \\
Informally, make $\varepsilon$ transitions from each accepting state
of the first NFA (these will now no longer be accepting states) to the
start states of the second NFA.

$N_A$ and $N_B$ and their respective languages the same as defined
above for union.
\\ $N_C = (Q_A \cup Q_B, \Sigma, \delta_C, q_{0A}, F_{AB})$ with:
\begin{itemize}
\item $\delta_C(q,a) = \delta_B (q,a), \forall q \in Q_B$
\item $\delta_C(q,a) = \delta_A (q,a), \forall q \in Q_A, a \neq
  \varepsilon$
\item $\delta_C(q,\varepsilon) = \delta_A(q, \varepsilon), \forall q
  \in Q_A \setminus F_A$
\item $\delta_C(q,\varepsilon) = \delta_A (q,\varepsilon) \cup
  \{q_{0B}\}, \forall q \in F_A$
\item $L_C = L_A \circ L_B$
\end{itemize}

The class of regular languages is closed under the start
operation. Essentially, you make a new start state (with an
$\varepsilon$ transition to the original start state) that is an
accepting state (so that the empty string will be accepted) and loop
all the accepting states with an $\varepsilon$ transition to said
start state (to start over and loop).
\\ $N_A$ is the same as defined above. Consider $N_S = (Q_A \cup
\{q_0\}, \Sigma, \delta_S, q_0, F_A \sup \{q_0\})$ with:
\begin{itemize}
\item $\delta_S(q_0, \varepsilon) = q_{0A}$ and $\delta_S(q_0,a) =
  \emptyset, a \neq \varepsilon$
\item $\delta_S(q,a) = \delta_A(q,a), \forall q \in Q_A\setminus F_A$
\item $\delta_S(q,\varepsilon) = \delta_A(q,\varepsilon) \cup
  \{q_{0A}\}, \forall q \in F_A$
\item $\delta_S(q,a) = \delta_A(q,a), \forall q \in F_A, a \neq
  \varepsilon$
\item $L_S = (L_A)^*$
\end{itemize}
\section{09/19/19}
When converting from a DFA to an NFA, often we produce nodes that are
not reachable (since we enumerate over all possible subsets of
nodes). In order to reduce the number of states we have, we can check
for reachable states with graph search algorithms. Furthermore, there
can be \textbf{redundant states} that do the same thing (i.e.\ $q_2$
will go to either $q_3$ or $q_4$ depending on input, but $q_3$ and
$q_4$ are not accepting states and go to the same state given the same
input, so we can combine $q_3$ and $q_4$).
\subsection{Myhill-Nerode Theorem}
Let $x, y$ be strings, $L$ a language. $x$ and $y$ are
\textbf{distinguishable} by $L$ if $\exists$ suffix $z$ such that $xz
\in L$ and $yz \notin L$ or $yz \in L$ and $xz \notin L$.

$x \equiv_L y$ (equivalence relation) $\iff$ $x$ and $y$ are
\textbf{indistinguishable} (not
distinguishable) by $L$.

Showing that two strings are distinguishable is easy, all you need to
do is provide an example. However, to show indistinguishable, you must
show for all possible $z$.

Let $L$ be a language and $X$ a set of strings. $X$ is
\textbf{pairwise distinguishable} by $L$ if each pair of elements in
$X$ are pairwise distinguishable by $L$ ($\forall x, x' \in X, x
\not \equiv_L x'$).

The \textbf{index} of $L$ is the size of a maximum set $X$ that is
pairwise distinguishable by $L$. Not necessarily finite. This index
characterizes precisely what regular languages are, as regular
languages will have a finite index.

\paragraph{Myhill-Nerode Theorem}
\begin{enumerate}[(a)]
\item $L$ is recognized by a DFA with $k$ states $\implies$ index of
  $L \leq k$

  \textbf{Proof}: Let $M$ be a $k$ state DFA recognizing $L$. Assume
  $L$ has index $> k$. $\exists X$ with $k+1$ elements distinguishable
  by $L$. $\exists$ strings $x$ and $y$, such that starting in
  the start state, $x$ and $y$ lead to the same state (by a counting
  argument), i.e. $\delta(q_0, x) = \delta(q_0, y)$. But then $x$ and
  $y$ are not distinguishable. \lightning
\item Index of $L = k$ (finite) $\implies L$ recognized by DFA with
  $k$ states

  \textbf{Proof}: $X = \left\{s_1, \ldots, s_k\right\}$ be pairwise
  distinguishable by $L$. $Q = \left\{q_1, \ldots, q_k\right\}$ are
  states of a DFA recognizing $L$ (note that these indices correspond
  to the indices of the strings of $X$) and define $\delta(q_i, a) = q_j$
  s.t.\ $s_j \equiv_L s_ia$ (states are equivalent to the string of
  the same index, we are using the fact that every string is
  equivalent to one string in $X$ as its the index (otherwise we would
  be able to add another string to $X$); think of each
  string being a representative). Let $q_0$ be the $q_i$ s.t.\ $s_i
  \equiv_L \varepsilon$(starting state corresponds to empty string). Let $F = \left\{q_i \mid s_i \in
    L\right\}$ (accept any string corresponding to accepted
  $s_i$'s). $M = \left\{s \mid \delta(q_0, s = q_i), q_i \in F\right\}
  = \left\{s \mid s \equiv_L s_i, s_i \text{ recognized by }L\right\}$
\item $L$ regular $\iff$ index is finite. Index is size of smallest
  DFA recognizing $L$.

  \textbf{Proof}: $(\implies)$ $L$ regular $\implies \exists$ DFA
  recognizing $L$. By (a), index of $L \leq k$
  \\ $(\impliedby)$ Index $L = k$ then (b) $\implies \exists$ DFA with
  $k$ states (so $L$ is regular)

  For minimality, if index of $L$ is not the size of minimal DFA then
  $\exists$ DFA with index $- 1$ states recognizing $L$. Impossible by (a).
\end{enumerate}
We will explicitly use this theorem to minimize the number of states.

Let $L$ be a regular language. Compute index of $L$ by finding set $X$
of all strings pairwise distinguishable by $L$. All strings considered
as $x, y, xz, yz$ may be \textbf{shorter than the number of states}
of a DFA accepting $L$. Every longer string is equivalent to a shorter
one obtained by pumping down (strings longer than number of states
will eventually take me to a state that I've already been in).

\paragraph{Minimizing using the Myhill-Nerode Theorem}
Let $L$ be a regular language. Compute index of $L$ as
above. Construct a DFA as in (b) to construct a minimal DFA accepting $L$.

We can also use the Myhill-Nerode theorem in the other direction.

$B = \left\{0^n1^n \mid n \geq 0 \right\}$ is non-regular because its
index is infinite. $X = \left\{0^n \mid n \geq 0\right\}$ is an
infinite set that is pairwise distinguishable by $B$.
\\ \textbf{Proof}: $\forall n, 0^n \not \equiv_B 0^i, 0 \leq i \leq
n-1$ because $\exists z =1^n$ such that $0^nz \in B$ but $0^iz \notin
B, 0 \leq i \leq n-1$
\end{document}